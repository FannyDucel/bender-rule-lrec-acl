[
  [
    "\nthe impetus toward conceptual\nentrainment marked by repeated referring\nexpressions appears to be so compelling that\nnative speakers of english will even produce\nnon-idiomatic referring expressions (e",
    "appliqu\u00e9e"
  ],
  [
    "\natr, a japanese research institute for\ntelephone dialogue translation supported by\na consortium of private companies and the\nministry of post and communication, also\nadopted a linguistics-based framework, al-\nthough they changed their direction in the\nlater stage of the project",
    "appliqu\u00e9e"
  ],
  [
    "\ndiverse systems, such as large scale english\nand japanese grammar, a statistical disam-\nbiguation module for the japanese parser, a\nrobust parser for english, etc",
    "appliqu\u00e9e"
  ],
  [
    "\nas for wide-coverage japanese gram-\nmar, we have developed our own grammar\n(slung) ",
    "appliqu\u00e9e"
  ],
  [
    ": hpsg-style underspeci\fed\njapanese grammar with wide coverage, in\nproc",
    "appliqu\u00e9e"
  ],
  [
    ": translating the xtag english\ngrammar to hpsg, in proc",
    "appliqu\u00e9e"
  ],
  [
    " as tagset we\nuse the stuttgart-tubinger tagset for german\n(schiller et al",
    "appliqu\u00e9e"
  ],
  [
    "\n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\ngerman | english\ntrain sentences 34 465\nwords 363514 | 383 509\nvoc",
    "appliqu\u00e9e"
  ],
  [
    " this work was\npartly supported by the german federal min-\nistry of education, science, research and\ntechnology under the contract number 01\niv 701 t4 (verbmobil)",
    "appliqu\u00e9e"
  ],
  [
    "phrase-pattern-based korean to english machine translation\nusing two level translation pattern selection\n\nkim, jung-jae and choi, key-sun\ncomputer science division, kaist\njjkim@nlp",
    "appliqu\u00e9e"
  ],
  [
    " for example, a korean verb ta-da\nwith objects bus(bus) and mal(horse) is\ntranslated into english verbs take and ride\nrespectively",
    "appliqu\u00e9e"
  ],
  [
    " for ex-\nample, a korean verb phrase pattern np+lul\nssu-da can be translated into wear np,\nwrite np, compose np, use np, or spend\nnp",
    "appliqu\u00e9e"
  ],
  [
    " if np has a meaning [head-gear], then\nthe korean verb phrase pattern can be trans-\nlated into wear np or put on np",
    "appliqu\u00e9e"
  ],
  [
    " it takes two\nsteps to select the most natural english trans-\nlation pattern as a corresponding pattern of\na korean pattern:\n\n1) to select possible translation pattern cat-\negories,\n2) to select the most natural english transla-\ntion pattern among possible translation pat-\ntern categories",
    "appliqu\u00e9e"
  ],
  [
    "\n\namong the ambiguities in korean to en-\nglish machine translation, the ambiguities in\nkorean pattern matching are reduced by us-\ning a hybrid method of exact example match-\ning and semantic constraint by thesaurus, and\nthe ambiguities in korean to english pattern\ntransfer are reduced by using syntactic col-\nlocational information of english (lee et al",
    "appliqu\u00e9e"
  ],
  [
    "1 pattern matching\n\nthere are several english translation pat-\nterns of a korean verb phrase pattern (e",
    "appliqu\u00e9e"
  ],
  [
    " in the first step, we\ndivide them into several translation pattern\ncategories with both examples and semantic\nconstraint by korean thesaurus",
    "appliqu\u00e9e"
  ],
  [
    " first three categories are se-\nmantically constrained by korean thesaurus",
    "appliqu\u00e9e"
  ],
  [
    " at the same\ntime, s? is translated into poem among all\nenglish words for the korean word si, be-\ncause only poem has the meaning of [pro-\nduction (language)]",
    "appliqu\u00e9e"
  ],
  [
    ")\n\nfor example, both korean verbs muk-\nda(eat) and ssu-da(write) can take si-lul\nas objects in example exl",
    "appliqu\u00e9e"
  ],
  [
    " to ac-\nquire the most natural english sentence, we\nuse english syntactic collocational informa-\ntion, especially for subject-verb relation and\nverb-object relation",
    "appliqu\u00e9e"
  ],
  [
    " we regard the english\npattern of the most frequent syntactically re-\nlated pair as the most natural translation pat-\ntern",
    "appliqu\u00e9e"
  ],
  [
    " english verb write, compose and\nenglish noun poem appear as verb-object re-\nlation in the corpus four times and zero times\nrespectively",
    "appliqu\u00e9e"
  ],
  [
    " there are\nmany korean nouns with the meaning [some-\nthing to ride] like horse, car, \"bus, train\nand so on",
    "appliqu\u00e9e"
  ],
  [
    " but\nthe korean thesaurus, which we used, does\nnot bring out the differences",
    "appliqu\u00e9e"
  ],
  [
    " this problem\nshows that korean and english have very dif-\nferent semantic hierarchies of thesaurus con-\nstruction (palmer et al",
    "appliqu\u00e9e"
  ],
  [
    " to score each node, several methods\ncan be used; the frequency of each pattern\nin the corpus (sorniertlamvanich, 1998) and\nthe korean syntactic collocational informa-\ntion (yoon, 1998)",
    "appliqu\u00e9e"
  ],
  [
    " also we\ndidnt describe syntactic information of the\n\fkorean pattern, the korean syntactic collo-\ncational information is not useful yet",
    "appliqu\u00e9e"
  ],
  [
    " ife has no constraint, -\nnttleng ~ distane\nnttleng:\n\n \n\n \n\nsem (p,sc) = +(i- )\n\nfigure 3: a pattern scoring method\n\nafter all the nodes are scored recursively\nwith the pattern scoring method, the root\nnode of the best score is regarded as the root\nof the best korean pattern tree",
    "appliqu\u00e9e"
  ],
  [
    " after the\nbest korean pattern tree is selected, this tree\nis transferred to english pattern tree in pat-\ntern transfer and the english pattern tree is\ntransferred to the english phrase structure\nautomatically",
    "appliqu\u00e9e"
  ],
  [
    " then, according to the en-\nglish phrase structure, the final english sen-\ntence is generated",
    "appliqu\u00e9e"
  ],
  [
    " and we manu-\n\n?we made the korean thesaurus by translating\nntt thesaurus for nouns and verbs",
    "appliqu\u00e9e"
  ],
  [
    " the english syntactic collo-\ncational information (about 54,000 different\nsubject-verb pairs and about 75,000 different\nverb-object pairs included) was obtained from\npenn treebank?",
    "appliqu\u00e9e"
  ],
  [
    " but we use only 6 levels which\nseem to be useful in korean\nshttp://www",
    "appliqu\u00e9e"
  ],
  [
    " to solve these problems, it\nis needed to use the korean syntactic analysis\n(yoon, 1998)",
    "appliqu\u00e9e"
  ],
  [
    "\nrestoration error has occurred when the nec-\nessary information in english sentence was\nnot restored, e",
    "appliqu\u00e9e"
  ],
  [
    " in the second step, the most\nnatural translation pattern is selected by the\nenglish syntactic collocational information",
    "appliqu\u00e9e"
  ],
  [
    "\nin the future, it is needed to use the syn-\ntactic collocational information of korean to\nreduce ambiguities in pattern matching step",
    "appliqu\u00e9e"
  ],
  [
    " and research on restoring the\nnecessary information in english sentence\nhas to be done",
    "appliqu\u00e9e"
  ],
  [
    "\n\nacknowledgement\n\nthis research is supported by the ko-\nrea science and engineering founda-\ntion(kosef) through the multilingual\ninformaton retrieval project at the ad-\nvanced information technology research\ncenter(alitrc), and also supported by korea\nterminology research center for language\nand knowledge engineering, under the\nproject on development of deep-level pro-\ncessing and quality management technology\nfor very large korean information base,\na project of plan step2000 by the fund of\nmlnistry of science and technology, during\nthe period from 1997 through 2000",
    "appliqu\u00e9e"
  ],
  [
    "\n\ndagan, ido and alon itai",
    "appliqu\u00e9e"
  ],
  [
    " ambi-\nguity resolution of korean sentence analysis\nand korean-english transfer based on korean\nverb patterns",
    "appliqu\u00e9e"
  ],
  [
    " a study on\nexample-based korean to english machine\ntranslation system development",
    "appliqu\u00e9e"
  ],
  [
    "\n\f \n\n \n\n \n\n \n\n \n\nsegment | file pairs | sentence pairs | english tokens | french tokens\ntrain 922 29,547,936 31,826,112\nheld-out 30 978,394 1,082,350\ntest 30 984,809 1,103,320\n\n \n\n \n\n \n\n \n\n \n\ntable 1: corpus segmentation",
    "appliqu\u00e9e"
  ],
  [
    "\n\n4 experiments\n\ni ran experiments on the canadian hansard\ncorpus, with english as the source language\nand french as the target language",
    "appliqu\u00e9e"
  ],
  [
    " one key area of interest with japanese\nis the effect that segmentation has on retrieval\nperformance",
    "appliqu\u00e9e"
  ],
  [
    " as japanese is a non-segmenting\nlanguage (does not explicitly delimit words or-\nthographically), we can take the brute-force ap-\nproach in treating each string as a sequence of\ncharacters (character-based indexing), or al-\nternatively call upon segmentation technology in\npartitioning each string into words (word-based\nindexing)",
    "appliqu\u00e9e"
  ],
  [
    "1 segmentation\ndespite non-segmenting languages such as\njapanese not making use of segment delimiters,\nit is possible to artificially partition off a given\nstring into constituent morphemes through the\nprocess of segmentation",
    "appliqu\u00e9e"
  ],
  [
    "\nlooking to past research on string compari-\nson methods for tm systems, almost all sys-\ntems involving japanese as the source lan-\nguage rely on segmentation (nakamura, 1989;\nsumita and tsutsumi, 1991; kitamura and ya-\nmamoto, 1996; tanaka, 1997), with sato (1992)\nand sato and kawase (1994) providing rare in-\nstances of character-based systems",
    "appliqu\u00e9e"
  ],
  [
    " this\nis despite fujii and croft (1993) providing evi-\ndence from japanese information retrieval that\ncharacter-based indexing performs comparably to\nword-based indexing",
    "appliqu\u00e9e"
  ],
  [
    " in analogous research,\nbaldwin and tanaka (2000) compared character-\nand word-based indexing within a japanese?\nenglish tr context and found character-based in-\ndexing to hold a slight empirical advantage",
    "appliqu\u00e9e"
  ],
  [
    "\nas far as we are aware, there is no tm sys-\ntem operating from japanese that does not rely\non word/segment/character order to some degree",
    "appliqu\u00e9e"
  ],
  [
    "\nfrom the japanese string? ?? ?? [natu?no?ame]\n?summer rain?,1 for example, we would generate\nthe following variants (common to both character-\nand word-based indexing):\n1-gram: ? ?? ??\n2-gram: ?? ???\nmixed 1/2-gram: ? ??? ?? ??? ??\n3 string comparison methods\nas the starting point for evaluation of the\nthree parameter types targeted in this re-\nsearch, we take two bag-of-words (segment order-\noblivious) and three segment order-sensitive meth-\nods, thereby modelling the effects of segment or-\nder (un)awareness",
    "appliqu\u00e9e"
  ],
  [
    " most trecs comprise a single sen-\ntence, with an average japanese character length\nof 27",
    "appliqu\u00e9e"
  ],
  [
    "7 and english word length of 13",
    "appliqu\u00e9e"
  ],
  [
    " the average japanese\ncharacter length of each trec is 76",
    "appliqu\u00e9e"
  ],
  [
    "3, and the av-\nerage english word length is 35",
    "appliqu\u00e9e"
  ],
  [
    "\nfor japanese word-based indexing, segmenta-\ntion was carried out primarily with chasen v2",
    "appliqu\u00e9e"
  ],
  [
    " as part of this, all japanese strings of\nlength 5 characters or less were extracted from\nthe dataset, and cross validation was performed\nover the residue, including the shorter strings in\nthe training data (i",
    "appliqu\u00e9e"
  ],
  [
    "\nso as to filter out any bias towards a given string\ncomparison method in tr, we determine transla-\ntion optimality based on both 3-operation edit dis-\ntance (operating over english word bigrams) and\nalso weighted sequential correspondence (operat-\ning over english word unigrams)",
    "appliqu\u00e9e"
  ],
  [
    "\nin the next step of evaluation, we took a random\nsample of 200 trecs from the original dataset, and\nran each of chasen, juman and altjaws over\nthe japanese component of each",
    "appliqu\u00e9e"
  ],
  [
    "0%\ntotal segment types 650 656 634\ntable 1: segmentation performance\njuman was katakana sequences such as ge?to-\nrokku-barubu ?gate-lock valve?, transcribed from\nenglish",
    "appliqu\u00e9e"
  ],
  [
    "\nfirst comparing character- and word-based in-\ndexing, we found that the disparity in retrieval\naccuracy was largely related to the scoring of\nkatakana words, which are significantly longer in\ncharacter length than native japanese words",
    "appliqu\u00e9e"
  ],
  [
    " a comparison of index-\ning techniques for japanese text retrieval",
    "appliqu\u00e9e"
  ],
  [
    " japanese morphological analysis sys-\ntem chasen version 2",
    "appliqu\u00e9e"
  ],
  [
    " a high-speed best\nmatch retrieval method for japanese text",
    "appliqu\u00e9e"
  ],
  [
    " an efficient way of gauging similar-\nity between long japanese expressions",
    "appliqu\u00e9e"
  ],
  [
    " learning curves for confusion set \ndisambiguation \n \n we collected a 1-billion-word training \ncorpus from a variety of english texts, including \nnews articles, scientific abstracts, government \ntranscripts, literature and other varied forms of \nprose",
    "appliqu\u00e9e"
  ],
  [
    " tagging english text with a \nprobabilistic model",
    "appliqu\u00e9e"
  ],
  [
    " decision lists for lexical \nambiguity resolution: application to accent \nrestoration in spanish and french ",
    "appliqu\u00e9e"
  ],
  [
    "1 pre-processing tools\nparser\nthe current version of the evaluation\nworkbench employs one of the high performance\n?super-taggers? for english - conexor?s fdg\nparser (tapanainen and ja?rvinen, 1997)",
    "appliqu\u00e9e"
  ],
  [
    "\nido dagan and alon itai",
    "appliqu\u00e9e"
  ],
  [
    " the results of a practi-\ncal evaluation of this method on a wide\ncoverage english grammar are given",
    "appliqu\u00e9e"
  ],
  [
    " last, in section 4,\nwe relate some experiments with a wide coverage\ntree-adjoining grammar [tag] for english",
    "appliqu\u00e9e"
  ],
  [
    "\n5 experiments with an english\ngrammar\nin order to compare a (normal) rcl parser and its\nguided versions, we looked for an existing wide-\ncoverage grammar",
    "appliqu\u00e9e"
  ],
  [
    " we chose the grammar for\nenglish designed for the xtag system (xtag,\n1995), because it both is freely available and\nseems rather mature",
    "appliqu\u00e9e"
  ],
  [
    "1 thus, we first had\nto transform that english tag into an equiva-\nlent rcg",
    "appliqu\u00e9e"
  ],
  [
    "\nfor our experiments, we first transformed the\nenglish xtag into an equivalent simple prcg:\nthe initial grammar ffi ",
    "appliqu\u00e9e"
  ],
  [
    " with a wide coverage english tag, on\na small sample set of short sentences, a guided\nparser is on the average three times faster than\nits non-guided counterpart, while, for longer sen-\ntences, more than one order of magnitude may be\nexpected",
    "appliqu\u00e9e"
  ],
  [
    " these savings\neven allow to consider the parsing of medium size\nsentences with the english xtag",
    "appliqu\u00e9e"
  ],
  [
    " a lexicalized tree\nadjoining grammar for english",
    "appliqu\u00e9e"
  ],
  [
    " we present an un-\nsupervised learning algorithm for iden-\ntification of paraphrases from a cor-\npus of multiple english translations of\nthe same source text",
    "appliqu\u00e9e"
  ],
  [
    " we use a\nlarge collection of multiple parallel english trans-\nlations of novels1",
    "appliqu\u00e9e"
  ],
  [
    "\nfigure 1: two english translations of the french\nsentence from flaubert?s ?madame bovary?\nour method for paraphrase extraction builds\nupon methodology developed in machine trans-\nlation (mt)",
    "appliqu\u00e9e"
  ],
  [
    "\n3 the data\nthe corpus we use for identification of para-\nphrases is a collection of multiple english trans-\nlations from a foreign source text",
    "appliqu\u00e9e"
  ],
  [
    "\nanother distinction between our corpus and\nparallel mt corpora is the irregularity of word\nmatchings: in mt, no words in the source lan-\nguage are kept as is in the target language trans-\nlation; for example, an english translation of\n2free of copyright restrictions part of\nour corpus(9 translations) is available at\nhttp://www",
    "appliqu\u00e9e"
  ],
  [
    "\na french source does not contain untranslated\nfrench fragments",
    "appliqu\u00e9e"
  ],
  [
    " the algorithm can identify paraphrasing re-\nlations only between words which occurred in our\ncorpus, which of course does not cover all english\ntokens",
    "appliqu\u00e9e"
  ],
  [
    "\n7 conclusions and future work\nin this paper, we presented a method for corpus-\nbased identification of paraphrases from multi-\nple english translations of the same source text",
    "appliqu\u00e9e"
  ],
  [
    " distributional clus-\ntering of english words",
    "appliqu\u00e9e"
  ],
  [
    "machine-learned contexts for linguistic operations \nin german sentence realization \n \nmichael gamon, eric ringger, simon corston-oliver, robert moore \nmicrosoft research  \nmicrosoft corporation \nredmond, wa 98052 \n{mgamon, ringger, simonco, bobmoore}@microsoft",
    "appliqu\u00e9e"
  ],
  [
    " our \nevidence consists of four examples from \nthe german sentence realization system \ncode-named amalgam: case \nassignment, assignment of verb position \nfeatures, extraposition, and syntactic \naggregation \n1 introduction \nthe last stage of natural language generation, \nsentence realization, creates the surface string \nfrom an abstract (typically semantic) \nrepresentation",
    "appliqu\u00e9e"
  ],
  [
    " \n4 assignment of case \nin german sentence realization, proper \nassignment of morphological case is essential for \nfluent and comprehensible output",
    "appliqu\u00e9e"
  ],
  [
    " german is a \nlanguage with fairly free constituent order, and the \nidentification of functional roles, such as subject \nversus object, is not determined by position in the \nsentence, as in english, but by morphological \nmarking of one of the four cases: nominative, \naccusative, genitive or dative",
    "appliqu\u00e9e"
  ],
  [
    " morphological realization of case \ncan be ambiguous in german (for example, a \nfeminine singular np is ambiguous between \naccusative and nominative case)",
    "appliqu\u00e9e"
  ],
  [
    " \nmorphological case, it has four possible values for \nthe four cases in german",
    "appliqu\u00e9e"
  ],
  [
    "9352 \n5 assignment of verb position \nfeatures \none of the most striking properties of german is \nthe distributional pattern of verbs in main and \nsubordinate clauses",
    "appliqu\u00e9e"
  ],
  [
    " most descriptive accounts of \ngerman syntax are based on a topology of the \ngerman sentence that treats the position of the \nverb as the fixed frame around which other \nsyntactic constituents are organized in relatively \nfree order (cf",
    "appliqu\u00e9e"
  ],
  [
    " the \nposition of the verb in german is non-negotiable; \nerrors in the positioning of the verb result in \ngibberish, whereas most permutations of other \nconstituents only result in less fluent output",
    "appliqu\u00e9e"
  ],
  [
    " \ndepending on the position of the finite verb, \ngerman sentences and verb phrases are classified \nas being ?verb-initial?, ?verb-second? or ?verb-\nfinal?",
    "appliqu\u00e9e"
  ],
  [
    "9491 \n6 extraposition \nin both german and english it is possible to \nextrapose clausal material to the right periphery of \nthe sentence (extraposed clauses underlined in the \nexamples below): \nrelative clause extraposition: \nenglish: a man just left who had come to \nask a question",
    "appliqu\u00e9e"
  ],
  [
    " \nthe interesting difference between english and \ngerman is the frequency of this phenomenon",
    "appliqu\u00e9e"
  ],
  [
    " \nwhile it can easily be argued that english \nsentence realization may ignore extraposition and \nstill result in very fluent output, the fluency of \nsentence realization for german will suffer much \nmore from the lack of a good extraposition \nmechanism",
    "appliqu\u00e9e"
  ],
  [
    " in the technical domain, more \nthan one third of german relative clauses are \nextraposed, as compared to a meagre 0",
    "appliqu\u00e9e"
  ],
  [
    "22% of \nenglish relative clauses",
    "appliqu\u00e9e"
  ],
  [
    " in encyclopaedia text \n(microsoft encarta), approximately every fifth \ngerman relative clause is extraposed, compared to \nonly 0",
    "appliqu\u00e9e"
  ],
  [
    "3% of english relative clauses",
    "appliqu\u00e9e"
  ],
  [
    " for \ncomplement clauses and infinitival clauses, the \ndifferences are not as striking, but still significant: \nin the technical and encyclopaedia domains, \nextraposition of infinitival and complement \nclauses in german ranges from 1",
    "appliqu\u00e9e"
  ],
  [
    "2%, \nwhereas english only shows a range from 0% to \n0",
    "appliqu\u00e9e"
  ],
  [
    " while this may seem a fairly \nstraightforward task compared to inter-sentential, \nsemantic and lexical aggregation, it should be \nnoted that the cross-linguistic complexity of the \nphenomenon makes it much less trivial than a first \nglance at english would suggest",
    "appliqu\u00e9e"
  ],
  [
    "  \nwe are currently adapting amalgam to the task \nof french sentence realization, as a test of the \nlinguistic generality of the system",
    "appliqu\u00e9e"
  ],
  [
    " extraposition: a case study \nin german sentence realization",
    "appliqu\u00e9e"
  ],
  [
    " 1988 the syntactic phenomena of \nenglish",
    "appliqu\u00e9e"
  ],
  [
    "  simple extensions could be \nmade to the system so that instead of \nsearching in the range of 50 bytes for the \nanswer phrase it could search for the answer \nin the range of 1? 2 chunks (basic phrases in \nenglish such as simple np, vp, pp, etc",
    "appliqu\u00e9e"
  ],
  [
    "\nthe comparison-based setup of ot learning is\nclosely related to discriminative learning approaches\nin probabilistic parsing (johnson et al, 1999; rie-\nzler et al, 2000; riezler et al, 2002),1 however the\ncomparison of generation alternatives ? rather than\nparsing alternatives ? adds the possibility of system-\natically learning the basic language-specific gram-\nmatical principles (which in probabilistic parsing\nare typically fixed a priori, using either a treebank-\nderived or a manually written grammar for the given\n\u000e\nthis work was supported by a postdoctoral fellowship of\nthe german academic exchange service (daad)",
    "appliqu\u00e9e"
  ],
  [
    " it\nis for this very reason, that who do you know is pre-\ndicted to be grammatical in english",
    "appliqu\u00e9e"
  ],
  [
    " soft constraints mirror hard constraints: voice\nand person in english and lummi",
    "appliqu\u00e9e"
  ],
  [
    " experimental results\non english basenp chunking, japanese\nword segmentation and japanese depen-\ndency parsing show that our new classi-\nfiers are about 30 to 300 times faster than\nthe standard kernel-based classifiers",
    "appliqu\u00e9e"
  ],
  [
    " examples\ninclude part-of-speech tagging (nakagawa et al,\n2002) text chunking (kudo and matsumoto, 2001),\nnamed entity recognition (isozaki and kazawa,\n2002), and japanese dependency parsing (kudo and\nmatsumoto, 2000; kudo and matsumoto, 2002)",
    "appliqu\u00e9e"
  ],
  [
    "\nexperiments on english basenp chunking,\njapanese word segmentation and japanese depen-\ndency parsing show that pki and pke perform re-\nspectively 2 to 13 times and 30 to 300 times faster\nthan standard kernel-based systems, without a dis-\ncernible change in accuracy",
    "appliqu\u00e9e"
  ],
  [
    "\n5 experiments\nto demonstrate performances of pki and pke, we\nexamined three nlp tasks: english basenp chunk-\ning (ebc), japanese word segmentation (jws) and\n\u0000\u0002\u0001\u0004\u0003\n\u0000\u0002\u0005\u0006\u0003\n\u0000\u0002\u0001\b\u0007 \t\u0004\u0003\n\u0000\u0002\u0001\b\u0007 \n\u000b\u0003\n\u0000\u0004\t\b\u0007 \n\u000b\u0003\n\u0000\u0004\t\b\u0007 \u0005\u0006\u0003\n\u0000\u0002\n\u000b\u0007 \u0005\u0006\u0003\n\u0000\u0004\t\b\u0007 \n\f\u0007 \u0005\u0006\u0003\n\n\f\u000e\u0010\u000f \u0011\n\u0012\n\n\u000b\u000e\u0010\u000f \u0011\n\n\u000b\u0013\n\n\u000b\u0013\n\u0012\n\n\u000b\u0013\n\u0012\n\n\f\u0014\n\u0012\n\u0013\u0002\u0015\n\u0012\n\n\u000b\u0013\n\u0016\u0018\u0017\u001a\u0019\u0004ff\nfi fl\nffi\nffi \u001f \u001f\nfl\n\u001f\nfl\nfl\n!#\"$\"&%\n'\u001a(#) *\n'\u001a+,'-+\n",
    "appliqu\u00e9e"
  ],
  [
    "\n'-+\ns\n1\nfigure 2: ? in trie representation\njapanese dependency parsing (jdp)",
    "appliqu\u00e9e"
  ],
  [
    "1 english basenp chunking (ebc)\ntext chunking is a fundamental task in nlp ? divid-\ning sentences into non-overlapping phrases",
    "appliqu\u00e9e"
  ],
  [
    "2 japanese word segmentation (jws)\nsince there are no explicit spaces between words in\njapanese sentences, we must first identify the word\nboundaries before analyzing deep structure of a sen-\ntence",
    "appliqu\u00e9e"
  ],
  [
    " japanese word segmentation is formalized as\na simple classification task",
    "appliqu\u00e9e"
  ],
  [
    "\nlet s = c1c2 ? ? ? cm be a sequence of japanese\ncharacters, t = t1t2 ? ? ? tm be a sequence of japanese\ncharacter types 3 associated with each character,\nand yi ? {+1,?1}, (i = (1, 2, ",
    "appliqu\u00e9e"
  ],
  [
    "3 japanese dependency parsing (jdp)\nthe task of japanese dependency parsing is to iden-\ntify a correct dependency of each bunsetsu (base\nphrase in japanese)",
    "appliqu\u00e9e"
  ],
  [
    " in previous research, we pre-\nsented a state-of-the-art svms-based japanese de-\npendency parser (kudo and matsumoto, 2002)",
    "appliqu\u00e9e"
  ],
  [
    " we\nuse a standard data set, which is the same corpus de-\nscribed in the japanese word segmentation",
    "appliqu\u00e9e"
  ],
  [
    "\n3usually, in japanese, word boundaries are highly con-\nstrained by character types, such as hiragana and katakana\n(both are phonetic characters in japanese), chinese characters,\nenglish alphabets and numbers",
    "appliqu\u00e9e"
  ],
  [
    " japanese dependency\nstructure analysis based on support vector machines",
    "appliqu\u00e9e"
  ],
  [
    " japanese dependency\nanalyisis using cascaded chunking",
    "appliqu\u00e9e"
  ],
  [
    "\nn\na?bdcfebgjifk\na$bdcfeeg9i\na?b?c?edcfiak7a$bdgledgji\n(14)\n4 experiments\nwe evaluated the performance of the proposed\nmethod in an actual application of nlp; the data set\nis written in japanese",
    "appliqu\u00e9e"
  ],
  [
    " the semantic attribute system, goi-\ntaikei ? a japanese lexicon, volume 1",
    "appliqu\u00e9e"
  ],
  [
    " japanese depen-\ndency analysis using cascaded chunking",
    "appliqu\u00e9e"
  ],
  [
    " as a\nsubgoal, this involves creating a prob-\nabilistic wsd system, which we eval-\nuate on the senseval-2 english all-\nwords task data",
    "appliqu\u00e9e"
  ],
  [
    " we carry out an eval-\nuation of the enriched subcategoriza-\ntion acquisition system using 29 dif-\nficult english verbs which shows that\nwsd helps to improve the acquisition\nperformance",
    "appliqu\u00e9e"
  ],
  [
    " we intro-\nduce a new probabilistic combination wsd sys-\ntem, which produces probability distributions\non senses, and we show that the system per-\nforms comparably on the senseval-2 english\nall-words task data (palmer et al",
    "appliqu\u00e9e"
  ],
  [
    " we trained all modules\n(except tagger and frequency which are not\ntrained) on semcor, the english all-words sen-\nseval-2 task test data and all data for the en-\nglish lexical sample senseval-2 task",
    "appliqu\u00e9e"
  ],
  [
    "\n\nwe decided on the optimal combination of\nmodules based on the accuracy (f-measure) on\nthe english all-words task (for this evaluation,\nthe system was trained on all corpora apart from\nthe english all-words task)",
    "appliqu\u00e9e"
  ],
  [
    "55% on the english all-\nwords task",
    "appliqu\u00e9e"
  ],
  [
    " this would place the system in the\nthird place (f-measure) in the english all-words\ntask (initial results)",
    "appliqu\u00e9e"
  ],
  [
    " large\nlexicons for natural language processing utilising\nthe grammar coding system of the longman dic-\ntionary of contemporary english",
    "appliqu\u00e9e"
  ],
  [
    " english verb classes and alterna-\ntions",
    "appliqu\u00e9e"
  ],
  [
    " english tasks: all-words\nand verb lexical sample",
    "appliqu\u00e9e"
  ],
  [
    " automatic extrac-\ntion of subcategorization frames for czech",
    "appliqu\u00e9e"
  ],
  [
    "uk\nzvika marx\ninterdisciplinary center\nfor neural computation,\nthe hebrew university\njerusalem, israel\nzvim@cs",
    "appliqu\u00e9e"
  ],
  [
    " pre-\nvious research has demonstrated that clustering\ncan be useful in inferring levin-style semantic\nclasses (levin, 1993) from both english and ger-\nman verb subcategorization information (brew and\nschulte im walde, 2002; schulte im walde, 2000;\nschulte im walde and brew, 2002)",
    "appliqu\u00e9e"
  ],
  [
    " the derivation of a grammatically-\nindexed lexicon from the longman dictionary of con-\ntemporary english",
    "appliqu\u00e9e"
  ],
  [
    " spectral clus-\ntering for german verbs",
    "appliqu\u00e9e"
  ],
  [
    " english verb classes and alternations",
    "appliqu\u00e9e"
  ],
  [
    "jp\nabstract\nwe have aligned japanese and english\nnews articles and sentences to make a\nlarge parallel corpus",
    "appliqu\u00e9e"
  ],
  [
    " we first used a\nmethod based on cross-language informa-\ntion retrieval (clir) to align the japanese\nand english articles and then used a\nmethod based on dynamic programming\n(dp) matching to align the japanese and\nenglish sentences in these articles",
    "appliqu\u00e9e"
  ],
  [
    "\nwe recently have obtained a noisy parallel cor-\npus of japanese and english newspapers consisting\nof issues published over more than a decade and\nhave tried to align their articles and sentences",
    "appliqu\u00e9e"
  ],
  [
    "\nin this paper, we first discuss the basic statistics\non the japanese and english newspapers",
    "appliqu\u00e9e"
  ],
  [
    "\n2 newspapers aligned\nthe japanese and english newspapers used as\nsource data were the yomiuri shimbun and the daily\nyomiuri",
    "appliqu\u00e9e"
  ],
  [
    " the number of japanese\narticles per year ranges from 100,000 to 350,000,\nwhile english articles ranges from 4,000 to 13,000",
    "appliqu\u00e9e"
  ],
  [
    "\nthe total number of japanese articles is about\n2,000,000 and the total number of english articles is\nabout 110,000",
    "appliqu\u00e9e"
  ],
  [
    " the number of english articles rep-\nresents less than 6 percent that of japanese articles",
    "appliqu\u00e9e"
  ],
  [
    "\ntherefore, we decided to search for the japanese ar-\nticles corresponding to each of the english articles",
    "appliqu\u00e9e"
  ],
  [
    "\nthe english articles as of mid-july 1996 have tags\nindicating whether they are translated from japanese\narticles or not, though they don?t have explicit links\nto the original japanese articles",
    "appliqu\u00e9e"
  ],
  [
    " consequently, we\nonly used the translated english articles for the arti-\ncle alignment",
    "appliqu\u00e9e"
  ],
  [
    " the number of english articles used\nwas 35,318, which is 68 percent of all of the arti-\ncles",
    "appliqu\u00e9e"
  ],
  [
    " on the other hand, the english articles before\nmid-july 1996 do not have such tags",
    "appliqu\u00e9e"
  ],
  [
    "?\nif an english article is a translation of a japanese\narticle, then the publication date of the japanese ar-\nticle will be near that of the english article",
    "appliqu\u00e9e"
  ],
  [
    " so we\nsearched for the original japanese articles within 2\ndays before and after the publication of each english\narticle, i",
    "appliqu\u00e9e"
  ],
  [
    ", the corresponding article of an english\narticle was searched for from the japanese articles of\n5 days? issues",
    "appliqu\u00e9e"
  ],
  [
    " the average number of english arti-\ncles per day was 24 and that of japanese articles per\n5 days was 1,532 for 1989-1996",
    "appliqu\u00e9e"
  ],
  [
    " for 1996-2001, the\naverage number of english articles was 18 and that\nof japanese articles was 2,885",
    "appliqu\u00e9e"
  ],
  [
    " as there are many\ncandidates for alignment with english articles, we\nneed a reliable measure to estimate the validity of\narticle alignments to search for appropriate japanese\narticles from these ambiguous matches",
    "appliqu\u00e9e"
  ],
  [
    "\ncorrect article alignment does not guarantee the\nexistence of one-to-one correspondence between\nenglish and japanese sentences in article alignment\nbecause literal translations are exceptional",
    "appliqu\u00e9e"
  ],
  [
    " original\njapanese articles may be restructured to conform to\nthe style of english newspapers, additional descrip-\ntions may be added to fill cultural gaps, and detailed\ndescriptions may be omitted",
    "appliqu\u00e9e"
  ],
  [
    " a typical example of a\nrestructured english and japanese article pair is:\npart of an english article: ?e1? two bullet holes were found at\nthe home of kengo tanaka, 65, president of bungei shunju, in ak-\nabane, tokyo, by his wife kimiko, 64, at around 9 a",
    "appliqu\u00e9e"
  ],
  [
    " ?/e4?\npart of a literal translation of a japanese article: ?j1? at about\n8:55 a",
    "appliqu\u00e9e"
  ],
  [
    "\nsuch sentence matches are of particular interest\nto researchers studying human translations and/or\nstylistic differences between english and japanese\nnewspapers",
    "appliqu\u00e9e"
  ],
  [
    " first, we use a method based on clir\nto align japanese and english articles (collier et\nal",
    "appliqu\u00e9e"
  ],
  [
    ", 1998; matsumoto and tanaka, 2002) and then\na method based on dp matching to align japanese\nand english sentences (gale and church, 1993; ut-\nsuro et al, 1994) in these articles",
    "appliqu\u00e9e"
  ],
  [
    "1 article alignment\ntranslation of words\nwe first convert each of the japanese articles into\na set of english words",
    "appliqu\u00e9e"
  ],
  [
    " we use chasen1 to seg-\nment each of the japanese articles into words",
    "appliqu\u00e9e"
  ],
  [
    " we\nnext extract content words, which are then translated\ninto english words by looking them up in the edr\njapanese-english bilingual dictionary,2 edict, and\nenamdict,3 which have about 230,000, 100,000,\n1http://chasen",
    "appliqu\u00e9e"
  ],
  [
    " we select two en-\nglish words for each of the japanese words using\nsimple heuristic rules based on the frequencies of\nenglish words",
    "appliqu\u00e9e"
  ],
  [
    "\narticle retrieval\nwe use each of the english articles as a query and\nsearch for the japanese article that is most similar\nto the query article",
    "appliqu\u00e9e"
  ],
  [
    " the similarity between an en-\nglish article and a (word-based english translation\nof) japanese article is measured by bm25 (robert-\nson and walker, 1994)",
    "appliqu\u00e9e"
  ],
  [
    "\nthe definition of bm25 is:\nbm25(j,e) =\n?\nt?e\nw(1) (k1 + 1)tfk + tf\n(k3 + 1)qtf\nk3 + qtf\nwhere\nj is the set of translated english words of a\njapanese article and e is the set of words of an\nenglish article",
    "appliqu\u00e9e"
  ],
  [
    "\nn is the number of japanese articles to be searched",
    "appliqu\u00e9e"
  ],
  [
    "\nto summarize, we first translate each of the\njapanese articles into a set of english words",
    "appliqu\u00e9e"
  ],
  [
    " we\nthen use each of the english articles as a query and\nsearch for the most similar japanese article in terms\nof bm25 and assume that it corresponds to the en-\nglish article",
    "appliqu\u00e9e"
  ],
  [
    "2 sentence alignment\nthe sentences5 in the aligned japanese and english\narticles are aligned by a method based on dp match-\ning (gale and church, 1993; utsuro et al, 1994)",
    "appliqu\u00e9e"
  ],
  [
    "gov/\n5we split the japanese articles into sentences by using sim-\nple heuristics and split the english articles into sentences by\nusing mxterminator (reynar and ratnaparkhi, 1997)",
    "appliqu\u00e9e"
  ],
  [
    " here, we only discuss the similarities\nbetween japanese and english sentences for align-\nment",
    "appliqu\u00e9e"
  ],
  [
    " let ji and ei be the words of japanese and\nenglish sentences for i-th alignment",
    "appliqu\u00e9e"
  ],
  [
    "\nco(ji ? ei) =\n?\n(j,e)?ji?ei min(f(j), f(e))\nji ? ei = {(j, e)|j ? ji, e ? ei} and ji ? ei is\na one-to-one correspondence between japanese and\nenglish words",
    "appliqu\u00e9e"
  ],
  [
    " we use chasen to\nmorphologically analyze the japanese sentences and\nextract content words, which consists of ji",
    "appliqu\u00e9e"
  ],
  [
    " we use\nbrill?s tagger (brill, 1992) to pos-tag the english\nsentences, extract content words, and use word-\nnet?s library7 to obtain lemmas of the words, which\nconsists of ei",
    "appliqu\u00e9e"
  ],
  [
    ", a one-to-one correspondence between\nthe words in ji and ei, by looking up japanese-\nenglish and english-japanese dictionaries made up\nby combining entries in the edr japanese-english\nbilingual dictionary and the edr english-japanese\nbilingual dictionary",
    "appliqu\u00e9e"
  ],
  [
    "\nwe evaluated the implemented program against a\ncorpus consisting of manually aligned japanese and\nenglish sentences",
    "appliqu\u00e9e"
  ],
  [
    " the source texts were japanese\nwhite papers (jeida, 2000)",
    "appliqu\u00e9e"
  ],
  [
    " the average number of japanese sentences\nper text was 413 and that of english sentences was\n495",
    "appliqu\u00e9e"
  ],
  [
    "\nthis recall and precision are quite good consid-\nering the relatively large differences in the language\nstructures between japanese and english",
    "appliqu\u00e9e"
  ],
  [
    "\nwe define avsim(j,e) as the similarity between\njapanese article, j , and english article, e:\navsim(j,e) =\n?m\nk=1 sim(jk, ek)\nm\nwhere (j1, e1), (j2, e2), ",
    "appliqu\u00e9e"
  ],
  [
    "\nour sentence alignment program aligns sentences\naccurately if the english sentences are literal trans-\nlations of the japanese as discussed in section 3",
    "appliqu\u00e9e"
  ],
  [
    "\nhowever, the relation between english news sen-\ntences and japanese news sentences are not literal\ntranslations",
    "appliqu\u00e9e"
  ],
  [
    "\nrandomly sampled article alignments\neach english article was aligned with a japanese\narticle with the highest bm25",
    "appliqu\u00e9e"
  ],
  [
    " this is because the en-\nglish articles from 1996-2001 were translations of\njapanese articles, while those from 1989-1996 were\nnot necessarily translations as explained in section\n2",
    "appliqu\u00e9e"
  ],
  [
    " in the first step, we classified whole one-\nto-one alignments into two classes: the first con-\nsisted of alignments whose japanese and english\nsentences ended with periods, question marks, ex-\nclamation marks, or other readily identifiable char-\nacteristics",
    "appliqu\u00e9e"
  ],
  [
    " we judged a sample as ?a? if the japanese and\nenglish sentences of the sample shared a common\nevent (approximately a clause)",
    "appliqu\u00e9e"
  ],
  [
    " col-\nlier et al (1998) compared the use of machine trans-\nlation (mt) with the use of bilingual dictionary term\nlookup (dtl) for news article alignment in japanese\nand english",
    "appliqu\u00e9e"
  ],
  [
    "11 these\n11we translated the english articles into japanese with an mt\nsystem",
    "appliqu\u00e9e"
  ],
  [
    " we then used the translated english articles as queries\nand searched the database consisting of japanese articles",
    "appliqu\u00e9e"
  ],
  [
    "\nmatsumoto and tanaka (2002) attempted to align\njapanese and english news articles in the nikkei in-\ndustrial daily",
    "appliqu\u00e9e"
  ],
  [
    " a\nfew requests were from high-school and junior-high-\nschool teachers of english",
    "appliqu\u00e9e"
  ],
  [
    "\nwe have applied our measures to a japanese and\nenglish bilingual corpus and these are language in-\ndependent",
    "appliqu\u00e9e"
  ],
  [
    " it is therefore reasonable to expect that\nthey can be applied to any language pair and still re-\ntain good performance, particularly since their effec-\ntiveness has been demonstrated in such a disparate\nlanguage pair as japanese and english",
    "appliqu\u00e9e"
  ],
  [
    " automatic align-\nment of japanese and english newspaper articles using an\nmt system and a bilingual company name dictionary",
    "appliqu\u00e9e"
  ],
  [
    " the dialogs were typed in german",
    "appliqu\u00e9e"
  ],
  [
    "\ntr-2000-09, charles university, prague, czech republic",
    "appliqu\u00e9e"
  ],
  [
    " of the 4th international conference\non text, speech and dialogue (tsd?2001), ?zelezn a? ruda,\nczech republic",
    "appliqu\u00e9e"
  ],
  [
    " thesis, institute of formal and\napplied linguistics ( ?ufal), faculty of mathematics and\nphysics, charles university, prague, czech republic",
    "appliqu\u00e9e"
  ],
  [
    " of the 7th international conference\non text, speech and dialogue (tsd?04), brno, czech re-\npublic, springer",
    "appliqu\u00e9e"
  ],
  [
    " the banking corpus of several hundred \ncalls has been collected first and it forms the basis \nof our initial multilingual triaging application, \nimplemented for english, french and german \n(hardy et al, 2003a); as well as our prototype \nautomatic financial services system, presented in \nthis paper, which completes a variety of tasks in \nenglish",
    "appliqu\u00e9e"
  ],
  [
    " the much larger software support corpus \n(10,000 calls in english and french) is still being \ncollected and processed and will be used to \ndevelop the next amiti?s prototype",
    "appliqu\u00e9e"
  ],
  [
    " second, we report higher per-\nformance than the previous best results on syntactic\nchunking (the conll?00 corpus) and named entity\nchunking (the conll?03 english and german cor-\npora)",
    "appliqu\u00e9e"
  ],
  [
    "\nfigure 4 shows results in comparison with the su-\npervised baseline in six configurations, each trained\n6\nwith one of three sets of labeled training examples: a\nsmall english set (10k examples randomly chosen),\nthe entire english training set (204k), and the entire\ngerman set (207k), tested on either the development\nset or test set",
    "appliqu\u00e9e"
  ],
  [
    "\ncomparison with top systems as shown in fig-\nure 5, aso-semi achieves higher performance than\nthe top systems on both english and german\ndata",
    "appliqu\u00e9e"
  ],
  [
    "1 effectiveness of auxiliary problems\nenglish named entity         german named entity\n68\n70\n72\n74\n76\n1\nf-\nm\nea\nsu\nre\n \n(%\n)\n85\n86\n87\n88\n89\n90\ndev set\nf-\nm\nea\nsu\nre\n \n(%\n)\nsupervised\nw/ \"predict (previous, current, or next) words\"\nw/ \"predict top-2 choices\"\nw/ \"predict words\" + \"predict top-2 choices\"\nfigure 9: named entity f-measure produced by using individ-\nual types of auxiliary problems",
    "appliqu\u00e9e"
  ],
  [
    "2 interpretation of \u0002\nto gain insights into the information obtained from\nunlabeled data, we examine the \u0002 entries associated\nwith the feature ?current words?, computed for the\nenglish named entity task",
    "appliqu\u00e9e"
  ],
  [
    "\nenglish named entity chunking, test set",
    "appliqu\u00e9e"
  ],
  [
    " tagging english text with\na probabilistic model",
    "appliqu\u00e9e"
  ],
  [
    "\n3 previous work\na considerable amount of research addresses structurally\nand statistically manipulating the hierarchy of word-\nnet and the construction of new wordnets using the con-\ncept structure from english",
    "appliqu\u00e9e"
  ],
  [
    " the ldc has recently re-\nleased the english gigaword corpus which includes most\nof the corpora listed above",
    "appliqu\u00e9e"
  ],
  [
    " ap-\nplied morphological processing of english",
    "appliqu\u00e9e"
  ],
  [
    " in\nthe typical setting, supervised learning needs train-\ning data created for each and every polysemous\nword; ng (1997) estimates an effort of 16 person-\nyears for acquiring training data for 3,200 significant\nwords in english",
    "appliqu\u00e9e"
  ],
  [
    " mihalcea and chklovski (2003)\nprovide a similar estimate of an 80 person-year ef-\nfort for creating manually labelled training data for\nabout 20,000 words in a common english dictionary",
    "appliqu\u00e9e"
  ],
  [
    "\nto simulate this classifier on senseval english\nall-words tasks? data (edmonds and cotton, 2001;\nsnyder and palmer, 2004), we mapped the fine-\ngrained senses from official answer keys to their\nrespective beginners",
    "appliqu\u00e9e"
  ],
  [
    " in\nprincipal, this is the most likely sense within the\nclass, because wordnet senses are said to be\n\u0001\u0002\u0003\u0001\u0002\n\u0004\u0001\u0002\u0005\u0001\u0002\n\u0006\u0001\u0002\u0007\u0001\u0002\n\b\u0001\u0002\t\u0001\u0002\n\n\u0001\u0002\u000b\u0001\u0002\n\u0003\u0001\u0001\u0002\n\f\u0004\n\u000e\u000f\u0010\u000e\u0011 \f\u0004\n\u0012\u0013\u0014\u0015\u0011 \f\u0005\n\u000e\u000f\u0010\u000e\u0011 \f\u0005\n\u0012\u0013\u0014\u0015\u0011\n\u0016\u0017\u0018\u0017\u0018\u0019\nfigure 1: performance of a hypothetical coarse-\ngrained classifier, output mapped to fine-grained\nsenses, on senseval english all-words tasks",
    "appliqu\u00e9e"
  ],
  [
    "\nfigure 1 shows the performance of this trans-\nformed fine-grained classifier (cg) for nouns and\nverbs with senseval-2 and 3 english all words\ntask data (marked as s2 and s3 respectively),\nalong with the baseline wordnet first sense (bl),\nand the best-performer classifiers at each sense-\nval excercise (cl), smuaw (mihalcea, 2002) and\ngambl-aw (decadt et al, 2004) respectively",
    "appliqu\u00e9e"
  ],
  [
    ", 1993) and senseval english all-words task\ndata",
    "appliqu\u00e9e"
  ],
  [
    " testing data\nsets from senseval-2 and senseval-3 english\nall-words tasks were used as testing corpora",
    "appliqu\u00e9e"
  ],
  [
    "636\ntable 7: results for senseval-2 english all words\ndata for all parts of speech and fine grained scoring",
    "appliqu\u00e9e"
  ],
  [
    "642\ntable 8: results for senseval-3 english all words\ndata for all parts of speech and fine grained scoring",
    "appliqu\u00e9e"
  ],
  [
    " parsing english with\na link grammar",
    "appliqu\u00e9e"
  ],
  [
    " the english all-words\ntask",
    "appliqu\u00e9e"
  ],
  [
    " our system performs at\nthe best published accuracy on the english\nverbs of senseval-2",
    "appliqu\u00e9e"
  ],
  [
    " the system performs at the best published\naccuracy on the english verbs of the senseval-2\n(palmer et al, 2001) exercise on evaluating au-\ntomatic wsd systems",
    "appliqu\u00e9e"
  ],
  [
    "3 evaluation\nwe tested the system on the 1806 test instances of\nthe 29 verbs from the english lexical sample task for\nsenseval-2 (palmer et al, 2001)",
    "appliqu\u00e9e"
  ],
  [
    " our\nsystem performs at the best published accuracy on\nthe english verbs of senseval-2 even though our\nheuristics for extracting syntactic features fail to\nidentify all and only the arguments of a verb",
    "appliqu\u00e9e"
  ],
  [
    " english verb classes and alterna-\ntions: a preliminary investigation",
    "appliqu\u00e9e"
  ],
  [
    " english\ntasks: all-words and verb lexical sample",
    "appliqu\u00e9e"
  ],
  [
    "\nthen, a sentence realizer, realpro (lavoie and ram-\nbow, 1997), transforms them into english sentences",
    "appliqu\u00e9e"
  ],
  [
    " an empir-\nical study on the generation of anaphora in chinese",
    "appliqu\u00e9e"
  ],
  [
    "\nrecent publications on the effect of morphol-\nogy on smt quality focused on morphologically\nrich languages such as german (nie?en and ney,\n2004); spanish, catalan, and serbian (popovic?\n1\nand ney, 2004); and czech (goldwater and mc-\nclosky, 2005)",
    "appliqu\u00e9e"
  ],
  [
    "\nspecifically considering arabic, lee (2004) in-\nvestigated the use of automatic alignment of pos\ntagged english and affix-stem segmented ara-\nbic to determine appropriate tokenizations",
    "appliqu\u00e9e"
  ],
  [
    "\nenglish the president will finish his tour with a visit to turkey",
    "appliqu\u00e9e"
  ],
  [
    " the\nlatter is modeled after the english penn pos tag\nset",
    "appliqu\u00e9e"
  ],
  [
    " this scheme is intended to\nminimize differences between arabic and english",
    "appliqu\u00e9e"
  ],
  [
    "3\nwe created the english language model from\nthe english side of the parallel corpus together\n3the parallel text includes arabic news (ldc2004t17),\netirr (ldc2004e72), english translation of arabic tree-\nbank (ldc2005e46), and ummah (ldc2004t18)",
    "appliqu\u00e9e"
  ],
  [
    "\nwith 116 million words the english gigaword\ncorpus (ldc2005t12) and 128 million words\nfrom the english side of the un parallel corpus\n(ldc2004e13)",
    "appliqu\u00e9e"
  ],
  [
    "4\nenglish preprocessing simply included lower-\ncasing, separating punctuation from words and\nsplitting off ??s?",
    "appliqu\u00e9e"
  ],
  [
    " the same preprocessing was\nused on the english data for all experiments",
    "appliqu\u00e9e"
  ],
  [
    " the data sets,\nmt03 and mt04, include one arabic source and\nfour english reference translations",
    "appliqu\u00e9e"
  ],
  [
    " these re-\nsults are not english case sensitive",
    "appliqu\u00e9e"
  ],
  [
    " for\ninstance, the phrase link (i1, i2, j1, j2) indicates\nthat the english phrase ei1 , ",
    "appliqu\u00e9e"
  ],
  [
    "\nchinese arabic\nalign",
    "appliqu\u00e9e"
  ],
  [
    "\nthe sri language modeling toolkit was used\nto train a trigrammodel with modified kneser-ney\nsmoothing on 155m words of english newswire\ntext, mostly from the xinhua portion of the gi-\ngaword corpus",
    "appliqu\u00e9e"
  ],
  [
    " during decoding, the number of\nenglish phrases per fl phrase was limited to 100\nand phrase distortion was limited to 4",
    "appliqu\u00e9e"
  ],
  [
    "1 bleu score comparison\ntable 4 presents the bleu scores for pharaoh runs\non chinese with five different alignments using\ndifferent settings for maximum phrase length (3\nvs",
    "appliqu\u00e9e"
  ],
  [
    " for ex-\nample, using a modified lexical weighting, the sys-\ntems are ranked according to their bleu scores as\nfollows: sb, sa, sg, si, su?an ordering that dif-\nfers from that of aer but is identical to that of\ncper (with a phrase length of 3) for chinese",
    "appliqu\u00e9e"
  ],
  [
    "\nchinese arabic\nalignment loose tight loose tight\nsg 24",
    "appliqu\u00e9e"
  ],
  [
    " figure 2 shows the per-\ncentage of untranslated words in the fl using the\nchinese and arabic nist mteval?2003 test sets",
    "appliqu\u00e9e"
  ],
  [
    " si behaves\nquite differently, leaving nearly 7% of the words\nuntranslated?an indicator of why it produces a\nhigher bleu score on chinese but a lower score\non arabic compared to other alignments",
    "appliqu\u00e9e"
  ],
  [
    " as a result, for\nboth languages, su and sg yield a much smaller\nchinese arabic\nalignment mpl=3 mpl=7 mpl=3 mpl=7\nsu 106 122 32 38\nsg 161 181 48 55\nsi 1331 3498 377 984\nsa 954 1856 297 594\nsb 876 1624 262 486\ntable 7: number of phrases in the phrase table filtered for\nmteval?2003 test sets (in thousands)\nphrase table than the other three alignments",
    "appliqu\u00e9e"
  ],
  [
    "\ndistribution of phrases to investigate how the\ndecoder chooses phrases of different lengths, we\nanalyzed the distribution of the phrases in the fil-\ntered phrase table and the phrases that were used\nto decode chinese mteval?2003 test set",
    "appliqu\u00e9e"
  ],
  [
    " the ?j-i? designators correspond\nto the phrase pairs with j fl words and i english\nwords",
    "appliqu\u00e9e"
  ],
  [
    " for\nsi, nearly 62% of the phrases contain more than 3\nwords on either fl or english side; for sa and sb,\nthis percentage is around 45-50%",
    "appliqu\u00e9e"
  ],
  [
    "\nthe bottom row of figure 3 shows the per-\ncentage of phrases used to decode the chinese\nmteval?2003 test set",
    "appliqu\u00e9e"
  ],
  [
    " for all five alignments, the ma-\njority of the used phrases is one-to-one (between\n5due to lack of space, we will present results on chinese-\nenglish only in the rest of this paper but the arabic-english\nresults show the same trends",
    "appliqu\u00e9e"
  ],
  [
    "\n14\nfigure 3: distribution of the phrases in the phrase table\nfiltered for chinese mteval?2003 test set (top row) and the\nphrases used in decoding the same test set (bottom row) ac-\ncording to their lengths\n50-65% of the total number of phrases used in de-\ncoding)",
    "appliqu\u00e9e"
  ],
  [
    " table 8 presents the average\nnumber of english and fl words in the phrases\nused in decoding chinese mteval?2003 test set",
    "appliqu\u00e9e"
  ],
  [
    " the number of\nenglish words per phrase is also higher for these\nthree systems than the other two",
    "appliqu\u00e9e"
  ],
  [
    "52\ntable 8: the average length of the phrases that are used in\ndecoding chinese mteval?2003 test set\nthe coverage of the chinese mteval?2003 test set\n(source side) using only phrases of a particular\nlength (from 1 to 7)",
    "appliqu\u00e9e"
  ],
  [
    "9\ntable 9: coverage of chinese mteval?2003 test set using\nphrases with a specific length on fl side (in percentages)\ntable 9 reveals that the coverage of the test set\nis higher for precision-oriented alignments than\nrecall-oriented alignments for all different lengths\nof the phrases",
    "appliqu\u00e9e"
  ],
  [
    " for\nexample, linear precedence in languages with poor\nmorphology such as english or french may have a\ngreater importance than obligation (i",
    "appliqu\u00e9e"
  ],
  [
    " 44 native speakers of french\ncompleted the questionnaire giving acceptability\njudgements following the magnitude estimation\ntechnique",
    "appliqu\u00e9e"
  ],
  [
    " menzel (2005) ?parsing unre-\nstricted german text with defeasible constraints?,\nin h",
    "appliqu\u00e9e"
  ],
  [
    " in this\nexample the french words une and autre would\nboth be assigned the index 24 ? for the english\nword another ? when french is the source lan-\nguage",
    "appliqu\u00e9e"
  ],
  [
    " to discourage all of these\nfrench words from aligning with the, the best of\nthese (la) is flagged as the best candidate",
    "appliqu\u00e9e"
  ],
  [
    " pos can also be useful\nfor less closely related language pairs, such as en-\nglish and japanese where english determiners are\nnever aligned; nor are japanese case markers",
    "appliqu\u00e9e"
  ],
  [
    " as we didn?t have access to\na romanian pos tagger, these features were not\nused for the romanian-english language pair",
    "appliqu\u00e9e"
  ],
  [
    " for the english-french dictionary\nwe used freedict,3 which contains 8,799 english\nwords",
    "appliqu\u00e9e"
  ],
  [
    "42\nfrench? english 96",
    "appliqu\u00e9e"
  ],
  [
    "21\nenglish? french 97",
    "appliqu\u00e9e"
  ],
  [
    "26\nromanian? english 82",
    "appliqu\u00e9e"
  ],
  [
    "53\nenglish? romanian 82",
    "appliqu\u00e9e"
  ],
  [
    " results on the romanian data using all fea-\ntures\nis used as a feature to represent whether there is\na strong alignment candidate",
    "appliqu\u00e9e"
  ],
  [
    "\nthe romanian results are close to the best re-\nported result of 26",
    "appliqu\u00e9e"
  ],
  [
    " for the french data, where a very\nlarge lexicon can be estimated from the million\nsentence alignments, the sparse word pairs learnt\non the word aligned sentences appear to lead to\noverfitting",
    "appliqu\u00e9e"
  ],
  [
    " with both the transla-\ntion score features (dice and model 1) removed\n? the sentence aligned data are not used ? the\naer of the romanian is more than twice that of\nthe french, despite employing more word aligned\ndata",
    "appliqu\u00e9e"
  ],
  [
    " this could be caused by the lack of possi-\nble (p) alignment markup in the romanian data,\nwhich provide a boost in aer on the french data\nset, rewarding what would otherwise be consid-\nered errors",
    "appliqu\u00e9e"
  ],
  [
    "edu\nabstract\nin this paper we investigate chinese-\nenglish name transliteration using compa-\nrable corpora, corpora where texts in the\ntwo languages deal in some of the same\ntopics ? and therefore share references\nto named entities ? but are not transla-\ntions of each other",
    "appliqu\u00e9e"
  ],
  [
    "\nfor example, if one were to go through an english,\nchinese and arabic newspaper on the same day,\nit is likely that the more important international\nevents in various topics such as politics, business,\nscience and sports, would each be covered in each\nof the newspapers",
    "appliqu\u00e9e"
  ],
  [
    " our idea is that the occur-\nrence of a cluster of names in, say, an english text,\nshould be useful if we find a cluster of what looks\nlike the same names in a chinese or arabic text",
    "appliqu\u00e9e"
  ],
  [
    " these are fragments of two\nstories from the june 8, 2001 xinhua english and\nchinese newswires, each covering an international\nwomen?s badminton championship",
    "appliqu\u00e9e"
  ],
  [
    "\nthus (camilla) martin shows up in the chinese\nversion as ??? ma-er-ting; judith meulendijks\nis ??????? yu mo-lun-di-ke-si; and mette\nsorensen is ?????mai su-lun-sen",
    "appliqu\u00e9e"
  ],
  [
    " while some of\nthe transliterations are ?standard? ? thus martin\nis conventionally transliterated as ??? ma-er-\nting ? many of them were clearly more novel,\nthough all of them follow the standard chinese\nconventions for transliterating foreign names",
    "appliqu\u00e9e"
  ],
  [
    "\n2 previous work\nin previous work on chinese named-entity\ntransliteration ? e",
    "appliqu\u00e9e"
  ],
  [
    " (meng et al, 2001; gao\net al, 2004), the problem has been cast as the\nproblem of producing, for a given chinese name,\nan english equivalent such as one might need in\na machine translation system",
    "appliqu\u00e9e"
  ],
  [
    " for example, for\nthe name ??????wei wei-lian-mu-si, one\nwould like to arrive at the english name v(enus)\nwilliams",
    "appliqu\u00e9e"
  ],
  [
    "\n3 chinese transliteration with\ncomparable corpora\nwe assume that we have comparable corpora, con-\nsisting of newspaper articles in english and chi-\nnese from the same day, or almost the same day",
    "appliqu\u00e9e"
  ],
  [
    " in\nour experiments we use data from the english and\nchinese stories from the xinhua news agency for\nabout 6 months of 2001",
    "appliqu\u00e9e"
  ],
  [
    " given an english name, identify candi-\ndate chinese character n-grams as possible\ntransliterations",
    "appliqu\u00e9e"
  ],
  [
    "\nsuppose several high-confidence name transliter-\nation pairs occur in a pair of english and chi-\nnese documents",
    "appliqu\u00e9e"
  ],
  [
    " we thus pro-\npose a score propagation method to allow these\nhigh-confidence pairs to propagate some of their\n2available from the ldc via the english gigaword\n(ldc2003t05) and chinese gigaword (ldc2003t09) cor-\npora",
    "appliqu\u00e9e"
  ],
  [
    "1 candidate selection\nthe english named entity candidate selection pro-\ncess was already described above",
    "appliqu\u00e9e"
  ],
  [
    " as discussed else-\nwhere (sproat et al, 1996), a subset of a few hun-\ndred characters (out of several thousand) tends to\nbe used overwhelmingly for transliterating foreign\nnames into chinese",
    "appliqu\u00e9e"
  ],
  [
    " if the character\n??? occurs, which is frequently used to represent\nthe space between parts of an english name, then\nat least one character to the left and right of this\ncharacter will be collected, even if the character in\nquestion is not in the list of ?foreign? characters",
    "appliqu\u00e9e"
  ],
  [
    "\narmed with the english and chinese candidate\nlists, we then consider the pairing of every en-\nglish candidate with every chinese candidate",
    "appliqu\u00e9e"
  ],
  [
    " in general,\nwe seek to estimate p (e|c), where e is a word in\nroman script, and c is a word in chinese script",
    "appliqu\u00e9e"
  ],
  [
    "\nsince chinese transliteration is mostly based on\npronunciation, we estimate p (e?|c?), where e? is\nthe pronunciation of e and c? is the pronunciation\nof c",
    "appliqu\u00e9e"
  ],
  [
    " here, e?i is the ith subsequence of\nthe english phone string, and c?i is the ith subse-\nquence of the chinese phone string",
    "appliqu\u00e9e"
  ],
  [
    " since chi-\nnese transliteration attempts to match the syllable-\nsized characters to equivalent sounding spans of\nthe english language, we fix the c?i to be syllables,\nand let the e?i range over all possible subsequences\nof the english phone string",
    "appliqu\u00e9e"
  ],
  [
    " for training data we\nhave a small list of 721 names in roman script and\ntheir chinese equivalent",
    "appliqu\u00e9e"
  ],
  [
    " english-chinese pairs in our training\ndictionary were aligned using the alignment algo-\nrithm from (kruskal, 1999), and a hand-derived\nset of 21 rules-of-thumb: for example, we have\nrules that encode the fact that chinese /l/ can cor-\nrespond to english /r/, /n/ or /er/; and that chinese\n/w/ may be used to represent /v/",
    "appliqu\u00e9e"
  ],
  [
    " given that there\nare over 400 syllables in mandarin (not count-\ning tone) and each of these syllables can match\na large number of potential english phone spans,\nthis is clearly not enough training data to cover all\nthe parameters, and so we use good-turing esti-\nmation to estimate probabilities for unseen corre-\nspondences",
    "appliqu\u00e9e"
  ],
  [
    " thus we set a hard rule that for an en-\nglish phone span to correspond to a chinese sylla-\nble, the initial phone of the english span must have\nbeen seen in the training data as corresponding to\nthe initial of the chinese syllable some minimum\nnumber of times",
    "appliqu\u00e9e"
  ],
  [
    " secondly,\nwe were interested in seeing how well one could do with a\nlimited resource of just a few hundred names, which is a more\nrealistic scenario for languages that have fewer resources than\nenglish and chinese",
    "appliqu\u00e9e"
  ],
  [
    " then,\nfor each transliteration candidate (both chinese\nand english), we compute its frequency in each\nof those pseudo-documents and obtain a raw fre-\nquency vector",
    "appliqu\u00e9e"
  ],
  [
    ", n,\nwhere (ei, ci) is a distinct pair of english and chi-\nnese names",
    "appliqu\u00e9e"
  ],
  [
    "\n4 evaluation\nwe use a comparable english-chinese corpus to\nevaluate our methods for chinese transliteration",
    "appliqu\u00e9e"
  ],
  [
    "\nwe take one day?s worth of comparable news arti-\ncles (234 chinese stories and 322 english stories),\ngenerate about 600 english names with the entity\nrecognizer (li et al, 2004) as described above, and\n76\nfind potential chinese transliterations also as pre-\nviously described",
    "appliqu\u00e9e"
  ],
  [
    " we generated 627 chinese can-\ndidates",
    "appliqu\u00e9e"
  ],
  [
    " to evaluate the results for a set of english\nnames, we take the mean of the reciprocal rank of\neach english name",
    "appliqu\u00e9e"
  ],
  [
    "\nwe attempted to create a complete set of an-\nswers for all the english names in our test set,\nbut a small number of english names do not seem\nto have any standard transliteration according to\nthe resources that we consulted",
    "appliqu\u00e9e"
  ],
  [
    " we ended up\nwith a list of about 490 out of the 600 english\nnames judged",
    "appliqu\u00e9e"
  ],
  [
    " we further notice that some an-\nswers (about 20%) are not in our chinese candi-\ndate set",
    "appliqu\u00e9e"
  ],
  [
    " this could be due to two reasons: (1) the\nanswer does not occur in the chinese news articles\nwe look at",
    "appliqu\u00e9e"
  ],
  [
    " in order to\nsee more clearly how accurate each method is for\nranking the candidates, we also compute the mrr\nfor the subset of english names whose transliter-\nation answers are in our candidate list",
    "appliqu\u00e9e"
  ],
  [
    " we dis-\ntinguish the mrrs computed on these two sets of\nenglish names as ?allmrr? and ?coremrr?",
    "appliqu\u00e9e"
  ],
  [
    " this table shows the 10 high-\nest scoring transliterations for each chinese char-\nacter sequence based on all texts in the chinese\nand english xinhua newswire for the 13th of au-\ngust, 2001",
    "appliqu\u00e9e"
  ],
  [
    " for all\nthe english names the mrr is 0",
    "appliqu\u00e9e"
  ],
  [
    " for ex-\nample, with pearson correlation, when the chinese\ntransliteration of an english name is included in\nour candidate list, the correct answer is, on aver-\nage, ranked at the 3rd place or better",
    "appliqu\u00e9e"
  ],
  [
    " in-\ndeed, intuitively the best candidate is the one that\nhas a good pronunciation alignment as well as a\ncorrelated frequency distribution with the english\nname",
    "appliqu\u00e9e"
  ],
  [
    ", those candidates that have a reasonable\nphonetic alignment with the english name), it can\noutperform the phonetic correspondence method",
    "appliqu\u00e9e"
  ],
  [
    "4 error analysis\nfrom the results above, we see that the mrrs for\nthe core english names are substantially higher\nthan those for all the english names",
    "appliqu\u00e9e"
  ],
  [
    " this means\nthat our methods perform very well whenever we\nhave the answer in our candidate list, but we have\nalso missed the answers for many english names",
    "appliqu\u00e9e"
  ],
  [
    " there are 25 such english name candi-\ndates",
    "appliqu\u00e9e"
  ],
  [
    " we are inves-\ntigating transliterations among several language\npairs, and are extending these methods to ko-\nrean, arabic, russian and hindi ? see (tao et al,\n2006)",
    "appliqu\u00e9e"
  ],
  [
    " a\nstochastic finite-state word-segmentation algorithm\nfor chinese",
    "appliqu\u00e9e"
  ],
  [
    "proceedings of the 45th annual meeting of the association of computational linguistics, pages 1?8,\nprague, czech republic, june 2007",
    "appliqu\u00e9e"
  ],
  [
    "\n3 experimental results\nwe test our framework on the task of large vocab-\nulary translation from dialectical (iraqi) arabic ut-\nterances into english",
    "appliqu\u00e9e"
  ],
  [
    "\nthere are 25k entries in the english vocabulary\nand 90k in arabic side",
    "appliqu\u00e9e"
  ],
  [
    "1 training and translation setup\nstarting from the collection of parallel training sen-\ntences, we train word alignment models in two trans-\nlation directions, from english to iraqi arabic and\nfrom iraqi arabic to english, and derive two sets\nof viterbi alignments",
    "appliqu\u00e9e"
  ],
  [
    " the language\nmodel is a statistical trigram model estimated with\nmodified kneser-ney smoothing (chen and good-\nman, 1996) using all english sentences in the paral-\nlel training data",
    "appliqu\u00e9e"
  ],
  [
    " we find\nlow-dimensional representation (r = 67) of english\nwords and arabic words and use their similarity to\nestablish semantic constraints as in equ",
    "appliqu\u00e9e"
  ],
  [
    " the complete english sentence is\n?have you ever had like any reflux diseases in your\nesophagus?",
    "appliqu\u00e9e"
  ],
  [
    " the example demos that due to reasonable\nconstraints placed in word alignment training, the\nlink to ? tk? is corrected and consequently we have\naccurate word translation for the arabic singleton\ntable 2: word pair constraint values\nenglish e arabic f conbilsa?1(f, e)\nesophagus mrm 0",
    "appliqu\u00e9e"
  ],
  [
    "1% absolute ter reduction) in translating dialec-\ntical arabic into english",
    "appliqu\u00e9e"
  ],
  [
    "proceedings of the 45th annual meeting of the association of computational linguistics, pages 9?16,\nprague, czech republic, june 2007",
    "appliqu\u00e9e"
  ],
  [
    "4 points improvement in bleu for\nenglish to japanese translation",
    "appliqu\u00e9e"
  ],
  [
    " for some language pairs, such as\nenglish and japanese, the ordering problem is es-\npecially hard, because the target word order differs\nsignificantly from the source word order",
    "appliqu\u00e9e"
  ],
  [
    "\nthe advantages of modeling how a target lan-\nguage syntax tree moves with respect to a source lan-\nguage syntax tree are that (i) we can capture the fact\nthat constituents move as a whole and generally re-\nspect the phrasal cohesion constraints (fox, 2002),\nand (ii) we can model broad syntactic reordering\nphenomena, such as subject-verb-object construc-\ntions translating into subject-object-verb ones, as is\ngenerally the case for english and japanese",
    "appliqu\u00e9e"
  ],
  [
    "4 bleu points in english-to-\njapanese translation on a computer domain",
    "appliqu\u00e9e"
  ],
  [
    " in case of\none-to-many alignments, for example, the case of\n?constraints? aligning to the japanese words for ?re-\nstriction? and ?condition?, the algorithm creates a\n1for example, in the first order shown, the descendants of\nword 6 are not contiguous and thus this order violates the con-\nstraint",
    "appliqu\u00e9e"
  ],
  [
    " the example in figure 2 shows\nthat the head word ?eliminates? takes a dependent\n?this? to the left (position ?1), and on the japanese\nside, the head word ?kaishou? (corresponding to\n?eliminates?) takes a dependent ?kore? (correspond-\ning to ?this?) to the left (position ?2)",
    "appliqu\u00e9e"
  ],
  [
    "\n5 evaluation on reference sentences\nour experiments on ordering reference sentences\nuse a set of 445k english sentences with their ref-\nerence japanese translations",
    "appliqu\u00e9e"
  ],
  [
    " japanese pos tags were assigned by an automatic\npos tagger, which is a local classifier not using tag\nsequence information",
    "appliqu\u00e9e"
  ],
  [
    " english japanese\navg",
    "appliqu\u00e9e"
  ],
  [
    "proceedings of the 45th annual meeting of the association of computational linguistics, pages 17?24,\nprague, czech republic, june 2007",
    "appliqu\u00e9e"
  ],
  [
    " these rules are extracted from a bitext anno-\ntated with both english (target side) parses and word\nalignments",
    "appliqu\u00e9e"
  ],
  [
    " the mistaken link [la ? the] intervenes be-\ntween axe?s and carrie`r, which both align within an\nenglish adjective phrase, while la aligns to a distant\nsubspan of the english parse tree",
    "appliqu\u00e9e"
  ],
  [
    " in this way, the\nalignment violates the constituent structure of the\nenglish parse",
    "appliqu\u00e9e"
  ],
  [
    "\nword alignment constellation that would allow a \nphrase extraction in a phrase-based translation \nsystem, but which does not correspond to an \nenglish constituent",
    "appliqu\u00e9e"
  ],
  [
    "[2]) ? [0] emplois sont [1] [2]\nfigure 1: in this transducer extraction example, (a) shows a proposed alignment from our test set with\nan alignment error that violates the constituent structure of the english sentence",
    "appliqu\u00e9e"
  ],
  [
    ", fj} given an english (target) sen-\ntence e = {e1, ",
    "appliqu\u00e9e"
  ],
  [
    " however, its distor-\ntion model considers only string distance, disregard-\ning the constituent structure of the english sentence",
    "appliqu\u00e9e"
  ],
  [
    "\nwe condition on t via a generative process that tran-\nsitions between two english positions by traversing\nthe unique shortest path ?(aj? ,aj ,t) through t from\naj? to aj ",
    "appliqu\u00e9e"
  ],
  [
    "\nthis model reduces to the classic hmm distor-\ntion model given minimal english trees of only uni-\nformly labeled pre-terminals and a root node",
    "appliqu\u00e9e"
  ],
  [
    "\nmd vp\nvp\nnp pp\ndt nn in nn\nfigure 3: for this example sentence, the learned dis-\ntortion distribution of pd(aj |aj? , j, t) resembles its\ncounterpart pd(aj |aj? , j) of the hmm model but re-\nflects the constituent structure of the english tree t",
    "appliqu\u00e9e"
  ],
  [
    " we require that the markov walk\nfrom leaf to leaf of the english tree must start and\nend at the root, using the following assumptions",
    "appliqu\u00e9e"
  ],
  [
    " hence, a choice to stop immediately is\na choice to emit another foreign word from the\ncurrent english word",
    "appliqu\u00e9e"
  ],
  [
    " in this familiar dynamic programming ap-\nproach, we must compute the distortion probabilities\nfor each pair of english positions",
    "appliqu\u00e9e"
  ],
  [
    "2 we also investigated extraction-\nspecific metrics: the frequency of interior nodes ? a\nmeasure of how often the alignments violate the con-\nstituent structure of english parses ? and a variant of\nthe cper metric of ayan and dorr (2006)",
    "appliqu\u00e9e"
  ],
  [
    "\n22\nfrench precision recall aer\nclassic hmm 93",
    "appliqu\u00e9e"
  ],
  [
    "6\nchinese precision recall aer\nclassic hmm 81",
    "appliqu\u00e9e"
  ],
  [
    " the evaluated alignments are a soft\nunion for french and a hard union for chinese, both\nusing competitive thresholding decoding",
    "appliqu\u00e9e"
  ],
  [
    "\nwe also compared our french results to the pub-\nlic baseline giza++ using the script published for\nthe naacl 2006 machine translation workshop\nshared task",
    "appliqu\u00e9e"
  ],
  [
    "\n4null emission probabilities were fixed to 1|e| , inversely pro-\nportional to the length of the english sentence",
    "appliqu\u00e9e"
  ],
  [
    "\nfrench w/o ct with ct\nhard intersection (min) 8",
    "appliqu\u00e9e"
  ],
  [
    "4\nchinese w/o ct with ct\nhard intersection (min) 27",
    "appliqu\u00e9e"
  ],
  [
    "2 rule extraction results\nwhile its competitive aer certainly speaks to the\npotential utility of our syntactic distortion model, we\nproposed the model for a different purpose: to mini-\nmize the particularly troubling alignment errors that\ncross constituent boundaries and violate the struc-\nture of english parse trees",
    "appliqu\u00e9e"
  ],
  [
    " we observed a similar 50% reduction\nfor the chinese data",
    "appliqu\u00e9e"
  ],
  [
    "\nfrench prec",
    "appliqu\u00e9e"
  ],
  [
    "0\nrelative change -17% 27% 10%\nchinese prec",
    "appliqu\u00e9e"
  ],
  [
    " both french\naligners were decoded using the best-performing\nsoft union combiner",
    "appliqu\u00e9e"
  ],
  [
    "proceedings of the 45th annual meeting of the association of computational linguistics, pages 25?32,\nprague, czech republic, june 2007",
    "appliqu\u00e9e"
  ],
  [
    " for nist, the lan-\nguage model score is determined using a 5-gram\nmodel trained on the english gigaword corpus, and\non french?english, we use the trigram model which\nwas provided for the naacl 2006 shared task",
    "appliqu\u00e9e"
  ],
  [
    "0m\nenglish gigaword lm 11",
    "appliqu\u00e9e"
  ],
  [
    " we used the\nldc segmenter for chinese",
    "appliqu\u00e9e"
  ],
  [
    " one and\nfour english references: the europarl data comes\nwith one reference, the nist 2004 evaluation set\nand the nist section of the 2006 evaluation set\nare provided with four references each, whereas the\ngale section of the 2006 evaluation set comes\nwith one reference only",
    "appliqu\u00e9e"
  ],
  [
    "\ntable 5 shows the translation quality achieved on\nthe nist test sets when additional source language\ndata from the chinese gigaword corpus compris-\ning newswire text is used for transductive learning",
    "appliqu\u00e9e"
  ],
  [
    "\nthese chinese sentences were sorted according to\ntheir n-gram overlap (see section 3",
    "appliqu\u00e9e"
  ],
  [
    "5) with the de-\nvelopment corpus, and the top 5,000 chinese sen-\ntences were used",
    "appliqu\u00e9e"
  ],
  [
    "2\ntable 5: translation quality using an additional\nphrase table trained on monolingual chinese news\ndata",
    "appliqu\u00e9e"
  ],
  [
    "proceedings of the 45th annual meeting of the association of computational linguistics, pages 33?40,\nprague, czech republic, june 2007",
    "appliqu\u00e9e"
  ],
  [
    " carpuat and wu (2005)\nintegrated the translation predictions from a chinese\nwsd system (carpuat et al, 2004) into a chinese-\nenglish word-based statistical mt system using the\nisi rewrite decoder (germann, 2003)",
    "appliqu\u00e9e"
  ],
  [
    " though they\nacknowledged that directly using english transla-\ntions as word senses would be ideal, they instead\npredicted the hownet sense of a word and then used\nthe english gloss of the hownet sense as the wsd\nmodel?s predicted translation",
    "appliqu\u00e9e"
  ],
  [
    "\n4 gathering training examples for wsd\nour experiments were for chinese to english trans-\nlation",
    "appliqu\u00e9e"
  ],
  [
    " hence, in the context of our work, a syn-\nchronous cfg grammar rule x ? ??, ?? gathered\nby hiero consists of a chinese portion ? and a cor-\nresponding english portion ?, where each portion is\na sequence of words and non-terminal symbols",
    "appliqu\u00e9e"
  ],
  [
    "\nour wsd classifier suggests a list of english\nphrases (where each phrase consists of one or more\nenglish words) with associated contextual probabil-\nities as possible translations for each particular chi-\nnese phrase",
    "appliqu\u00e9e"
  ],
  [
    " in general, the chinese phrase may\nconsist of k chinese words, where k = 1, 2, 3, ",
    "appliqu\u00e9e"
  ],
  [
    "\nwhenever hiero is about to extract a grammar\nrule where its chinese portion is a phrase of one or\ntwo chinese words with no non-terminal symbols,\nwe note the location (sentence and token offset) in\nthe chinese half of the parallel corpus from which\nthe chinese portion of the rule is extracted",
    "appliqu\u00e9e"
  ],
  [
    " the ac-\ntual sentence in the corpus containing the chinese\nphrase, and the one sentence before and the one sen-\ntence after that actual sentence, will serve as the con-\ntext for one training example for the chinese phrase,\nwith the corresponding english phrase of the gram-\nmar rule as its translation",
    "appliqu\u00e9e"
  ],
  [
    " since the extracted training data may\n35\nbe noisy, for each chinese phrase, we remove en-\nglish translations that occur only once",
    "appliqu\u00e9e"
  ],
  [
    "\nusing the wsd classifier described in section 2,\nwe classified the words in each chinese source sen-\ntence to be translated",
    "appliqu\u00e9e"
  ],
  [
    " we first performed wsd on\nall single chinese words which are either noun, verb,\nor adjective",
    "appliqu\u00e9e"
  ],
  [
    " next, we classified the chinese phrases\nconsisting of 2 consecutive chinese words by simply\ntreating the phrase as a single unit",
    "appliqu\u00e9e"
  ],
  [
    " when perform-\ning classification, we give as output the set of en-\nglish translations with associated context-dependent\nprobabilities, which are the probabilities of a chi-\nnese word (phrase) translating into each english\nphrase, depending on the context of the chinese\nword (phrase)",
    "appliqu\u00e9e"
  ],
  [
    " after wsd, the ith word ci in every\nchinese sentence may have up to 3 sets of associ-\nated translations provided by the wsd system: a set\nof translations for ci as a single word, a second set\nof translations for ci?1ci considered as a single unit,\nand a third set of translations for cici+1 considered\nas a single unit",
    "appliqu\u00e9e"
  ],
  [
    "\n5 incorporating wsd during decoding\nthe following tasks are done for each rule that is\nconsidered during decoding:\n? identify chinese words to suggest translations\nfor\n? match suggested translations against the en-\nglish side of the rule\n? compute features for the rule\nthe wsd system is able to predict translations\nonly for a subset of chinese words or phrases",
    "appliqu\u00e9e"
  ],
  [
    "\nhence, we must first identify which parts of the\nchinese side of the rule have suggested translations\navailable",
    "appliqu\u00e9e"
  ],
  [
    "\nnext, we want to know, for each chinese sub-\nstring considered, whether the wsd system sup-\nports the chinese-english translation represented by\nthe rule",
    "appliqu\u00e9e"
  ],
  [
    " if the rule is finally chosen as part of the\nbest derivation for translating the chinese sentence,\nthen all the words in the english side of the rule will\nappear in the translated english sentence",
    "appliqu\u00e9e"
  ],
  [
    " hence,\nwe need to match the translations suggested by the\nwsd system against the english side of the rule",
    "appliqu\u00e9e"
  ],
  [
    " first, the proposed translation must\nbe a substring of the english side of the rule",
    "appliqu\u00e9e"
  ],
  [
    " second, the\nmatch must contain at least one aligned chinese-\nenglish word pair, but we do not make any other\nrequirements about the alignment of the other chi-\nnese or english words",
    "appliqu\u00e9e"
  ],
  [
    "\ndefine a chunk of a rule to be a maximal sub-\nstring of terminal symbols on the english side of the\nrule",
    "appliqu\u00e9e"
  ],
  [
    " whenever we find\na matching wsd translation, we mark the whole\nchunk on the english side as consumed",
    "appliqu\u00e9e"
  ],
  [
    " hereafter, we will use symbols\nto represent the chinese and english words in the\nrule: c1, c2, and c3 will represent the chinese words\n???, ???, and ?t? respectively",
    "appliqu\u00e9e"
  ],
  [
    " similarly, e1, e2,\ne3, e4, and e5 will represent the english words go,\nto, every, month, and to respectively",
    "appliqu\u00e9e"
  ],
  [
    " when the rule\nis extracted from the parallel corpus, it has these\nalignments between the words of its chinese and\nenglish portion: {c1?e3,c2?e4,c3?e1,c3?e2,c3?e5},\nwhich means that c1 is aligned to e3, c2 is aligned to\n1in order to check this requirement, we extended hiero to\nmake word alignment information available to the decoder",
    "appliqu\u00e9e"
  ],
  [
    "\n36\ninput: rule r considered during decoding with its own associated costr\nlc = list of symbols in chinese portion of r\nwsdcost = 0\ni = 1\nwhile i ? len(lc):\nci = ith symbol in lc\nif ci is a chinese word (i",
    "appliqu\u00e9e"
  ],
  [
    ", not a non-terminal symbol):\nseenchunk = ? // seenchunk is a global variable and is passed by reference to matchwsd\nif (ci is not the last symbol in lc) and (ci+1 is a terminal symbol): then ci+1=(i+1)th symbol in lc, else ci+1 = null\nif (ci+1!=null) and (ci, ci+1) as a single unit has wsd translations:\nwsdc = set of wsd translations for (ci, ci+1) as a single unit with context-dependent probabilities\nwsdcost = wsdcost + matchwsd(ci, wsdc, seenchunk)\nwsdcost = wsdcost + matchwsd(ci+1, wsdc, seenchunk)\ni = i + 1\nelse:\nwsdc = set of wsd translations for ci with context-dependent probabilities\nwsdcost = wsdcost + matchwsd(ci, wsdc, seenchunk)\ni = i + 1\ncostr = costr + wsdcost\nmatchwsd(c, wsdc, seenchunk):\n// seenchunk is the set of chunks of r already examined for possible matching wsd translations\ncost = 0\nchunkset = set of chunks in r aligned to c\nfor chunkj in chunkset:\nif chunkj not in seenchunk:\nseenchunk = seenchunk ? { chunkj }\nechunkj = set of english words in chunkj aligned to c\ncandidatewsd = ?\nfor wsdk in wsdc:\nif (wsdk is sub-sequence of chunkj) and (wsdk contains at least one word in echunkj )\ncandidatewsd = candidatewsd ? { wsdk }\nwsdbest = best matching translation in candidatewsd against chunkj\ncost = cost + costbywsdfeatures(wsdbest) // costbywsdfeatures sums up the cost of the two wsd features\nreturn cost\nfigure 1: wsd translations affecting the cost of a rule r considered during decoding",
    "appliqu\u00e9e"
  ],
  [
    " although all\nwords are aligned here, in general for a rule, some of\nits chinese or english words may not be associated\nwith any alignments",
    "appliqu\u00e9e"
  ],
  [
    "\nin our experiment, c1c2 as a phrase has a list of\ntranslations proposed by the wsd system, includ-\ning the english phrase ?every month?",
    "appliqu\u00e9e"
  ],
  [
    "\nthe english phrases ?go to? and ?to? are among the\nlist of translations proposed by the wsd system for\nc3, and they are eventually chosen as the best match-\ning translations for the chunks e1e2 and e3e4e5, re-\nspectively",
    "appliqu\u00e9e"
  ],
  [
    "\n6 experiments\nas mentioned, our experiments were on chinese to\nenglish translation",
    "appliqu\u00e9e"
  ],
  [
    "\nthe english portion of the fbis corpus and the xin-\nhua portion of the gigaword corpus, we trained a tri-\ngram language model using the sri language mod-\nelling toolkit (stolcke, 2002)",
    "appliqu\u00e9e"
  ],
  [
    " the first way in which wsd helps is when\nit enables the integrated hiero+wsd system to out-\nput extra appropriate english words",
    "appliqu\u00e9e"
  ],
  [
    " for example,\nthe translations for the chinese sentence ?",
    "appliqu\u00e9e"
  ],
  [
    "\nhere, the chinese words ??\u001brz? are not trans-\nlated by hiero at all",
    "appliqu\u00e9e"
  ],
  [
    " for example,\nfor the chinese sentence ?",
    "appliqu\u00e9e"
  ],
  [
    " ?, the wsd system helps to correct hiero?s\noriginal translation by providing the correct transla-\ntion of ?all ethnic groups? for the chinese phrase\n??\u0018?:\n? hiero: ",
    "appliqu\u00e9e"
  ],
  [
    " we found that in some situations,\nhiero+wsd has provided extra appropriate english\nwords, but those particular words are not used in the\nreference sentences",
    "appliqu\u00e9e"
  ],
  [
    " an interesting example is the\ntranslation of the chinese sentence ??? i? ?\n?8q?\u0006?r?\u001brz?????",
    "appliqu\u00e9e"
  ],
  [
    " in\nthis case however, those extra english words pro-\nvided by hiero+wsd, though appropriate, do not\n39\nresult in more n-gram matches as the reference sen-\ntences used phrases such as ?will not gain?, ?will not\nget?, etc",
    "appliqu\u00e9e"
  ],
  [
    " for future work, an immediate step\nwould be for the wsd classifier to provide trans-\nlations for longer chinese phrases",
    "appliqu\u00e9e"
  ],
  [
    "proceedings of the 45th annual meeting of the association of computational linguistics, pages 41?48,\nprague, czech republic, june 2007",
    "appliqu\u00e9e"
  ],
  [
    " the ap-\nproach is evaluated in two tasks: identifica-\ntion of the correct translation for a set of \nhighly ambiguous verbs in english-\nportuguese translation and disambiguation \nof verbs from the senseval-3 lexical sam-\nple task",
    "appliqu\u00e9e"
  ],
  [
    " \nthis paper focuses on the application of our ap-\nproach to the translation of verbs in english to por-\ntuguese translation, specifically for a set of 10 \nmainly light and highly ambiguous verbs",
    "appliqu\u00e9e"
  ],
  [
    ", 2005); \nand (2) an english setting consisting of 32 verbs \nfrom senseval-3 lexical sample task (mihalcea et",
    "appliqu\u00e9e"
  ],
  [
    " five words to the right and left of the target \nverb in the portuguese translation",
    "appliqu\u00e9e"
  ],
  [
    " narrow context consisting of 5 collocations \nof the verb in the portuguese translation, which \ntake into account the positions of the words, \nrepresented by has_narrow_trns(snt, \nword_position, portuguese_word): \nhas_narrow_trns(snt1, 1st_word_right, como)",
    "appliqu\u00e9e"
  ],
  [
    " currently, we are \nevaluating the role of the wsd models for the 10 \nverbs of the multilingual task in an english-\nportuguese statistical machine translation system",
    "appliqu\u00e9e"
  ],
  [
    " \nreferences \neneko agirre and german rigau",
    "appliqu\u00e9e"
  ],
  [
    " the senseval-3 english lexical sample \ntask",
    "appliqu\u00e9e"
  ],
  [
    " longman dictionary of \ncontemporary english",
    "appliqu\u00e9e"
  ],
  [
    "proceedings of the 45th annual meeting of the association of computational linguistics, pages 49?56,\nprague, czech republic, june 2007",
    "appliqu\u00e9e"
  ],
  [
    "\na similar work is the recent research by chen et al\n(2006), where active learning was used successfully\nto reduce the annotation effort for wsd of 5 english\nverbs using coarse-grained evaluation",
    "appliqu\u00e9e"
  ],
  [
    " for wsd,\nfujii et al (1998) used selective sampling for a\njapanese language wsd system, chen et al (2006)\nused active learning for 5 verbs using coarse-grained\nevaluation, and h",
    "appliqu\u00e9e"
  ],
  [
    "proceedings of the 45th annual meeting of the association of computational linguistics, pages 65?72,\nprague, czech republic, june 2007",
    "appliqu\u00e9e"
  ],
  [
    " this database contains infor-\nmation about 2150 languages (sampled from across\nthe world; figure 1 depicts the locations of lan-\n65\nnumeral glottalized number of\nlanguage classifiers rel/n order o/v order consonants tone genders\nenglish absent nrel vo none none three\nhindi absent reln ov none none two\nmandarin obligatory reln vo none complex none\nrussian absent nrel vo none none three\ntukang besi absent ? either implosives none three\nzulu absent nrel vo ejectives simple five+\ntable 1: example database entries for a selection of diverse languages and features",
    "appliqu\u00e9e"
  ],
  [
    " this implication\n(vo ? na) has one glaring exception: english",
    "appliqu\u00e9e"
  ],
  [
    " moreover, languages are not in-\ndependent: german and dutch are more similar than\ngerman and hindi due to history and geography",
    "appliqu\u00e9e"
  ],
  [
    " for instance, the wals database contains a\nhalf dozen versions of german",
    "appliqu\u00e9e"
  ],
  [
    " the flat model\nconsiders these versions of german just as statisti-\ncally independent as, say, german and hindi",
    "appliqu\u00e9e"
  ],
  [
    " (by noise, we refer either to mis-\nannotations, or to ?strange? languages like english",
    "appliqu\u00e9e"
  ],
  [
    " labial-velars are joined sounds like /kp/ and /gb/\n(to english speakers, sounding like chicken noises); uvulars\nsounds are made in the back of the throat, like snoring",
    "appliqu\u00e9e"
  ],
  [
    "proceedings of the 45th annual meeting of the association of computational linguistics, pages 73?80,\nprague, czech republic, june 2007",
    "appliqu\u00e9e"
  ],
  [
    "\na native english speaker and two non-native en-\nglish speaker were asked to assign correct/incorrect\nlabels to \u0002\u0005\u0005 sentences in dlm-train1",
    "appliqu\u00e9e"
  ],
  [
    " the result\nfor an native english speaker was that all positive\nsentences were labeled as correct and all negative\nsentences except for one were labeled as incorrect",
    "appliqu\u00e9e"
  ],
  [
    "\non the other hand, the results for non-native english\nspeakers are 67\u0013 and 70\u0013",
    "appliqu\u00e9e"
  ],
  [
    "  \nwe further describe the methods by which \nenglish language data can be used to \nbootstrap the ner process in other languages",
    "appliqu\u00e9e"
  ],
  [
    "org) to automatically create \nan annotated corpus of text in any given language, \nwith no linguistic expertise required on the part of \nthe user at run-time (and only english knowledge \nrequired during development)",
    "appliqu\u00e9e"
  ],
  [
    "   \n in order to make sure that the process is as \nlanguage-independent as possible, we declined to \nmake use of any non-english linguistic resources \noutside of the wikimedia domain (specifically, \nwikipedia and the english language wiktionary  \n(en",
    "appliqu\u00e9e"
  ],
  [
    "  in \nthis snippet, there are three articles links to english \nlanguage wikipedia pages, titled ?tributary,? \n?north branch susquehanna river,? and ?luzerne \ncounty, pennsylvania",
    "appliqu\u00e9e"
  ],
  [
    "  for example, in the \nturkish language article ?kanuni sultan s?ley-\nman? one finds a set of links including [[en:sulei-\nman the magnificent]] and [[ru:???????? i]]",
    "appliqu\u00e9e"
  ],
  [
    "  \nthese represent links to the english language \narticle ?suleiman the magnificent? and the russian \nlanguage article ????????? i",
    "appliqu\u00e9e"
  ],
  [
    "  in this paper, we emphasize the \nuse of links between articles of different languages, \nspecifically between english (the largest and best \nlinked wikipedia) and other languages",
    "appliqu\u00e9e"
  ],
  [
    "  we also note that the ner \ncomponent was not the focus of the research, and \nwas specific to the english language",
    "appliqu\u00e9e"
  ],
  [
    "1   initial set-up and overview \nour approach to multilingual ner is to pull back \nthe decision-making process to english whenever \npossible, so that we could apply some level of lin-\nguistic expertise",
    "appliqu\u00e9e"
  ],
  [
    " \n for computational feasibility, we downloaded \nvarious language wikipedias and the english lan-\nguage wiktionary   in their text (",
    "appliqu\u00e9e"
  ],
  [
    "  the system then uses catego-\nry links and/or interwiki links to associate that \nphrase with an english language phrase or set of \ncategories",
    "appliqu\u00e9e"
  ],
  [
    "  finally, it determines the appropriate \ntype of the english language data and assumes that \nthe original phrase is of the same type",
    "appliqu\u00e9e"
  ],
  [
    " \n in practice, the english language categorization \nshould be treated as one-time work, since it is \nidentical regardless of the language model being \nbuilt",
    "appliqu\u00e9e"
  ],
  [
    "  it is also the only stage of development at \nwhich we apply substantial linguistic knowledge, \neven of english",
    "appliqu\u00e9e"
  ],
  [
    "   \n in the sections that follow, we begin by show-\ning how the english language categorization is \ndone",
    "appliqu\u00e9e"
  ],
  [
    "  we go on to describe how individual non-\nenglish phrases are associated with english lan-\nguage information",
    "appliqu\u00e9e"
  ],
  [
    "2   english language categorization  \nfor each article title of interest (specifically ex-\ncluding template pages, wikipedia admistrative \npages, and articles whose title begins with ?list \nof?), we extracted the categories to which that en-\ntry was assigned",
    "appliqu\u00e9e"
  ],
  [
    "3 multilingual categorization  \nwhen attempting to categorize a non-english term \nthat has an entry in its language?s wikipedia, we \nuse two techniques to make a decision based on \nenglish language information",
    "appliqu\u00e9e"
  ],
  [
    "  first, whenever \npossible, we find the title of an associated english \nlanguage article by searching for a wikilink \nbeginning with ?en:?",
    "appliqu\u00e9e"
  ],
  [
    "  if such a title is found, then \nwe categorize the english article as shown in \nsection 3",
    "appliqu\u00e9e"
  ],
  [
    "2, and decide that the non-english title is \nof the same type as its english counterpart",
    "appliqu\u00e9e"
  ],
  [
    "  we \nnote that links to/from english are the most \ncommon interlingual wikilinks",
    "appliqu\u00e9e"
  ],
  [
    " in this case, we attempt to make a deci-\nsion based on category information, associating \nthe categories with their english equivalents, when \npossible",
    "appliqu\u00e9e"
  ],
  [
    " \n for example, the breton town of erquy has a \nsubstantial article in the french language wikipe-\ndia, but no article in english",
    "appliqu\u00e9e"
  ],
  [
    "  the system proceeds \nby determining that erquy belongs to four french \nlanguage categories:  ?cat?gorie:commune des \nc?tes-d'armor,? ?cat?gorie:ville portuaire de \nfrance,? ?cat?gorie:port de plaisance,? and \n?cat?gorie:station baln?aire",
    "appliqu\u00e9e"
  ],
  [
    "?  the system pro-\nceeds to associate these, respectively, with ?cate-\ngory:communes of c?tes-d'armor,? unknown, \n?category:marinas,? and ?category:seaside re-\nsorts? by looking in the french language pages of \neach for wikilinks of the form [[en:",
    "appliqu\u00e9e"
  ],
  [
    "     \n we note that the second french category actu-\nally has a perfectly good english equivalent (cate-\ngory:port cities and towns in france), but no one \nhas linked them as of this writing",
    "appliqu\u00e9e"
  ],
  [
    "   we also note \nthat the ambiguous categories are much more \ngpe-oriented in french",
    "appliqu\u00e9e"
  ],
  [
    " \n? we then search an associated english language \narticle, if available, for additional information",
    "appliqu\u00e9e"
  ],
  [
    "  \nthe parenthetical notation gives alternate names in \nthe breton and gallo languages",
    "appliqu\u00e9e"
  ],
  [
    ")   \n if the article has an english equivalent, we \nsearch that article for wikilinked phrases as well, \non the assumption that both articles will refer to \nmany of the same entities",
    "appliqu\u00e9e"
  ],
  [
    "  as the english lan-\nguage wikipedia is the largest, it frequently con-\ntains explicit references to and articles on \nsecondary people and places mentioned, but not \nlinked, within a given non-english article",
    "appliqu\u00e9e"
  ],
  [
    "  together, \nthese allow phrases like this (taken from the \nfrench wikipedia) to be correctly marked in its \nentirety as an entity of type money: ?25 millions \nde dollars",
    "appliqu\u00e9e"
  ],
  [
    "  we had \nthree human annotated test sets, spanish, french \nand ukrainian, consisting of newswire",
    "appliqu\u00e9e"
  ],
  [
    "1 spanish language evaluation  \nthe spanish wikipedia is a substantial, well-de-\nveloped wikipedia, consisting of more than \n290,000 articles as of october 2007",
    "appliqu\u00e9e"
  ],
  [
    "  \n \ntable 2: spanish results \n \nf (prec",
    "appliqu\u00e9e"
  ],
  [
    " \n an important question remains: ?how do these \nresults compare to other methodologies??  in par-\nticular, while we can get these results for free, how \nmuch work would traditional methods require to \nachieve comparable results? \n to attempt to answer this question, we trained \nphoenixidf on additional ace 2007 spanish lan-\nguage data converted to muc-style tags, and \nscored its performance using the same set of \nnewswire",
    "appliqu\u00e9e"
  ],
  [
    "2  french language evaluation \nthe french wikipedia is one of the largest \nwikipedias, containing more than 570,000 articles \nas of october 2007",
    "appliqu\u00e9e"
  ],
  [
    "   \n \ntable 4: french results \n \nf (prec",
    "appliqu\u00e9e"
  ],
  [
    " we did not have sufficient quantities of \nannotated data to run a test of the traditional meth-\nods, but spanish and french are sufficiently similar \nlanguages that we expect this model is comparable \nto one created with about 40,000 words of human-\nannotated data",
    "appliqu\u00e9e"
  ],
  [
    "3 ukrainian language evaluation \n \nthe ukrainian wikipedia is a medium-sized \nwikipedia with 74,000 articles as of october 2007",
    "appliqu\u00e9e"
  ],
  [
    " \nalso, the typical article is shorter and less well-\nlinked to other articles than in the french or span-\nish versions",
    "appliqu\u00e9e"
  ],
  [
    " we were also \nable to run a comparison test as in spanish",
    "appliqu\u00e9e"
  ],
  [
    "   \n \ntable 5: ukrainian results \n \nf (prec",
    "appliqu\u00e9e"
  ],
  [
    "761 \n \nthe ukrainian newswire contained a much higher \nproportion of organizations than the french or \nspanish versions, contributing to the overall lower \nscore",
    "appliqu\u00e9e"
  ],
  [
    " the ukrainian language wikipedia itself \ncontains very few articles on organizations relative \nto other types, so the distribution of entities of the \ntwo test sets are quite different",
    "appliqu\u00e9e"
  ],
  [
    " \n \ntable 7: other language results \n \nf-score polish portuguese russian \nall ",
    "appliqu\u00e9e"
  ],
  [
    " \n in the future, we would like to find a way to \nautomatically generate the list of key words and \nphrases for useful english language categories",
    "appliqu\u00e9e"
  ],
  [
    " we also believe perform-\nance could be improved by using higher order non-\nenglish categories and better disambiguation",
    "appliqu\u00e9e"
  ],
  [
    " despite its simplicity, experimental\nresults on classifying the english pronoun it\nshow the system achieves the highest perfor-\nmance yet attained on this important task",
    "appliqu\u00e9e"
  ],
  [
    " in particular, a long-standing\nchallenge has been to correctly classify instances of\nthe english pronoun it",
    "appliqu\u00e9e"
  ],
  [
    "\nthe word it is one of the most frequent words in\nthe english language, accounting for about 1% of\ntokens in text and over a quarter of all third-person\npronouns",
    "appliqu\u00e9e"
  ],
  [
    "\nporting this approach to a new language would re-\nquire not only access to a syntactic parser and a list\nof cognitive verbs in that language, but the devel-\nopment of new patterns to catch non-referential pro-\nnoun uses that do not exist in english",
    "appliqu\u00e9e"
  ],
  [
    " the es in the german ?wie geht es\nihnen? and the il in the french ?s?il vous pla??t? are\nboth non-referential",
    "appliqu\u00e9e"
  ],
  [
    " although we focus on the english\npronoun it, our approach should differentiate any\nwords that have both a structural and a referential\nrole in language, e",
    "appliqu\u00e9e"
  ],
  [
    " we\nalso annotated 709 instances in the wsj portion of\nthe darpa tipster project (harman, 1992), and\n279 instances in the english portion of the europarl\ncorpus (koehn, 2005)",
    "appliqu\u00e9e"
  ],
  [
    "\nsince applying an english stemmer to the con-\ntext words (section 3",
    "appliqu\u00e9e"
  ],
  [
    " for\nexample, if a single form in english (e",
    "appliqu\u00e9e"
  ],
  [
    ", spanish demonstrative ese, nominal ref-\nerence e?se, abstract or statement reference eso, and\ncomplementizer que), then aligned examples pro-\nvide automatically-disambiguated english data",
    "appliqu\u00e9e"
  ],
  [
    "\nido dagan and alan itai",
    "appliqu\u00e9e"
  ],
  [
    " towards the\nautomatic recognition of anaphoric features in english\ntext: the impersonal pronoun ?it?",
    "appliqu\u00e9e"
  ],
  [
    " identification\nand resolution of chinese zero pronouns: a machine\nlearning approach",
    "appliqu\u00e9e"
  ],
  [
    "\nthe collection of queries is a random sample of\nfully-anonymized queries in english submitted by\nweb users in 2006",
    "appliqu\u00e9e"
  ],
  [
    "\naccuracy of class labels: built over many years of\nmanual construction efforts, lexical gold standards\nsuch as wordnet (fellbaum, 1998) provide wide-\ncoverage upper ontologies of the english language",
    "appliqu\u00e9e"
  ],
  [
    " in proceedings of the 45th\nannual meeting of the association for computational\nlinguistics (acl-07), pages 232?239, prague, czech\nrepublic",
    "appliqu\u00e9e"
  ],
  [
    " how is open\nie possible? we analyze a sample of english\nsentences to demonstrate that numerous rela-\ntionships are expressed using a compact set\nof relation-independent lexico-syntactic pat-\nterns, which can be learned by an open ie sys-\ntem",
    "appliqu\u00e9e"
  ],
  [
    "\n? we provide a corpus-based characterization of\nhow binary relationships are expressed in en-\nglish to demonstrate that learning a relation-\nindependent extractor is feasible, at least for the\nenglish language",
    "appliqu\u00e9e"
  ],
  [
    " section 2 assesses the promise of relation-\nindependent extraction for the english language by\ncharacterizing how a sample of relations is ex-\npressed in text",
    "appliqu\u00e9e"
  ],
  [
    "\n2 the nature of relations in english\nhow are relationships expressed in english sen-\ntences? in this section, we show that many rela-\ntionships are consistently expressed using a com-\npact set of relation-independent lexico-syntactic pat-\nterns, and quantify their frequency based on a sam-\nple of 500 sentences selected at random from an ie\ntraining corpus developed by (bunescu andmooney,\n2007)",
    "appliqu\u00e9e"
  ],
  [
    " in the next section, we show how we can use a\nconditional random field, a model that can be de-\nscribed as a finite state machine with weighted tran-\nsitions, to learn a model of how binary relationships\nare expressed in english",
    "appliqu\u00e9e"
  ],
  [
    " 25, 118 00 prague 1, czech republic\nmirovsky@ufal",
    "appliqu\u00e9e"
  ],
  [
    "0 is a manual-\nly annotated corpus of czech",
    "appliqu\u00e9e"
  ],
  [
    "\nin english (lit",
    "appliqu\u00e9e"
  ],
  [
    "2 agreement\nthere are several cases of agreement in czech lan-\nguage, like agreement in case, number and gender \nin attributive adjective phrase, agreement in gender \nand number between predicate and subject (though \nit may be complex), or agreement in case in appo-\nsition",
    "appliqu\u00e9e"
  ],
  [
    "\nacknowledgment\nthis research was supported by the grant agency \nof the academy of sciences of the czech repub-\nlic, project is-rest (no",
    "appliqu\u00e9e"
  ],
  [
    "jp\nabstract\nthis paper presents a comparative evalua-\ntion of several state-of-the-art english parsers\nbased on different frameworks",
    "appliqu\u00e9e"
  ],
  [
    " most state-of-the-art\nparsers for english were trained with the wall street\njournal (wsj) portion of the penn treebank, and\nhigh accuracy has been reported for wsj text; how-\never, these parsers rely on lexical information to at-\ntain high accuracy, and it has been criticized that\nthese parsers may overfit to wsj text (gildea, 2001;\n46\nklein and manning, 2003)",
    "appliqu\u00e9e"
  ],
  [
    " in general, our evaluation methodol-\nogy can be applied to english parsers based on any\nframework; however, in this paper, we chose parsers\nthat were originally developed and trained with the\npenn treebank or its variants, since such parsers can\nbe re-trained with genia, thus allowing for us to\ninvestigate the effect of domain adaptation",
    "appliqu\u00e9e"
  ],
  [
    "\nalthough we restricted ourselves to parsers\ntrainable with penn treebank-style treebanks, our\nmethodology can be applied to any english parsers",
    "appliqu\u00e9e"
  ],
  [
    " extended\nconstituent-to-dependency conversion for english",
    "appliqu\u00e9e"
  ],
  [
    " parsing english\nwith a link grammar",
    "appliqu\u00e9e"
  ],
  [
    "\n57\ngiven a pair of english sentences to be com-\npared (a system translation against a reference\ntranslation), we perform tokenization2 , lemmati-\nzation using wordnet3, and part-of-speech (pos)\ntagging with the mxpost tagger (ratnaparkhi,\n1996)",
    "appliqu\u00e9e"
  ],
  [
    " the workshop used a europarl dataset and a\nnews commentary dataset, where each dataset con-\nsisted of english sentences (2,000 english sentences\nfor europarl and 2,007 english sentences for news\ncommentary) and their translations in various lan-\nguages",
    "appliqu\u00e9e"
  ],
  [
    " as part of the workshop, correlations of\nthe automatic metrics were measured for the tasks\n60\nof translating german, spanish, and french into en-\nglish",
    "appliqu\u00e9e"
  ],
  [
    " for this dataset, human judgements\nare available on adequacy and fluency for six sys-\ntem submissions, and there are four english refer-\nence translation texts",
    "appliqu\u00e9e"
  ],
  [
    " the hungarian method for the assign-\nment problem",
    "appliqu\u00e9e"
  ],
  [
    "\njudges prized conciseness and specificity, and ex-\npected (or at least hoped for) explanations in fluent\nenglish",
    "appliqu\u00e9e"
  ],
  [
    "\n70\nreferences\nido dagan, oren glickman, and bernardo magnini",
    "appliqu\u00e9e"
  ],
  [
    "\ndanilo giampiccolo, bernardo magnini, ido dagan, and\nbill dolan",
    "appliqu\u00e9e"
  ],
  [
    " this complica-\ntion stems from the use of multi-word phrases that\n73\nnobody likes to pay taxes\npersonne n ' aime payer des imp?ts\n(nobody likes) (paying taxes)\n1 2\nfigure 1: an english source tree with translated french\noutput",
    "appliqu\u00e9e"
  ],
  [
    " in this\ncase, we present two candidate french translations\nof an english sentence, assuming there is no entry\nin the phrase table for ?voting session",
    "appliqu\u00e9e"
  ],
  [
    "? because the\nproper french construction is ?session of voting?,\nthe decoder has to move voting after session using a\ndistortion operation",
    "appliqu\u00e9e"
  ],
  [
    " during both discussions, we represent each\ntarget phrase as a set that contains the english tokens\nused in its translation: f?j = {ei|ai = j}",
    "appliqu\u00e9e"
  ],
  [
    "\nin this section we will test the impact of such infor-\nmation on an english to french translation task",
    "appliqu\u00e9e"
  ],
  [
    " since we require source\ndependency trees, all experiments test english to\nfrench translation",
    "appliqu\u00e9e"
  ],
  [
    " english dependency trees are\nprovided by minipar (lin, 1994)",
    "appliqu\u00e9e"
  ],
  [
    " we provide\ntwo human annotators6 a set of 75 english source\nsentences, along with a reference translation and a\npair of translation candidates, one from each sys-\ntem",
    "appliqu\u00e9e"
  ],
  [
    "\n6annotators were both native english speakers who speak\nfrench as a second language",
    "appliqu\u00e9e"
  ],
  [
    " each has a strong comprehension\nof written french",
    "appliqu\u00e9e"
  ],
  [
    " repealed the 1998 directive the ban on advertising\ntable 5: a comparison of baseline and cohesion-constrained english-to-french translations, with english glosses",
    "appliqu\u00e9e"
  ],
  [
    "\n5 discussion\nexamining the french translations produced by our\ncohesion constrained phrasal decoder, we can draw\nsome qualitative generalizations",
    "appliqu\u00e9e"
  ],
  [
    " our cohesion constraint\nremoves this option, forcing the decoder to assem-\nble the correct french construction for ?does not yet\nexist",
    "appliqu\u00e9e"
  ],
  [
    " in this\ncase, we do not have a strong translation mapping to\nproduce a french modifier equivalent to the english\n?banning",
    "appliqu\u00e9e"
  ],
  [
    " chinese syn-\ntactic reordering for statistical machine translation",
    "appliqu\u00e9e"
  ],
  [
    "\n2 a generic phrase training procedure\nlet e = ei1 denote an english sentence and let\nf = fj1 denote its translation in a foreign lan-\nguage, say chinese",
    "appliqu\u00e9e"
  ],
  [
    " we use\ne = eieib and f = f\nje\njb\nto denote an english and\nforeign phrases respectively, where ib(jb) is the po-\nsition in the sentence of the beginning word of the\nenglish(foreign) phrase and ie(je) is the position of\nthe ending word of the phrase",
    "appliqu\u00e9e"
  ],
  [
    " to\ngive an example, the unigram ?tomorrow? in ?the day\nafter tomorrow? whose chinese translation is a sin-\ngle word ??\u0015?",
    "appliqu\u00e9e"
  ],
  [
    "\ngiven a sentence pair, the basic assumption is that\nif the hmm word alignment model can align an en-\nglish phrase well to a foreign phrase, the posterior\ndistribution of the english phrase generating all for-\neign phrases on the other side is significantly biased",
    "appliqu\u00e9e"
  ],
  [
    "\nsimilarly we calculate the confidence metric of\naligning a foreign phrase correctly with the word\nalignment model in foreign to english direction",
    "appliqu\u00e9e"
  ],
  [
    " we do\nexperiments on iwslt (paul, 2006) 2006 chinese-\nenglish corpus",
    "appliqu\u00e9e"
  ],
  [
    " the task is to translate chinese ut-\nterances in travel domain into english",
    "appliqu\u00e9e"
  ],
  [
    "\nthe training corpus consists of 40k chinese-\nenglish parallel sentences in travel domain with to-\neval set 04dev 04test 05test 06dev 06test\n# of sentences 506 500 506 489 500\n# of words 2808 2906 3209 5214 5550\n# of refs 16 16 16 7 7\ntable 2: dev/test set statistics\ntal 306k english words and 295k chinese words",
    "appliqu\u00e9e"
  ],
  [
    "\nin the data processing step, chinese characters are\nsegmented into words",
    "appliqu\u00e9e"
  ],
  [
    " english text are normalized\nand lowercased",
    "appliqu\u00e9e"
  ],
  [
    " the language model is a statistical\ntrigram model estimated with modified kneser-ney\nsmoothing (chen and goodman, 1996) using only\nenglish sentences in the parallel training data",
    "appliqu\u00e9e"
  ],
  [
    "\nstarting from the collection of parallel training\nsentences, we build word alignment models in two\ntranslation directions, from english to chinese and\nfrom chinese to english, and derive two sets of\nviterbi alignments",
    "appliqu\u00e9e"
  ],
  [
    " the maximum number of words in chinese and\nenglish phrases is set to 8 and 25 respectively for all\nconditions2",
    "appliqu\u00e9e"
  ],
  [
    " our experimental results on iwslt chinese-\nenglish corpus have demonstrated consistent and\nsignificant improvement over the widely used word\nalignment matrix based extraction method",
    "appliqu\u00e9e"
  ],
  [
    " in the past, we have classified chi-\nnese text documents using english train-\ning data under the heterogeneous trans-\nfer learning framework",
    "appliqu\u00e9e"
  ],
  [
    " this allows, for example, a\ncollection of chinese text documents to be classi-\nfied using another collection of english text as the\n1\ntraining data (c",
    "appliqu\u00e9e"
  ],
  [
    "\nas the world wide web in china grows rapidly,\nit has become an increasingly important prob-\nlem to be able to accurately classify chinese web\npages",
    "appliqu\u00e9e"
  ],
  [
    " however, because the labeled chinese web\npages are still not sufficient, we often find it diffi-\ncult to achieve high accuracy by applying tradi-\ntional machine learning algorithms to the chinese\nweb pages directly",
    "appliqu\u00e9e"
  ],
  [
    " would it be possible to make\nthe best use of the relatively abundant labeled en-\nglish web pages for classifying the chinese web\npages?\nto answer this question, in (ling et al, 2008),\nwe developed a novel approach for classifying the\nweb pages in chinese using the training docu-\nments in english",
    "appliqu\u00e9e"
  ],
  [
    " the problem to be\nsolved is: we are given a collection of labeled\nenglish documents and a large number of unla-\nbeled chinese documents",
    "appliqu\u00e9e"
  ],
  [
    " the english and chi-\nnese texts are not aligned",
    "appliqu\u00e9e"
  ],
  [
    " our objective is to clas-\nsify the chinese documents into the same label\nspace as the english data",
    "appliqu\u00e9e"
  ],
  [
    " in our work, we first translated the\nchinese document into english automatically us-\ning some available translation software, such as\ngoogle translate",
    "appliqu\u00e9e"
  ],
  [
    " in (ling et al, 2008) we have shown\nhow to classify the chinese text using english text\nas the training data",
    "appliqu\u00e9e"
  ],
  [
    " in acl 2007,\npages 440?447, prague, czech republic",
    "appliqu\u00e9e"
  ],
  [
    " in\nacl 2007, prague, czech republic",
    "appliqu\u00e9e"
  ],
  [
    "\nin acl 2007, pages 256?263, prague, czech republic",
    "appliqu\u00e9e"
  ],
  [
    " in acl 2007, pages 264?\n271, prague, czech republic, june",
    "appliqu\u00e9e"
  ],
  [
    " can chinese web pages be\nclassified with english data source? in www 2008, pages\n969?978, new york, ny, usa",
    "appliqu\u00e9e"
  ],
  [
    " the responses\nfrom both experiments correlate with the\noverlap of paraphrases from the english\nlexical substitution task which bodes well\nfor the use of substitutes as a proxy for\nword sense",
    "appliqu\u00e9e"
  ],
  [
    " in the\nsenseval-3 english lexical task corpus (mihal-\ncea et al, 2004) (hereafter referred to as se-3), the\nratio is much higher at 8% of all markables1",
    "appliqu\u00e9e"
  ],
  [
    " re-\ncently, mccarthy and navigli (2007) proposed\nthe english lexical substitution task (hereafter\nreferred to as lexsub) under the auspices of\nsemeval-2007",
    "appliqu\u00e9e"
  ],
  [
    " the lexsub dataset\ncomprises open class words (nouns, verbs, adjec-\ntives and adverbs) with token instances of each\nword appearing in the context of one sentence\ntaken from the english internet corpus (sharoff,\n2006)",
    "appliqu\u00e9e"
  ],
  [
    " three annotators partic-\nipated in each experiment; all were native british\nenglish speakers",
    "appliqu\u00e9e"
  ],
  [
    " there was a high correlation between\nannotator judgments within and across tasks, as\nwell as with previous word sense annotation and\nwith paraphrases proposed in the english lex-\nical substitution task",
    "appliqu\u00e9e"
  ],
  [
    " in proceedings of the 4th\ninternational workshop on semantic evaluations\n(semeval-2007), pages 7?12, prague, czech repub-\nlic",
    "appliqu\u00e9e"
  ],
  [
    " a usage-based ap-\nproach to spanish verbs of ?becoming?",
    "appliqu\u00e9e"
  ],
  [
    " improving english\nverb sense disambiguation performance with lin-\nguistically motivated features and clear sense dis-\ntinction boundaries",
    "appliqu\u00e9e"
  ],
  [
    " framework\nand results for english senseval",
    "appliqu\u00e9e"
  ],
  [
    " semeval-2007\ntask 10: english lexical substitution task",
    "appliqu\u00e9e"
  ],
  [
    " in pro-\nceedings of the 4th international workshop on se-\nmantic evaluations (semeval-2007), pages 48?53,\nprague, czech republic",
    "appliqu\u00e9e"
  ],
  [
    "\nthe senseval-3 english lexical sample task",
    "appliqu\u00e9e"
  ],
  [
    " in proceedings of the 4th\ninternational workshop on semantic evaluations\n(semeval-2007), pages 30?35, prague, czech re-\npublic",
    "appliqu\u00e9e"
  ],
  [
    " c?2009 acl and afnlp\nunsupervised argument identification for semantic role labeling\nomri abend1 roi reichart2 ari rappoport1\n1institute of computer science , 2icnc\nhebrew university of jerusalem\n{omria01|roiri|arir}@cs",
    "appliqu\u00e9e"
  ],
  [
    " we also obtain an 8% increase in\nprecision for a spanish corpus",
    "appliqu\u00e9e"
  ],
  [
    ", english newspaper texts (see section 2)",
    "appliqu\u00e9e"
  ],
  [
    " in addition,\nwe carried out experiments on spanish (on sen-\ntences of length bounded by 15, excluding punctu-\nation), achieving an increase of over 7",
    "appliqu\u00e9e"
  ],
  [
    "8% improvement\nover the baseline in english and a 2",
    "appliqu\u00e9e"
  ],
  [
    "2% improve-\nment in spanish",
    "appliqu\u00e9e"
  ],
  [
    " english is the most stud-\nied language, using the framenet (fn) (baker et\nal",
    "appliqu\u00e9e"
  ],
  [
    "\nwork has been carried out in a few other lan-\nguages besides english",
    "appliqu\u00e9e"
  ],
  [
    " chinese has been studied\nin (xue, 2008)",
    "appliqu\u00e9e"
  ],
  [
    " experiments on catalan and span-\nish were done in semeval 2007 (ma`rquez et al,\n2007) with two participating systems",
    "appliqu\u00e9e"
  ],
  [
    " attempts\nto compile corpora for german (burdchardt et al,\n2006) and arabic (diab et al, 2008) are also un-\nderway",
    "appliqu\u00e9e"
  ],
  [
    " full constituency syntactic infor-\nmation in an english srl system",
    "appliqu\u00e9e"
  ],
  [
    " we use the taggers mx-\npost (ratnaparkhi, 1996) for english and tree-\ntagger (schmid, 1994) for spanish, to obtain pos\ntags for our model",
    "appliqu\u00e9e"
  ],
  [
    " the english ?that?, the german ?dass?\nand the spanish ?que?",
    "appliqu\u00e9e"
  ],
  [
    "\nfor each verb instance, we traverse over its an-\n31\nenglish\nto + vb",
    "appliqu\u00e9e"
  ],
  [
    "\nspanish\ncque",
    "appliqu\u00e9e"
  ],
  [
    " for english we use the bikel parser default\nhead word rules (bikel, 2004)",
    "appliqu\u00e9e"
  ],
  [
    " we used the propbank corpus for de-\nvelopment and for evaluation on english",
    "appliqu\u00e9e"
  ],
  [
    "3m\nsentences of length at most 15 (excluding punctua-\ntion) extracted from the spanish wikipedia",
    "appliqu\u00e9e"
  ],
  [
    "\nsince our model detects clauses as an interme-\ndiate product, we provide a separate evaluation\nof this task for the english corpus",
    "appliqu\u00e9e"
  ],
  [
    " the left section\npresents results on english and the right section\npresents results on spanish",
    "appliqu\u00e9e"
  ],
  [
    "\nin the ?collocation maximum precision? set-\nting the parameters of the collocation stage (? and\nr) were generally tuned such that maximal preci-\nsion is achieved while preserving a minimal recall\nlevel (40% for english, 20% for spanish on the de-\nvelopment data)",
    "appliqu\u00e9e"
  ],
  [
    " note\nthat for both english and spanish f-score im-\nprovements are achieved via a precision improve-\nment that is more significant than the recall degra-\ndation",
    "appliqu\u00e9e"
  ],
  [
    " in the spanish\nexperiments its f-score (23",
    "appliqu\u00e9e"
  ],
  [
    "87%\nfor english and 51",
    "appliqu\u00e9e"
  ],
  [
    "75%) for english (spanish)",
    "appliqu\u00e9e"
  ],
  [
    "\nto better understand our model?s performance,\nwe performed experiments on the english cor-\npus to test how well its first stage detects clauses",
    "appliqu\u00e9e"
  ],
  [
    " we\nhave experimented on two languages: english and\nspanish",
    "appliqu\u00e9e"
  ],
  [
    " the straightforward adaptability of un-\n34\nenglish (test data) spanish (test data)\nprecision recall f1 precision recall f1\nclause detection 52",
    "appliqu\u00e9e"
  ],
  [
    " results are given for english (ptb, sentences\nlength bounded by 10, left part of the table) and spanish (semeval 2007 spanish srl task, right part of the table)",
    "appliqu\u00e9e"
  ],
  [
    "87% for english and 51",
    "appliqu\u00e9e"
  ],
  [
    "83% for spanish",
    "appliqu\u00e9e"
  ],
  [
    "\n0 2 4 6 8 10\n42\n44\n46\n48\n50\n52\nnumber of sentences (millions)\npr\nec\nisi\non\n \n \nsecond stage\nfirst stage\nbaseline\nfigure 3: the performance of the second stage on english\n(squares) vs",
    "appliqu\u00e9e"
  ],
  [
    " experiments were performed on the english\ndevelopment data",
    "appliqu\u00e9e"
  ],
  [
    "\nour model displayed an increase in precision of\n9% in english and 8% in spanish over a strong\nbaseline",
    "appliqu\u00e9e"
  ],
  [
    "8% in english\nand of 2",
    "appliqu\u00e9e"
  ],
  [
    "2% in spanish over the baseline",
    "appliqu\u00e9e"
  ],
  [
    " the techniques pre-\nsented in this paper are based on this observation,\nusing around 35m sentences in total for english\nand 3",
    "appliqu\u00e9e"
  ],
  [
    "3m sentences for spanish",
    "appliqu\u00e9e"
  ],
  [
    "\naljoscha burchardt, katrin erk, anette frank, andrea\nkowalski, sebastian pad and manfred pinkal, 2006\nthe salsa corpus: a german corpus resource for\nlexical semantics",
    "appliqu\u00e9e"
  ],
  [
    " semeval?2007 task 09: multi-\nlevel semantic annotation of catalan and spanish",
    "appliqu\u00e9e"
  ],
  [
    " labeling chinese predicates\nwith semantic roles",
    "appliqu\u00e9e"
  ],
  [
    " evaluation on\nthe penn chinese treebank indicates that a\nconverted dependency treebank helps con-\nstituency parsing and the use of unlabeled\ndata by self-training further increases pars-\ning f-score to 85",
    "appliqu\u00e9e"
  ],
  [
    " we also have investi-\ngated our two-step solution on two existing tree-\nbanks, the penn chinese treebank (ctb) (xue et\nal",
    "appliqu\u00e9e"
  ],
  [
    ", 2005) and the chinese dependency treebank\n(cdt)2 (liu et al, 2006)",
    "appliqu\u00e9e"
  ],
  [
    "0%\nimprovement (6% error reduction) over the previ-\nous best result for chinese parsing",
    "appliqu\u00e9e"
  ],
  [
    " in section 4, we\nevaluate our two-step solution on two existing het-\nerogeneous chinese treebanks",
    "appliqu\u00e9e"
  ],
  [
    "<world> ?<every> i<country> <\n?<people> ?<all> r<with> 81<eyes>\n? ?<cast> ? l<hong kong>0with\n/people from all over the world are cast-\ning their eyes on hong kong0as its english\ntranslation",
    "appliqu\u00e9e"
  ],
  [
    " according to chinese head percola-\ntion tables used in the ps to ds conversion tool\n/penn2malt03 and charniak?s parser4, the head\nof vp-2 is the word /r0(a preposition, with\n/ba0as its pos tag in ctb), and the head of\nip-obj is ??0",
    "appliqu\u00e9e"
  ],
  [
    "\ncdt consists of 60k chinese sentences, anno-\ntated with pos tag information and dependency\nstructure information (including 28 pos tags, and\n24 dependency tags) (liu et al, 2006)",
    "appliqu\u00e9e"
  ],
  [
    " it motivates us to em-\nploy self-training technique for chinese parsing",
    "appliqu\u00e9e"
  ],
  [
    " our results on chinese data\nconfirm previous findings on english data shown\nin (mcclosky et al, 2006a; reichart and rap-\npoport, 2007)",
    "appliqu\u00e9e"
  ],
  [
    "4 comparison with previous studies for\nchinese parsing\ntable 8 and 9 present the results of previous stud-\nies on ctb",
    "appliqu\u00e9e"
  ],
  [
    " in table 9, petrov\nand klein (2007) trained their model on ctb ar-\nticles 1-270 and 400-1151, and burkett and klein\n(2008) used the same ctb articles and parse trees\nof their english translation (from the english chi-\nnese translation treebank) as training data",
    "appliqu\u00e9e"
  ],
  [
    " collins et al\n(1999) performed statistical constituency parsing\nof czech on a treebank that was converted from\nthe prague dependency treebank under the guid-\nance of conversion rules and heuristic rules, e",
    "appliqu\u00e9e"
  ],
  [
    " moreover, experimental results on the\npenn chinese treebank indicate that a converted\ndependency treebank helps constituency parsing,\nand it is better to exploit probability information\nproduced by the parser through score interpolation\nthan to prune low quality trees for the use of the\nconverted treebank",
    "appliqu\u00e9e"
  ],
  [
    "\nbuilding a treebank for french",
    "appliqu\u00e9e"
  ],
  [
    " two statistical pars-\ning models applied to the chinese treebank",
    "appliqu\u00e9e"
  ],
  [
    "\nsyntactic annotation of a german newspaper corpus",
    "appliqu\u00e9e"
  ],
  [
    " a cor-\nrigendum to sun and jurafsky (2004) shallow semantic\nparsing of chinese",
    "appliqu\u00e9e"
  ],
  [
    " a statistical parser for czech",
    "appliqu\u00e9e"
  ],
  [
    " development and evaluation of a korean treebank\nand its application to nlp",
    "appliqu\u00e9e"
  ],
  [
    " building a\njapanese parsed corpus while improving the parsing sys-\ntem",
    "appliqu\u00e9e"
  ],
  [
    " is it harder to\nparse chinese, or the chinese treebank? in proceedings\nof acl 2003, pages 439-446",
    "appliqu\u00e9e"
  ],
  [
    " building a depen-\ndency treebank for improving chinese parser",
    "appliqu\u00e9e"
  ],
  [
    " journal of\nchinese language and computing, 16(4):207-224",
    "appliqu\u00e9e"
  ],
  [
    " developing a syntactic anno-\ntation scheme and tools for a spanish treebank",
    "appliqu\u00e9e"
  ],
  [
    " a\nfast, accurate deterministic parser for chinese",
    "appliqu\u00e9e"
  ],
  [
    " parsing the penn chinese tree-\nbank with semantic knowledge",
    "appliqu\u00e9e"
  ],
  [
    " the penn chinese treebank: phrase structure an-\nnotation of a large corpus",
    "appliqu\u00e9e"
  ],
  [
    " the proposed method is evaluated\nin english and chinese treebanks",
    "appliqu\u00e9e"
  ],
  [
    " it is\nshown that a translated english treebank\nhelps a chinese parser obtain a state-of-\nthe-art result",
    "appliqu\u00e9e"
  ],
  [
    " as a\ncase study, we consider how to enhance a chinese\ndependency parser by using a translated english\ntreebank",
    "appliqu\u00e9e"
  ],
  [
    " we regard that the\nmorphological issue should be handled aiming at\nthe specific language, our solution here is to use\ncharacter-level features for a target language like\nchinese",
    "appliqu\u00e9e"
  ],
  [
    "\nthe former showed that complementary informa-\ntion about english verbs can be extracted from\ntheir translations in a second language (chinese)\nand the use of multilingual features improves clas-\nsification performance of the english verbs",
    "appliqu\u00e9e"
  ],
  [
    " the first is that they considered a pair of suf-\nficiently related languages, danish and swedish,\nand made full use of the similar characteristics of\ntwo languages",
    "appliqu\u00e9e"
  ],
  [
    " here we consider two quite dif-\nferent languages, english and chinese",
    "appliqu\u00e9e"
  ],
  [
    "1 data\nas a case study, this work will be conducted be-\ntween the source language, english, and the tar-\nget language, chinese, namely, we will investigate\n56\nhow a translated english treebank enhances a chi-\nnese dependency parser",
    "appliqu\u00e9e"
  ],
  [
    "\nfor english data, the penn treebank (ptb) 3\nis used",
    "appliqu\u00e9e"
  ],
  [
    " for chinese data, the chinese treebank\n(ctb) version 4",
    "appliqu\u00e9e"
  ],
  [
    "0 (ldc2002l27),\nand an english to chinese lexicon in stardict2,\nare conflated, with some necessary manual exten-\nsions, to cover 99% words appearing in the ptb\n(the most part of the untranslated words are named\nentities",
    "appliqu\u00e9e"
  ],
  [
    " translate the ptb text into chinese word by\nword",
    "appliqu\u00e9e"
  ],
  [
    " after the target sentence is generated, the at-\ntached pos tags and dependency information of\neach english word will also be transferred to each\ncorresponding chinese word",
    "appliqu\u00e9e"
  ],
  [
    "\nalthough we try to perform an exact word-by-\nword translation, this aim cannot be fully reached\nin fact, as the following case is frequently encoun-\ntered, multiple english words have to be translated\ninto one chinese word",
    "appliqu\u00e9e"
  ],
  [
    " to solve this problem,\nwe use a policy that lets the output chinese word\nonly inherits the attached information of the high-\nest syntactic head in the original multiple english\nwords",
    "appliqu\u00e9e"
  ],
  [
    "\nwhile memory-based and margin-based learn-\ning approaches such as support vector machines\nare popularly applied to shift-reduce parsing, we\napply maximum entropy model as the learning\nmodel for efficient training and adopting over-\nlapped features as our work in (zhao and kit,\n2008), especially, those character-level ones for\nchinese parsing",
    "appliqu\u00e9e"
  ],
  [
    " surprisingly, as to our\nbest knowledge, this is the first report on using this\ntype of features in chinese dependency parsing",
    "appliqu\u00e9e"
  ],
  [
    " as chinese\nis basically a character-based written language",
    "appliqu\u00e9e"
  ],
  [
    "\ncharacter plays an important role in many means,\nmost characters can be formed as single-character\nwords, and chinese itself is character-order free\nrather than word-order free to some extent",
    "appliqu\u00e9e"
  ],
  [
    " in ad-\ndition, there is often a close connection between\nthe meaning of a chinese word and its first or last\ncharacter",
    "appliqu\u00e9e"
  ],
  [
    " then some features based\non a query in these word pairs according to the\ncurrent parsing state (namely, words in the cur-\nrent stack and input) will be derived to enhance\nthe chinese parser",
    "appliqu\u00e9e"
  ],
  [
    "\nin chinese, word lemma is always its word form\nitself, this is a convenient characteristic in com-\nputational linguistics and makes lemma features\nunnecessary for chinese parsing at all",
    "appliqu\u00e9e"
  ],
  [
    " however,\nchinese has a special primary processing task, i",
    "appliqu\u00e9e"
  ],
  [
    " unfortunately, word defini-\ntions for chinese are not consistent in various lin-\nguistical views, for example, seven segmentation\nconventions for computational purpose are for-\nmally proposed since the first bakeoff3",
    "appliqu\u00e9e"
  ],
  [
    "\nnote that ctb or any other chinese treebank\nhas its own word segmentation guideline",
    "appliqu\u00e9e"
  ],
  [
    " however, as we say the\n3bakeoff is a chinese processing share task held by\nsighan",
    "appliqu\u00e9e"
  ],
  [
    "\n59\nenglish treebank is translated into chinese word\nby word, chinese words in the translated text are\nexactly some entries from the bilingual lexicon,\nthey are actually irregular phrases, short sentences\nor something else rather than words that follows\nany existing word segmentation convention",
    "appliqu\u00e9e"
  ],
  [
    " if the\nbilingual lexicon is not carefully selected or re-\nfined according to the treebank where the chinese\nparser is trained from, then there will be a serious\ninconsistence on word segmentation conventions\nbetween the translated and the target treebanks",
    "appliqu\u00e9e"
  ],
  [
    " thus it is somewhat surprising that\nwe show a translated english treebank may help\nchinese parsing, as english and chinese even be-\nlong to two different language systems",
    "appliqu\u00e9e"
  ],
  [
    "\ntable 6 shows such a statistics on the matching\ndegree distribution from all training samples for\nchinese parsing",
    "appliqu\u00e9e"
  ],
  [
    " the ex-\nperimental results in english and chinese tree-\nbanks show the proposed method is effective and\nhelps the chinese parser in this work achieve a\nstate-of-the-art result",
    "appliqu\u00e9e"
  ],
  [
    " for an immediate ex-\nample, we may adopt a translated chinese tree-\nbank to improve english parsing",
    "appliqu\u00e9e"
  ],
  [
    " although there\nare still something to do, the remained key work\nhas been as simple as considering how to deter-\nmine the matching strategy for searching the trans-\nlated word pair list in english according to the\nframework of our method",
    "appliqu\u00e9e"
  ],
  [
    " single malt or\n5for example, catalan and spanish treebanks from the\nancora(-es/ca) multilevel annotated corpus that are an-\nnotated by the universitat de barcelona (clic-ub) and the\nuniversitat polit?cnica de catalunya (upc)",
    "appliqu\u00e9e"
  ],
  [
    " in proceedings of\nacl-2007, pages 616?623, prague, czech republic,\njune",
    "appliqu\u00e9e"
  ],
  [
    " chinese dependency parsing with large\nscale automatically constructed case structures",
    "appliqu\u00e9e"
  ],
  [
    " c?2009 acl and afnlp\ntopological field parsing of german\njackie chi kit cheung\ndepartment of computer science\nuniversity of toronto\ntoronto, on, m5s 3g4, canada\njcheung@cs",
    "appliqu\u00e9e"
  ],
  [
    " we report the results of topo-\nlogical field parsing of german using the\nunlexicalized, latent variable-based berke-\nley parser (petrov et al, 2006) without\nany language- or model-dependent adapta-\ntion, we achieve state-of-the-art results on\nthe tu?ba-d/z corpus, and a modified ne-\ngra corpus that has been automatically\nannotated with topological fields (becker\nand frank, 2002)",
    "appliqu\u00e9e"
  ],
  [
    "\n1 introduction\nfreer-word-order languages such as german ex-\nhibit linguistic phenomena that present unique\nchallenges to traditional cfg parsing",
    "appliqu\u00e9e"
  ],
  [
    "\nwe report the results of parsing german using\nthe unlexicalized, latent variable-based berkeley\nparser (petrov et al, 2006)",
    "appliqu\u00e9e"
  ],
  [
    "\ngerman syntax and parsing have been studied\nusing a variety of grammar formalisms",
    "appliqu\u00e9e"
  ],
  [
    " hocken-\nmaier (2006) has translated the german tiger\ncorpus (brants et al, 2002) into a ccg-based\ntreebank to model word order variations in ger-\nman",
    "appliqu\u00e9e"
  ],
  [
    " foth et al (2004) consider a version of de-\npendency grammars known as weighted constraint\ndependency grammars for parsing german sen-\ntences",
    "appliqu\u00e9e"
  ],
  [
    " this\nparser is later extended by frank et al (2003)\nwith a topological field parser for more efficient\nparsing of german",
    "appliqu\u00e9e"
  ],
  [
    " in neumann et al (2000),\ntopological field parsing is part of a divide-and-\nconquer strategy for shallow analysis of german\ntext with the goal of improving an information ex-\ntraction system",
    "appliqu\u00e9e"
  ],
  [
    "\n2 topological field model of german\ntopological fields are high-level linear fields in\nan enclosing syntactic region, such as a clause\n(ho?hle, 1983)",
    "appliqu\u00e9e"
  ],
  [
    "\ntype fields\nvl (koord) (c) (mf) vc (nf)\nv1 (koord) (lv) lk (mf) (vc) (nf)\nv2 (koord) (lv) vf lk (mf) (vc) (nf)\ntable 1: topological field model of german",
    "appliqu\u00e9e"
  ],
  [
    "\nin the german topological field model, clauses\nbelong to one of three types: verb-last (vl), verb-\nsecond (v2), and verb-first (v1), each with a spe-\ncific sequence of topological fields (table 1)",
    "appliqu\u00e9e"
  ],
  [
    "\nperiments)3 taken from the german newspaper die\ntageszeitung",
    "appliqu\u00e9e"
  ],
  [
    " although we\ncould have trained the model in becker and frank\n(2002) on the tu?ba-d/z corpus, it would not have\n3these are the same splits into training, development, and\ntest sets as in the acl-08 parsing german workshop",
    "appliqu\u00e9e"
  ],
  [
    " no details of the cor-\nrection process were provided in the paper, and de-\nscriptive grammars of german provide insufficient\nguidance on many of the examples in negra on\nissues such as ellipses, short infinitival clauses,\nand expanded participial constructions modifying\nnouns",
    "appliqu\u00e9e"
  ],
  [
    " a stochastic topo-\nlogical parser for german",
    "appliqu\u00e9e"
  ],
  [
    " probabilistic parsing\nfor german using sister-head dependencies",
    "appliqu\u00e9e"
  ],
  [
    " a\nbroad-coverage parser for german based on defea-\nsible constraints",
    "appliqu\u00e9e"
  ],
  [
    " notes on the syntax and the pragmatics\nof german left dislocation",
    "appliqu\u00e9e"
  ],
  [
    " creating a ccgbank and a\nwide-coverage ccg lexicon for german",
    "appliqu\u00e9e"
  ],
  [
    " topological fields chunking for\ngerman with svm?s: optimizing svm-parameters\nwith ga?s",
    "appliqu\u00e9e"
  ],
  [
    " a\ndivide-and-conquer strategy for shallow parsing\nof german free texts",
    "appliqu\u00e9e"
  ],
  [
    " parsing german with\nlatent variable grammars",
    "appliqu\u00e9e"
  ],
  [
    " in proceedings of the\nacl-08: hlt workshop on parsing german (page-\n08), pages 33?39",
    "appliqu\u00e9e"
  ],
  [
    "\nthe tu?ba-d/z treebank: annotating german with a\ncontext-free backbone",
    "appliqu\u00e9e"
  ],
  [
    " stylebook for the tubingen tree-\nbank of written german (tu?ba-d/z)",
    "appliqu\u00e9e"
  ],
  [
    " topolog-\nical field chunking for german",
    "appliqu\u00e9e"
  ],
  [
    " for instance, the english sentence i\nsaw [the student [from mit]] exhibits the classic\nproblem of pp-attachment ambiguity",
    "appliqu\u00e9e"
  ],
  [
    " however,\nits urdu translation, literally glossed as i [[mit of ]\nstudent] saw, uses a genitive phrase that may only\nbe attached to the adjacent noun phrase",
    "appliqu\u00e9e"
  ],
  [
    " know-\ning the correspondence between these sentences\nshould help us resolve the english ambiguity",
    "appliqu\u00e9e"
  ],
  [
    "\nwe test the effectiveness of our bilingual gram-\nmar induction model on three corpora of parallel\ntext: english-korean, english-urdu and english-\nchinese",
    "appliqu\u00e9e"
  ],
  [
    " for example, suppose the constituent my\nlong name is node-aligned to its urdu translation\nmera lamba naam",
    "appliqu\u00e9e"
  ],
  [
    " if however,\nthe english word long were (incorrectly) aligned\nunder giza++ to some urdu word outside the cor-\nresponding constituent, then the score would drop\nto 1",
    "appliqu\u00e9e"
  ],
  [
    "\ndata the penn korean treebank (han et al,\n2002) consists of 5,083 korean sentences trans-\nlated into english for the purposes of language\ntraining in a military setting",
    "appliqu\u00e9e"
  ],
  [
    " both the korean\nand english sentences are annotated with syntactic\ntrees",
    "appliqu\u00e9e"
  ],
  [
    " we note\nthat in the korean data, a separate tag is given for\n2sampling the alignment tree is important, as it provides\nus with counts of aligned constituents for the coupling pa-\nrameter",
    "appliqu\u00e9e"
  ],
  [
    " the english-urdu par-\nallel corpus3 consists of 4,325 sentences from the\nfirst three sections of the penn treebank and their\nurdu translations annotated at the part-of-speech\nlevel",
    "appliqu\u00e9e"
  ],
  [
    " the urdu side of this corpus does not pro-\nvide tree annotations so here we can test parse ac-\ncuracy only on english",
    "appliqu\u00e9e"
  ],
  [
    " we use the remaining\nsections of the penn treebank for english test-\ning",
    "appliqu\u00e9e"
  ],
  [
    " the english-chinese treebank (bies et al,\n2007) consists of 3,850 chinese newswire sen-\ntences translated into english",
    "appliqu\u00e9e"
  ],
  [
    " both the english\nand chinese sentences are annotated with parse\ntrees",
    "appliqu\u00e9e"
  ],
  [
    " for korean we found that the\nbaseline performed well using these values",
    "appliqu\u00e9e"
  ],
  [
    " how-\never, on our english and chinese data, we found\nthat somewhat higher smoothing values worked\nbest, so we utilized values of 20 and 80 for con-\nstituent and distituent smoothing counts, respec-\ntively",
    "appliqu\u00e9e"
  ],
  [
    "\nfor instance, the smallest improvement is ob-\nserved for english when trained with urdu",
    "appliqu\u00e9e"
  ],
  [
    " the\nkorean-english pairing results in substantial im-\nprovements for korean and quite large improve-\nments for english, for which the absolute gain\nreaches 28 points in f-measure",
    "appliqu\u00e9e"
  ],
  [
    " in the case of chi-\nnese and english, the gains for english are fairly\nminimal whereas those for chinese are quite sub-\n79\nmax sent",
    "appliqu\u00e9e"
  ],
  [
    " this asymmetry should not be surprising,\nas chinese on its own seems to be quite a bit more\ndifficult to parse than english",
    "appliqu\u00e9e"
  ],
  [
    " for the baseline, how-\never, adding this additional training data degrades\nperformance in the case of english paired with ko-\nrean",
    "appliqu\u00e9e"
  ],
  [
    " english chinese translation treebank\nv 1",
    "appliqu\u00e9e"
  ],
  [
    " penn korean treebank: development and\nevaluation",
    "appliqu\u00e9e"
  ],
  [
    " bilingual\nparsing with factored estimation: using english to\nparse korean",
    "appliqu\u00e9e"
  ],
  [
    " as another example, our\n8as in previous work, english evaluation ignores any to-\nken whose gold-standard pos tag is one of {?? ?? : , ",
    "appliqu\u00e9e"
  ],
  [
    "9m\ntable 1: effect of the marginal-probability beam\non english parsing",
    "appliqu\u00e9e"
  ],
  [
    " for each beam value, parsers\nwere trained on the english training set and evalu-\nated on the english validation set; the same beam\nvalue was applied to both training and validation\ndata",
    "appliqu\u00e9e"
  ],
  [
    " for perspec-\ntive, the english training set has a total of 39,832\nsentences and 950,028 words",
    "appliqu\u00e9e"
  ],
  [
    "4 main results\ntable 2 lists the accuracy of models 1 and 2 on the\nenglish and czech test sets, together with some\nrelevant results from related work",
    "appliqu\u00e9e"
  ],
  [
    " c?2010 association for computational linguistics\ndependency parsing and projection based on word-pair classification\nwenbin jiang and qun liu\nkey laboratory of intelligent information processing\ninstitute of computing technology\nchinese academy of sciences\np",
    "appliqu\u00e9e"
  ],
  [
    " the classifier\ntrained on the chinese projected classification in-\nstances achieves a precision of 58",
    "appliqu\u00e9e"
  ],
  [
    " for the 2nd-order mst\nparser trained on penn chinese treebank (ctb)\n5",
    "appliqu\u00e9e"
  ],
  [
    " we define a boolean-valued\nfunction ?(y, i, j, r) to investigate the dependency\nrelationship of word i and word j in parse tree y:\n?(y, i, j, r) =\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n1\n(i, j) ? y and r = +\nor\n(i, j) /? y and r = ?\n0 otherwise\n(7)\nthen the score that word i and word j in the target\nsentence y forms a projected dependency edge,\nfigure 2: the word alignment matrix between a\nchinese sentence and its english translation",
    "appliqu\u00e9e"
  ],
  [
    "\nthanks to the reminding of the third reviewer\nof our paper, we find that the pairwise classifica-\ntion schema has also been used in japanese de-\npendency parsing (uchimoto et al, 1999; kudo\nand matsumoto, 2000)",
    "appliqu\u00e9e"
  ],
  [
    " lu? et al (2002) aims to\nobtain chinese bracketing knowledge via itg\n(wu, 1997) alignment",
    "appliqu\u00e9e"
  ],
  [
    "1 word-pair classification model\nwe experiment on two popular treebanks, the wall\nstreet journal (wsj) portion of the penn english\ntreebank (marcus et al, 1993), and the penn chi-\nnese treebank (ctb) 5",
    "appliqu\u00e9e"
  ],
  [
    " curves in fig-\nure 3 show the performance of the english and\nchinese parsers, each of which is trained on an in-\nstance set corresponding to a certain r",
    "appliqu\u00e9e"
  ],
  [
    " we find\nthat for both english and chinese, maximum per-\nformance is achieved at about r = 2",
    "appliqu\u00e9e"
  ],
  [
    " 3 the\nenglish and chinese classifiers trained on the in-\nstance sets with r = 2",
    "appliqu\u00e9e"
  ],
  [
    " on both english and chinese,\nthe word-pair classification model falls behind of\nthe state-of-the-art",
    "appliqu\u00e9e"
  ],
  [
    "2 dependency projection\nin this work we focus on the dependency projec-\ntion from english to chinese",
    "appliqu\u00e9e"
  ],
  [
    " both english and chinese sentences\nare tagged by the implementations of the pos tag-\nger of collins (2002), which trained on wsj and\nctb 5",
    "appliqu\u00e9e"
  ],
  [
    " the english sentences are\nthen parsed by an implementation of 2nd-ordered\nmst model of mcdonald and pereira (2006),\nwhich is trained on dependency trees extracted\nfrom wsj",
    "appliqu\u00e9e"
  ],
  [
    " au-\ntomatic adaptation of annotation standards: chinese\nword segmentation and pos tagging?a case study",
    "appliqu\u00e9e"
  ],
  [
    " japanese de-\npendency structure analysis based on support vector\nmachines",
    "appliqu\u00e9e"
  ],
  [
    " learning chinese bracketing knowledge\nbased on a bilingual language model",
    "appliqu\u00e9e"
  ],
  [
    " deterministic depen-\ndency parsing of english text",
    "appliqu\u00e9e"
  ],
  [
    " japanese dependency structure analysis\nbased on maximum entropy models",
    "appliqu\u00e9e"
  ],
  [
    " the penn chinese treebank: phrase\nstructure annotation of a large corpus",
    "appliqu\u00e9e"
  ],
  [
    " experiments on the\ntranslated portion of the chinese treebank\nshow that our system outperforms mono-\nlingual parsers by 2",
    "appliqu\u00e9e"
  ],
  [
    "93 points for chinese\nand 1",
    "appliqu\u00e9e"
  ],
  [
    "64 points for english",
    "appliqu\u00e9e"
  ],
  [
    "\nexperiments on the translated portion of the\nchinese treebank (xue et al, 2002; bies et al,\n2007) show that our system outperforms state-of-\nthe-art monolingual parsers by 2",
    "appliqu\u00e9e"
  ],
  [
    "\nin the english side, it is difficult for a parser to\ndetermine the head of word ?with? because there\nis a pp-attachment problem",
    "appliqu\u00e9e"
  ],
  [
    " however, in chinese\nit is unambiguous",
    "appliqu\u00e9e"
  ],
  [
    " therefore, we can use the in-\nformation on the chinese side to help disambigua-\nhe  ate    the    meat with     a    fork    ",
    "appliqu\u00e9e"
  ],
  [
    " we obtain their corresponding\nwords ??(meat)?, ??(use)?, and ???(fork)? in\nchinese via the word alignment links",
    "appliqu\u00e9e"
  ],
  [
    " we ver-\nify that the corresponding words form a subtree\nby looking up a subtree list in chinese (described\nin section 4",
    "appliqu\u00e9e"
  ],
  [
    "1 reordering and mton mapping in\ntranslation\nboth chinese and english are classified as svo\nlanguages because verbs precede objects in simple\nsentences",
    "appliqu\u00e9e"
  ],
  [
    " however, chinese has many character-\nistics of such sov languages as japanese",
    "appliqu\u00e9e"
  ],
  [
    " in en-\nglish the prepositional phrase ?at the ceremony?\nfollows the verb ?said?, while its corresponding\nprepositional phrase ??(null)??(ceremony)\n?(at)? precedes the verb ??(say)? in chinese",
    "appliqu\u00e9e"
  ],
  [
    " in chinese the relative\nclause ???(today) ??(signed)? precedes the\nhead noun ???(project)?, while its correspond-\ning clause ?signed today? follows the head noun\n?projects? in english",
    "appliqu\u00e9e"
  ],
  [
    " for example, we extract subtree ??\n?(society):2-??(fringe):0? on the chinese side\nand get its corresponding subtree ?fringes(w 2):0-\nof:1-society(w 1):2? on the english side, where\nw 1 means that the target word is aligned to the\nfirst word of the source subtree, and w 2 means\nthat the target word is aligned to the second word\nof the source subtree",
    "appliqu\u00e9e"
  ],
  [
    "\nthe extracted subtree pairs indicate the trans-\nlation characteristics between chinese and en-\nglish",
    "appliqu\u00e9e"
  ],
  [
    "\n5 experiments\nall the bilingual data were taken from the trans-\nlated portion of the chinese treebank (ctb)\n(xue et al, 2002; bies et al, 2007), articles\n1-325 of ctb, which have english translations\nwith gold-standard parse trees",
    "appliqu\u00e9e"
  ],
  [
    "\nfor chinese unannotated data, we used the\nxin cmn portion of chinese gigaword version\n2",
    "appliqu\u00e9e"
  ],
  [
    " for english\nunannotated data, we used the bllip corpus that\ncontains about 43 million words of wsj text",
    "appliqu\u00e9e"
  ],
  [
    " as in the\nchinese experiments, the parsers with bilingual\nsubtree features outperformed the baselines",
    "appliqu\u00e9e"
  ],
  [
    "\nchinese english\nhuang2009 86",
    "appliqu\u00e9e"
  ],
  [
    " in pro-\nceedings of the 45th annual meeting of the asso-\nciation of computational linguistics, pages 17?24,\nprague, czech republic, june",
    "appliqu\u00e9e"
  ],
  [
    " tagged chinese gigaword\nversion 2",
    "appliqu\u00e9e"
  ],
  [
    " an error-driven word-character hy-\nbrid model for joint chinese word segmentation and\npos tagging",
    "appliqu\u00e9e"
  ],
  [
    " building a large-scale annotated chinese cor-\npus",
    "appliqu\u00e9e"
  ],
  [
    " we will argue that\nthe automatic identification of generic expressions\nshould be cast as a machine learning problem in-\nstead of a rule-based approach, as there is (i) no\ntransparent marking of genericity in english (as in\nmost other european languages) and (ii) the phe-\nnomenon is highly context dependent",
    "appliqu\u00e9e"
  ],
  [
    " parsing was done using the english lfg\ngrammar (cf",
    "appliqu\u00e9e"
  ],
  [
    " reference to kinds in\nenglish",
    "appliqu\u00e9e"
  ],
  [
    " c?2010 association for computational linguistics\nstructural semantic relatedness: a knowledge-based method to \nnamed entity disambiguation \n \nxianpei han        jun zhao? \nnational laboratory of pattern recognition  \n institute of automation, chinese academy of sciences \nbeijing 100190, china  \n{xphan,jzhao}@nlpr",
    "appliqu\u00e9e"
  ],
  [
    " wikipedia1, a large-scale online encyc-\nlopedia, its english version includes more than \n3,000,000 concepts and new articles are added \nquickly and up-to-date",
    "appliqu\u00e9e"
  ],
  [
    "02 (fellbaum et al, 1998), a \nlexical knowledge source includes over 110,000 \nwordnet concepts (word senses about english \nwords)",
    "appliqu\u00e9e"
  ],
  [
    " 9, \n2007 english version of wikipedia; and the web \npages of each ambiguous name in weps datasets \nas the ne co-occurrence corpus",
    "appliqu\u00e9e"
  ],
  [
    " mann and yarowsky (2003) and niu \net al (2004) extended the vector representation \nwith extracted biographic facts",
    "appliqu\u00e9e"
  ],
  [
    " \nniu c",
    "appliqu\u00e9e"
  ],
  [
    " the average \nchinese character error rate (cer) obtained for \nthe 205 spoken documents was about 35%",
    "appliqu\u00e9e"
  ],
  [
    " a comparative study of probabilistic \nranking models for chinese spoken document \nsummarization",
    "appliqu\u00e9e"
  ],
  [
    " matbn: a mandarin chinese \nbroadcast news corpus",
    "appliqu\u00e9e"
  ],
  [
    " international journal of \ncomputational linguistics and chinese language \nprocessing, 10, (2): 219 - 236",
    "appliqu\u00e9e"
  ],
  [
    "2 further, to mitigate badly estimated\npscfg derivations based on low-frequency rules of\nthe much sparser syntax model, the syntax grammar\nalso contains the hierarchical grammar as a back-\nbone (cf",
    "appliqu\u00e9e"
  ],
  [
    "6m\nsentence pairs (206m chinese and 228m english\nwords)",
    "appliqu\u00e9e"
  ],
  [
    "\nin proceedings of the 45th annual meeting of the as-\nsociation of computational linguistics, prague, czech\nrepublic, june",
    "appliqu\u00e9e"
  ],
  [
    " we frame the mt problem as a de-\ncipherment task, treating the foreign text as\na cipher for english and present novel meth-\nods for training translation models from non-\nparallel text",
    "appliqu\u00e9e"
  ],
  [
    "\nin our case, we observe a large number of foreign\nstrings f , and we apply maximum likelihood train-\ning:\nargmax\n?\n?\nf\np?(f) (3)\nfollowing weaver (1955), we imagine that this cor-\npus of foreign strings ?is really written in english,\nbut has been coded in some strange symbols,? thus:\nargmax\n?\n?\nf\n?\ne\np (e) ? p?(f |e) (4)\nthe variable e ranges over all possible english\nstrings, and p (e) is a language model built from\nlarge amounts of english text that is unrelated to the\nforeign strings",
    "appliqu\u00e9e"
  ],
  [
    " we note that for each\nf , not only is the alignment a still hidden, but now\nthe english translation e is hidden as well",
    "appliqu\u00e9e"
  ],
  [
    "\nfor example, the following english plaintext se-\nquences:\ni saw the boy ",
    "appliqu\u00e9e"
  ],
  [
    " generate an english plaintext sequence e =\ne1",
    "appliqu\u00e9e"
  ],
  [
    "\nwe model p (e) using a statistical word n-gram\nenglish language model (lm)",
    "appliqu\u00e9e"
  ],
  [
    "\nwe use the same generative story as before for\ndecipherment, except that we use chinese restau-\nrant process (crp) formulations for the source and\nchannel probabilities",
    "appliqu\u00e9e"
  ],
  [
    " we use an english word bi-\ngram lm as the base distribution (p0) for the source\nmodel and specify a uniform p0 distribution for the\n14\nchannel",
    "appliqu\u00e9e"
  ],
  [
    "\nsmart sample-choice selection: in the original\nsampling step, for each cipher token we have to sam-\nple from a list of all possible plaintext choices (10k-\n1m english words)",
    "appliqu\u00e9e"
  ],
  [
    "\nsay that our current plaintext hypothesis contains\nenglish words x, y and z at positions i ? 1, i and\ni+1 respectively",
    "appliqu\u00e9e"
  ],
  [
    " in order to sample at position i, we\nchoose the topk english words y ranked by p (x y\nz), which can be computed offline from a statistical\nword bigram lm",
    "appliqu\u00e9e"
  ],
  [
    " we then use the viterbi algo-\nrithm to choose the english plaintext e that maxi-\nmizes p (e) ? p?trained(c|e)\n3",
    "appliqu\u00e9e"
  ],
  [
    "3 experiments and results\ndata: for the word substitution experiments, we use\ntwo corpora:\n? temporal expression corpus containing short\nenglish temporal expressions such as ?the\nnext month?, ?the last three\nyears?, etc",
    "appliqu\u00e9e"
  ],
  [
    "\nwe also have access to a separate english\ncorpus (which is not parallel to the ciphertext)\ncontaining 125k temporal expressions (242k\nword tokens, 201 word types) for lm training",
    "appliqu\u00e9e"
  ],
  [
    "\n? transtac corpus containing full english sen-\ntences",
    "appliqu\u00e9e"
  ],
  [
    " the data consists of 10k cipher sen-\ntences (102k tokens, 3397 word types); and\na plaintext corpus of 402k english sentences\n(2",
    "appliqu\u00e9e"
  ],
  [
    "\nthe cipher data was originally generated from en-\nglish text by substituting each english word with a\nunique cipher word",
    "appliqu\u00e9e"
  ],
  [
    "\nbuild an english word n-gram lm, which is used in\nthe decipherment process",
    "appliqu\u00e9e"
  ],
  [
    "\nfigure 2: comparison of the original (o) english plain-\ntext with output from bayesian word substitution deci-\npherment (d) for a few samples cipher (c) sentences\nfrom the transtac corpus",
    "appliqu\u00e9e"
  ],
  [
    "fm) and a monolingual\nenglish corpus, our goal is to decipher the foreign\ntext and produce an english translation",
    "appliqu\u00e9e"
  ],
  [
    " from equa-\ntion 4 we have:\nargmax\n?\n?\nf\n?\ne\np (e) ? p?(f |e)\nfor p (e), we use a word n-gram lm trained on\nmonolingual english data",
    "appliqu\u00e9e"
  ],
  [
    " generate an english string e = e1",
    "appliqu\u00e9e"
  ],
  [
    " for each english word token ei (including\nnulls), choose a foreign word translation fi,\nwith probability p?(fi|ei)",
    "appliqu\u00e9e"
  ],
  [
    " finally, we use the viterbi algo-\nrithm to decode the foreign sentence f and pro-\nduce an english translation e that maximizes p (e) ?\np?trained(f |e)",
    "appliqu\u00e9e"
  ],
  [
    "\nwhole-segment language models: when using\nword n-gram models of english for decipherment,\nwe find that some of the foreign sentences are\ndecoded into sequences (such as ?thank you\ntalking about ??) that are not good english",
    "appliqu\u00e9e"
  ],
  [
    "\nthis stems from the fact that n-gram lms have no\nglobal information about what constitutes a valid\nenglish segment",
    "appliqu\u00e9e"
  ],
  [
    " to learn this information auto-\nmatically, we build a p (e) model that only recog-\nnizes english whole-segments (entire sentences or\nexpressions) observed in the monolingual training\ndata",
    "appliqu\u00e9e"
  ],
  [
    " recall the generative story for ibm model\n3 translation which has the following formula:\np?(f, a|e) =\nl?\ni=0\nt?(faj |ei) ?\nl?\ni=1\nn?(?i|ei)\n?\nm?\naj 6=0,j=1\nd?(aj |i, l,m) ?\nl?\ni=0\n?i!\n?\n1\n?0!\n?\n(\nm? ?0\n?0\n)\n?p?01? ? p\nm?2?0\n0?\n(8)\nthe alignment a is represented as a vector; aj = i\nimplies that the foreign word fj is produced by the\nenglish word ei during translation",
    "appliqu\u00e9e"
  ],
  [
    " in order to apply bayesian inference for de-\ncipherment, we model each of these tables using a\n17\nchinese restaurant process (crp) formulation",
    "appliqu\u00e9e"
  ],
  [
    "\nthe sampler is seeded with an initial english sample\ntranslation and a corresponding alignment for every\nforeign sentence",
    "appliqu\u00e9e"
  ],
  [
    " we define several sampling oper-\nators, which are applied in sequence one after the\nother to generate english samples for the entire for-\neign corpus",
    "appliqu\u00e9e"
  ],
  [
    " some of the sampling operators are de-\nscribed below:\n? translateword(j): sample a new english word\ntranslation for foreign word fj , from all possi-\nbilities (including null)",
    "appliqu\u00e9e"
  ],
  [
    "\n? swapsegment(i1, i2): swap the alignment\nlinks for english words ei1 and ei2 ",
    "appliqu\u00e9e"
  ],
  [
    "\n? joinwords(i1, i2): eliminate the english word\nei1 and transfer its links to the word ei2 ",
    "appliqu\u00e9e"
  ],
  [
    "\nthese small-change operators are similar to the\nheuristic techniques used for greedy decoding by\ngerman et al (2001)",
    "appliqu\u00e9e"
  ],
  [
    "5\nchoosing the best translation: once the sampling\nrun finishes, we select the final sample and extract\nthe corresponding english translations for every for-\neign sentence",
    "appliqu\u00e9e"
  ],
  [
    "3 mt experiments and results\ndata: we work with the spanish/english language\npair and use the following corpora in our mt exper-\niments:\n? time corpus: we mined english newswire\ntext on the web and collected 295k tempo-\nral expressions such as ?last year?, ?the\nfourth quarter?, ?in jan 1968?, etc",
    "appliqu\u00e9e"
  ],
  [
    " we\nthen translate the english temporal phrases into\nspanish using an automatic translation soft-\nware (google translate) followed by manual\nannotation to correct mistakes made by the\nsoftware",
    "appliqu\u00e9e"
  ],
  [
    "\nboth spanish/english sides of train are used for\nparallel mt training, whereas decipherment uses\nonly monolingual english data for training lms",
    "appliqu\u00e9e"
  ],
  [
    "\nevaluation: all the mt systems are run on the\nspanish test data and the quality of the result-\ning english translations are evaluated using two\ndifferent measures?(1) normalized edit distance\nscore (navarro, 2001),6 and (2) bleu (papineni et\n6when computing edit distance, we account for substitu-\ntions, insertions, deletions as well as local-swap edit operations\nrequired to convert a given english string into the (gold) refer-\nence translation",
    "appliqu\u00e9e"
  ],
  [
    " we see that deciphering with\n10k monolingual spanish sentences yields the same\nperformance as training with around 200-500 paral-\nlel english/spanish sentence pairs",
    "appliqu\u00e9e"
  ],
  [
    " extensive\nexperiments involving large-scale english-to-\njapanese translation revealed a significant im-\nprovement of 1",
    "appliqu\u00e9e"
  ],
  [
    " compared with flat phrases, syntactic rules are\ngood at capturing global reordering, which has been\nreported to be essential for translating between lan-\nguages with substantial structural differences, such\nas english and japanese, which is a subject-object-\nverb language (xu et al, 2009)",
    "appliqu\u00e9e"
  ],
  [
    " more-\nover, we found that most japanese function words\ntend to align to a few english words such as ?of?\nand ?the?, which may appear anywhere in an english\nsentence",
    "appliqu\u00e9e"
  ],
  [
    " following these problematic alignments,\nwe are forced to make use of relatively large english\ntree fragments to construct translation rules that tend\nto be ill-formed and less generalized",
    "appliqu\u00e9e"
  ],
  [
    "1 japanese function words\nin the present paper, we limit our discussion\non japanese particles and auxiliary verbs (martin,\n1975)",
    "appliqu\u00e9e"
  ],
  [
    " particles are suffixes or tokens in japanese\ngrammar that immediately follow modified con-\ntent words or sentences",
    "appliqu\u00e9e"
  ],
  [
    " there are eight types of\njapanese function words, which are classified de-\npending on what function they serve: case markers,\nparallel markers, sentence ending particles, interjec-\n1these numbers are language/corpus-dependent and are not\nnecessarily to be taken as a general reflection of the overall qual-\nity of the word alignments for arbitrary language pairs",
    "appliqu\u00e9e"
  ],
  [
    "\njapanese grammar also uses auxiliary verbs to\ngive further semantic or syntactic information about\nthe preceding main or full verb",
    "appliqu\u00e9e"
  ],
  [
    " alike english, the\nextra meaning provided by a japanese auxiliary verb\nalters the basic meaning of the main verb so that the\nmain verb has one or more of the following func-\ntions: passive voice, progressive aspect, perfect as-\npect, modality, dummy, or emphasis",
    "appliqu\u00e9e"
  ],
  [
    "2 hpsg forests\nfollowing our precious work (wu et al, 2010), we\nuse head-drive phrase structure grammar (hpsg)\nforests generated by enju2 (miyao and tsujii, 2008),\nwhich is a state-of-the-art hpsg parser for english",
    "appliqu\u00e9e"
  ],
  [
    " the chunk-level\ndependency tree for the japanese sentence is shown as well",
    "appliqu\u00e9e"
  ],
  [
    " for example, by ignoring the ambiguous\nalignments on the japanese function words, we en-\nlarge the frontier set to include from 12 to 19 of the\n24 non-terminal nodes",
    "appliqu\u00e9e"
  ],
  [
    "\nin the english-to-japanese translation test case of\nthe present study, the target chunk set is yielded\nby a state-of-the-art japanese dependency parser,\ncabocha v0",
    "appliqu\u00e9e"
  ],
  [
    " for\nexample, the japanese sentence in figure 1 is sepa-\nrated into four chunks, and the dependencies among\nthese chunks are identified by arrows",
    "appliqu\u00e9e"
  ],
  [
    "1 setup\nwe implemented the forest-to-string decoder de-\nscribed in (mi et al, 2008) that makes use of forest-\nbased translation rules (mi and huang, 2008) as\nthe baseline system for translating english hpsg\nforests into japanese sentences",
    "appliqu\u00e9e"
  ],
  [
    " here, en = english\nand jp = japanese",
    "appliqu\u00e9e"
  ],
  [
    " note that japanese function words oc-\ncupy more than a quarter of the japanese words",
    "appliqu\u00e9e"
  ],
  [
    "jp\n27\nc3-t m&h-f min-f c3-f\nfree fw y n y y\nalignment a? a a? a?\nenglish side tree forest forest forest\n# rule 86",
    "appliqu\u00e9e"
  ],
  [
    " the sri language modeling toolkit\n(stolcke, 2002) was employed to train a five-gram\njapanese lm on the training set",
    "appliqu\u00e9e"
  ],
  [
    " a reference grammar of\njapanese",
    "appliqu\u00e9e"
  ],
  [
    " in pro-\nceedings of the 2007 joint conference on empir-\nical methods in natural language processing and\ncomputational natural language learning (emnlp-\nconll), pages 360?368, prague, czech republic,\njune",
    "appliqu\u00e9e"
  ],
  [
    " a japanese-\nenglish patent parallel corpus",
    "appliqu\u00e9e"
  ],
  [
    "ca\nabstract\nthis paper extends the training and tun-\ning regime for phrase-based statistical ma-\nchine translation to obtain fluent trans-\nlations into morphologically complex lan-\nguages (we build an english to finnish\ntranslation system)",
    "appliqu\u00e9e"
  ],
  [
    "\nwe show, using both automatic evaluation\nscores and linguistically motivated analy-\nses of the output, that our methods out-\nperform previously proposed ones and pro-\nvide the best known results on the english-\nfinnish europarl translation task",
    "appliqu\u00e9e"
  ],
  [
    " rather\nthan focusing on a few linguistically motivated\naspects of finnish morphological behaviour, we\ndevelop techniques for handling morphological\ncomplexity in general",
    "appliqu\u00e9e"
  ],
  [
    " we chose finnish as our\ntarget language for this work, because it ex-\nemplifies many of the problems morphologically\ncomplex languages present for smt",
    "appliqu\u00e9e"
  ],
  [
    " among all\nthe languages in the europarl data-set, finnish\nis the most difficult language to translate from\nand into, as was demonstrated in the mt sum-\nmit shared task (koehn, 2005)",
    "appliqu\u00e9e"
  ],
  [
    " another reason\nis the current lack of knowledge about how to ap-\nply smt successfully to agglutinative languages\nlike turkish or finnish",
    "appliqu\u00e9e"
  ],
  [
    " we hypothesize that this may\nbe an inherently difficult representational form\nfor a language with the degree of morphologi-\ncal complexity found in finnish",
    "appliqu\u00e9e"
  ],
  [
    "org/projects/sgd\n34\nmorphological pre-processing\nenglish training data finnish training datawords\nstem+ +morph\nwords\npost-process:morph re-stitching\nstem+ +morph\nevaluation against original reference\nfully inflected surface form\nmt systemalignment:word          word          word\nstem+      +morph        stem\n(a) segmented translation model\nmorphlgica pe-ci-gsnetdrrrrrrrrrrnetdrrrrrrrrrrnetd\nlgictrrrrrtcetfwdtrrrrrlgic\nmetfwe eepm+ r:tir:temillp-erdenglish?training?data finnish?training?datanetdl\nlgictrtcetfwdt\nnetdl\n:elgr:temillrdsmetfwrsirpgpgmwp-e\nlgictrtcetfwdt\n:elgr:temillrvsrusfmetfwe eehryi-it+gpe-\nmecf iarlgicsrlgictcetfwdt ?+-e?+eirmedi l?t?+mir?etcrc+ffp-elgictcetfwdtrtcetfwv\n?? ?+gpe-r+e+p-lgretpep-+ rti?iti-mi\nf?  hrp-? imgidrl?t?+mir?etc\nmetfwe eepm+ r:tir:temillp-ervlgictrtcetfwdtrtcetfwv\n(b) post-processing model translation & generation\nfigure 1: training and testing pipelines for the smt models",
    "appliqu\u00e9e"
  ],
  [
    " the\ncrf model was trained on a ?210,000 finnish\nsentences, consisting of ?1",
    "appliqu\u00e9e"
  ],
  [
    " the labels in the output\nsequence y were obtained by selecting the most\nproductive 150 stems, and then collapsing cer-\ntain vowels into equivalence classes correspond-\ning to finnish vowel harmony patterns",
    "appliqu\u00e9e"
  ],
  [
    "\nfinnish adjectives must be marked with the\nsame case as their head noun, while verbs must\nagree in person and number with their subject",
    "appliqu\u00e9e"
  ],
  [
    "\nin addition, finnish generally marks di-\nrect objects of verbs with the accusative\nor the partitive case; we observed more\naccusative/partitive-marked nouns following\nverbs in the crf-lm output than in the base-\nline, as illustrated by example (1) in fig",
    "appliqu\u00e9e"
  ],
  [
    " finnish postposi-\ntions require the preceding noun to be in the\ngenitive or sometimes partitive case, which oc-\ncurs correctly more frequently in the crf-lm\nthan the baseline",
    "appliqu\u00e9e"
  ],
  [
    " 3,\nall three translations correspond to the english\ntext, ?with the basque nationalists",
    "appliqu\u00e9e"
  ],
  [
    "\nin addition, while finnish may express pos-\nsession using case marking alone, it has another\nconstruction for possession; this can disam-\nbiguate an otherwise ambiguous clause",
    "appliqu\u00e9e"
  ],
  [
    " while (koehn and hoang, 2007; yang\nand kirchhoff, 2006; avramidis and koehn,\n2008) obtain improvements using factored mod-\nels for translation into english, german, span-\nish, and czech, these models may be less useful\nfor capturing long-distance dependencies in lan-\nguages with much more complex morphological\nsystems such as finnish",
    "appliqu\u00e9e"
  ],
  [
    "?\n(2) input: ?with the basque nationalists?\na",
    "appliqu\u00e9e"
  ],
  [
    " they use a segmented phrase table and\nlanguage model along with the word-based ver-\nsions in the decoder and in tuning a finnish tar-\nget",
    "appliqu\u00e9e"
  ],
  [
    " popovic? and ney (2004)\nperform segmentation to reduce morphological\ncomplexity of the source to translate into an iso-\nlating target, reducing the translation error rate\nfor the english target",
    "appliqu\u00e9e"
  ],
  [
    " for czech-to-english,\ngoldwater and mcclosky (2005) lemmatized the\nsource text and inserted a set of ?pseudowords?\nexpected to have lexical reflexes in english",
    "appliqu\u00e9e"
  ],
  [
    " de gispert (2008) uses\na language-specific targeted morphological clas-\nsifier for spanish verbs to avoid this issue",
    "appliqu\u00e9e"
  ],
  [
    "\nusing our proposed approach we obtain better\nscores than the state of the art on the english-\nfinnish translation task (luong et al, 2010):\nfrom 14",
    "appliqu\u00e9e"
  ],
  [
    " we\nalso demonstrate that for finnish (and possi-\nbly other agglutinative languages), phrase-based\nmt benefits from allowing the translation model\naccess to morphological segmentation yielding\nproductive morphological phrases",
    "appliqu\u00e9e"
  ],
  [
    " we\nwould particularly like to thank the developers\nof the open-source moses machine translation\ntoolkit and the omorfi morphological analyzer\nfor finnish which we used for our experiments",
    "appliqu\u00e9e"
  ],
  [
    " optimizing chinese word seg-\nmentation for machine translation performance",
    "appliqu\u00e9e"
  ],
  [
    " on the\nimpact of morphology in english to spanish sta-\ntistical mt",
    "appliqu\u00e9e"
  ],
  [
    " in proceedings of the confer-\nence on empirical methods in natural language\nprocessing (emnlp), pages 868?876, prague,\nczech republic",
    "appliqu\u00e9e"
  ],
  [
    " in acl ?07: proceedings of\nthe 45th annual meeting of the acl on inter-\nactive poster and demonstration sessions, pages\n177?108, prague, czech republic",
    "appliqu\u00e9e"
  ],
  [
    "\nin proceedings of the 45th annual meeting of the\nassociation of computational linguistics, pages\n304?311, prague, czech republic",
    "appliqu\u00e9e"
  ],
  [
    " in in proceedings of the\n45th annual meeting of the association for com-\nputational linguistics (acl07), pages 128?135,\nprague, czech republic",
    "appliqu\u00e9e"
  ],
  [
    " case markers and morphology: address-\ning the crux of the fluency problem in english-\nhindi smt",
    "appliqu\u00e9e"
  ],
  [
    "\n3 experimental setup\nto make sure that the data we use in our simula-\ntion is as close to real-world data as possible, we do\nnot create an artificial data set as done in (schein\nand ungar, 2007; reidsma and carletta, 2008) but\nuse real data from a wsd task for the german verb\ndrohen (threaten)",
    "appliqu\u00e9e"
  ],
  [
    "\n6 acknowledgments\nthis work was funded by the german research\nfoundation dfg (grant pi 154/9-3)",
    "appliqu\u00e9e"
  ],
  [
    " in proceedings of the\n2007 joint conference on empirical methods in natu-\nral language processing and computational natural\nlanguage learning, prague, czech republic",
    "appliqu\u00e9e"
  ],
  [
    "\n7 experiments\nwe report experiments on translation from chinese\nto english, using the tree-to-string model described\n8in fact in our experiments we use the original hypergraph\nto compute admissible outside scores for an exact a* search\nalgorithm for this problem",
    "appliqu\u00e9e"
  ],
  [
    " in\nproceedings of the 45th annual meeting of the asso-\nciation of computational linguistics, pages 144?151,\nprague, czech republic, june",
    "appliqu\u00e9e"
  ],
  [
    " in our exper-\niment, only english docs8 at level 3 of the cate-\ngory tree are utilized to evaluate the performance",
    "appliqu\u00e9e"
  ],
  [
    " manuale di economica politica,\n(translated into english by a",
    "appliqu\u00e9e"
  ],
  [
    " for a\npreference pair xj = (x(1)j ,x\n(2)\nj ) where x\n(1)\nj is pre-\nferred over x(2)j , and x?j = x\n(1)\nj ? x\n(2)\nj , we consider\nthe following hinge loss-type objective function:\nlj(w) = (??w, x?j ?)+\nwhere (a)+ = max(0, a) , w ? ird is a weight vec-\ntor, and ??, ?? denotes the standard vector dot prod-\nuct",
    "appliqu\u00e9e"
  ],
  [
    " all data was tokenized and\nlowercased; german compounds were split (dyer,\n2009)",
    "appliqu\u00e9e"
  ],
  [
    " for the 5-gram language\nmodels, we replaced every word in the lm training\ndata with <unk> that did not appear in the english\npart of the parallel training data to build an open vo-\ncabulary language model",
    "appliqu\u00e9e"
  ],
  [
    " the cmu-ark german-\nenglish translation system",
    "appliqu\u00e9e"
  ],
  [
    " in proceedings of emnlp-\nconll, prague, czech republic",
    "appliqu\u00e9e"
  ],
  [
    " in proceedings of the 2007\n20\njoint conference on empirical mehtods in natural\nlanguage processing and computational language\nlearning (emnlp?07), prague, czech republic",
    "appliqu\u00e9e"
  ],
  [
    " handwriting input\noffers a more convenient input method for writing\nsystems with complex orthography, including many\nasian languages such as chinese, japanese and ko-\nrean",
    "appliqu\u00e9e"
  ],
  [
    " 3 yields:\np (w,l|o,h) ?\np(o|w)? p(h|l)? p (l|w)? p (w)(4)\nit is evident from the above equation that the prob-\nabilistic formulation of hvr combines four knowl-\nedge sources:\n33\nfigure 1: examples of single-stroke handwriting gestures for the 26 english letters\n? acoustic model score: p(o|w)\n? haptic model score: p(h|l)\n? pli model score: p (l|w)\n? language model score: p (w)\nnote that the acoustic model and language model\nscores are already used in the conventional asr",
    "appliqu\u00e9e"
  ],
  [
    " for\neach configuration, 250 sentences were collected\nfrom a non-native fluent english speaker",
    "appliqu\u00e9e"
  ],
  [
    " we apply our model\nto the timit corpus, and the results demon-\nstrate that our model discovers sub-word units\nthat are highly correlated with english phones\nand also produces better segmentation than the\nstate-of-the-art unsupervised baseline",
    "appliqu\u00e9e"
  ],
  [
    " our model\nshows its ability to discover sub-word units that are\nhighly correlated with standard english phones and\nto capture acoustic context information",
    "appliqu\u00e9e"
  ],
  [
    "\nwe compare our unsupervised acoustic model\nwith three supervised ones: 1) an english triphone\nmodel, 2) an english monophone model and 3) a\nthai monophone model",
    "appliqu\u00e9e"
  ],
  [
    " the first two were trained\non timit, while the thai monophone model was\ntrained with 32 hour clean read thai speech from\nthe lotus corpus (kasuriya et al, 2003)",
    "appliqu\u00e9e"
  ],
  [
    " each circle represents a\nmapping pair for a cluster label and an english\nphone",
    "appliqu\u00e9e"
  ],
  [
    "\ncorrelation between the cluster labels and individ-\nual english phones",
    "appliqu\u00e9e"
  ],
  [
    " this context-dependent rela-\ntionship is also observed in other english phones\nand their corresponding sets of clusters",
    "appliqu\u00e9e"
  ],
  [
    " the english triphone model achieves the best\np@n and eer results and performs slightly bet-\nter than the english monophone model, which indi-\ncates a correlation between the quality of an acous-\ntic model and its performance on the spoken term\ndetection task",
    "appliqu\u00e9e"
  ],
  [
    " although our unsupervised model\ndoes not perform as well as the supervised english\n47\nunit(%) p@n eer\nenglish triphone 75",
    "appliqu\u00e9e"
  ],
  [
    "7\nenglish monophone 74",
    "appliqu\u00e9e"
  ],
  [
    "8\nthai monophone 56",
    "appliqu\u00e9e"
  ],
  [
    "\nacoustic models, it generates a comparable eer and\na more accurate detection performance for top hits\nthan the thai monophone model",
    "appliqu\u00e9e"
  ],
  [
    " without any prior\n48\nknowledge, this method is able to discover phonetic\nunits that are closely related to english phones, im-\nprove upon state-of-the-art unsupervised segmenta-\ntion method and generate more precise spoken term\ndetection performance on the timit dataset",
    "appliqu\u00e9e"
  ],
  [
    "\nacknowledgements\nthe authors would like to thank hung-an chang and\nekapol chuangsuwanich for training the english\nand thai acoustic models",
    "appliqu\u00e9e"
  ],
  [
    " thai speech corpus for thai\nspeech recognition",
    "appliqu\u00e9e"
  ],
  [
    " c?2012 association for computational linguistics\nautomated essay scoring based on finite state transducer: towards asr\ntranscription of oral english speech\nxingyuan peng?, dengfeng ke?, bo xu??\n?digital content technology and services research center\n?national lab of pattern recognition\ninstitute of automation, chinese academy of sciences\nno",
    "appliqu\u00e9e"
  ],
  [
    "\nin this paper, our evaluation objects are the oral\nenglish picture compositions in english as a sec-\nond language (esl) examination",
    "appliqu\u00e9e"
  ],
  [
    " as the evaluating ob-\njects are from an oral english picture composition\nexamination, it has two important features that make\nthe fst algorithm quite suitable",
    "appliqu\u00e9e"
  ],
  [
    " our experimental data is acquired in\nan oral english examination for esl students",
    "appliqu\u00e9e"
  ],
  [
    "\nalso, we presented the result of using lsa-svr\napproach as a contrast experiment to show the im-\nprovement of our fst model in scoring oral english\npicture composition",
    "appliqu\u00e9e"
  ],
  [
    " however, in\ncertain situations, such as towards asr transcription\nof oral english speech, its weakness of sequence ne-\nglect will be magnified, leading to drastic decline of\nperformance",
    "appliqu\u00e9e"
  ],
  [
    " it is an error insensitive mod-\nel under the task of automated oral english picture\ncomposition scoring",
    "appliqu\u00e9e"
  ],
  [
    " auto-\nmated japanese essay scoring system: jess",
    "appliqu\u00e9e"
  ],
  [
    " automated chinese essay scoring using\nvector space models",
    "appliqu\u00e9e"
  ],
  [
    " c?2012 association for computational linguistics\npdtb-style discourse annotation of chinese text\nyuping zhou\ncomputer science department\nbrandeis university\nwaltham, ma 02452\nyzhou@brandeis",
    "appliqu\u00e9e"
  ],
  [
    "edu\nabstract\nwe describe a discourse annotation scheme\nfor chinese and report on the preliminary re-\nsults",
    "appliqu\u00e9e"
  ],
  [
    " our scheme, inspired by the penn dis-\ncourse treebank (pdtb), adopts the lexically\ngrounded approach; at the same time, it makes\nadaptations based on the linguistic and statisti-\ncal characteristics of chinese text",
    "appliqu\u00e9e"
  ],
  [
    "\nin this paper we describe a discourse annota-\ntion scheme for chinese that adopts this lexically\ngrounded approach while making adaptations when\nwarranted by the linguistic and statistical properties\nof chinese text",
    "appliqu\u00e9e"
  ],
  [
    " in\nsection 3, we first show that some key features of\nchinese make adaptations necessary in section 3",
    "appliqu\u00e9e"
  ],
  [
    "\n3 adapted scheme for chinese\n3",
    "appliqu\u00e9e"
  ],
  [
    "1 key characteristics of chinese text\ndespite similarities in discourse features between\nchinese and english (xue, 2005), there are differ-\nences that have a significant impact on how dis-\ncourse relations could be best annotated",
    "appliqu\u00e9e"
  ],
  [
    " because all that is said\nis about the pilot program, it is perfectly natural to\ninclude it all in a single sentence in chinese",
    "appliqu\u00e9e"
  ],
  [
    " if we apply the\npdtb scheme to the english translation, regardless\nof whether the two pieces of facts are expressed in\ntwo sentences or two semi-colon-separated clauses,\nat least one discourse relation will be annotated, re-\nlating these two text units",
    "appliqu\u00e9e"
  ],
  [
    " in contrast, if we apply\nthe same scheme to the chinese sentence, no dis-\ncourse relation will be picked out because this is\njust one comma-separated sentence with no explicit\ndiscourse connectives in it",
    "appliqu\u00e9e"
  ],
  [
    " in other words, the dis-\ncourse relation within the chinese sentence, which\nwould be captured in its english counterpart follow-\ning the pdtb procedure, would be lost when anno-\ntating chinese",
    "appliqu\u00e9e"
  ],
  [
    " such loss is not a sporadic occur-\nrence but rather a very prevalent one since it is asso-\nciated with the customary writing style of chinese",
    "appliqu\u00e9e"
  ],
  [
    "\nto ensure a reasonable level of coverage, we need to\nconsider comma-delimited intra-sentential implicit\nrelations when annotating chinese text",
    "appliqu\u00e9e"
  ],
  [
    " we think, however,\nthat disambiguating the commas in chinese text is\nvaluable in its own right and is a necessary step in\nannotating discourse relations",
    "appliqu\u00e9e"
  ],
  [
    " they, judging\nfrom their english translation, may seem clear cases\nof free adjuncts in pdtb terms (prasad et al, 2007),\nbut there is no justification for treating them as such\nin chinese",
    "appliqu\u00e9e"
  ],
  [
    " for ex-\nample, one can be reasonably certain that ??\n?? (?acknowledge?) functions as a verb in (5),\nhowever, there is no indication whether it is\nin the form corresponding to ?acknowledging?\nor ?acknowledged? in english",
    "appliqu\u00e9e"
  ],
  [
    " or putting it\ndifferently, whether one wants to express in\nchinese the meaning corresponding to the -ing\nform or the tensed form in english, the same\nform ???? could apply",
    "appliqu\u00e9e"
  ],
  [
    "\nthese basic decisions directly based on linguistic\ncharacteristics of chinese lead to more systematic\nadaptations to the annotation scheme, to which we\nwill turn in the next subsection",
    "appliqu\u00e9e"
  ],
  [
    " according to a rough count on\n20 randomly selected files from chinese treebank\n(xue et al, 2005), 82% are tokens of implicit rela-\ntion, compared to 54",
    "appliqu\u00e9e"
  ],
  [
    " when annotating chinese text, maintaining\nthis procedural division makes much less sense: the\nlandscape of discourse relation (or at least the key\nelements of it) has already been mapped out by the\npdtb work and to set up a separate task to cover\n18% of the data does not seem like a worthwhile\nbother without additional benefits for doing so",
    "appliqu\u00e9e"
  ],
  [
    "\ncertainly not if one interprets the term literally ; but\nin a broader sense, our approach can be seen as an\ninstantiation of a generalized version of it, much the\nsame way that the pdtb is an, albeit different, in-\nstantiation of it for english",
    "appliqu\u00e9e"
  ],
  [
    " so this restriction is not applicable\nfor chinese annotation",
    "appliqu\u00e9e"
  ],
  [
    " in addi-\ntion, the phenomenon of parallel connectives is pre-\ndominant in chinese",
    "appliqu\u00e9e"
  ],
  [
    " parallel connectives are pairs\nof connectives that take the same arguments, exam-\nples of which in english are ?if",
    "appliqu\u00e9e"
  ],
  [
    " (8) below presents\ntwo such examples, for which parallel connectives\nare not possible in english",
    "appliqu\u00e9e"
  ],
  [
    "\nso the situation with chinese is that distinguish-\ning arg1 and arg2 the pdtb way is meaningless\nin most cases, and in the remaining cases, it of-\nten results in duplication",
    "appliqu\u00e9e"
  ],
  [
    " the data\nset consists of 98 files taken from the chinese tree-\nbank (xue et al, 2005)",
    "appliqu\u00e9e"
  ],
  [
    "\nchinese pdtb\ntkn no",
    "appliqu\u00e9e"
  ],
  [
    "9)\ntable 1: inter-annotator agreement in various aspects\nof chinese discourse annotation: rel-ident, discourse\nrelation identification; rel-type, relation type classifica-\ntion; imp-sns-type, classification of sense type of im-\nplicit relations; arg-order, order determination of arg1\nand arg2",
    "appliqu\u00e9e"
  ],
  [
    "\n5 conclusions\nwe have presented a discourse annotation scheme\nfor chinese that adopts the lexically ground ap-\nproach of the pdtb while making systematic adap-\ntations motivated by characteristics of chinese text",
    "appliqu\u00e9e"
  ],
  [
    " annotating the discourse con-\nnectives in the chinese treebank",
    "appliqu\u00e9e"
  ],
  [
    "\n1\nzongtong jiang yu siyue lai lundun fangwen\nthe president will visit london in april\nsource phrase target phrase dependency category\nr1 fangwen visit {} fixed\nr2 yu siyue in april {1? 2} fixed\nr3 zongtong jiang the president will {2? 1} floating left\nr4 yu siyue lai lundun london in april {2? 3} floating right\nr5 zongtong jiang president will {} ill-formed\nfigure 1: a training example consisting of a (romanized) chinese sentence, an english dependency\ntree, and the word alignment between them",
    "appliqu\u00e9e"
  ],
  [
    "\nwe evaluate our method on the nist chinese-\nenglish translation datasets",
    "appliqu\u00e9e"
  ],
  [
    "\n2 shift-reduce parsing for phrase-based\nstring-to-dependency translation\nfigure 1 shows a training example consisting of\na (romanized) chinese sentence, an english de-\npendency tree, and the word alignment between\nthem",
    "appliqu\u00e9e"
  ],
  [
    "\n5 experiments\nwe evaluated our phrase-based string-to-\ndependency translation system on chinese-\nenglish translation",
    "appliqu\u00e9e"
  ],
  [
    "0m chinese\nwords and 82",
    "appliqu\u00e9e"
  ],
  [
    "2m english words",
    "appliqu\u00e9e"
  ],
  [
    " we used the\nstanford parser (klein and manning, 2003) to\nget dependency trees for english sentences",
    "appliqu\u00e9e"
  ],
  [
    "\n4-gram language model on the xinhua portion of\nthe gigaword coprus, which contians 238m\nenglish words",
    "appliqu\u00e9e"
  ],
  [
    " a 3-gram dependency language\nmodel was trained on the english dependency\ntrees",
    "appliqu\u00e9e"
  ],
  [
    " we used the 2002 nist mt chinese-\nenglish dataset as the development set and the\n2003-2005 nist datasets as the testsets",
    "appliqu\u00e9e"
  ],
  [
    " c?2013 association for computational linguistics\nintegrating translation memory into phrase-based \nmachine translation during decoding \n \n \nkun wang?        chengqing zong?        keh-yih su? \n?national laboratory of pattern recognition, institute of automation, \nchinese academy of sciences, beijing, china \n?behavior design corporation, taiwan \n?\n{kunwang, cqzong}@nlpr",
    "appliqu\u00e9e"
  ],
  [
    " the \naverage length of chinese sentences is 13",
    "appliqu\u00e9e"
  ],
  [
    "85 \nwords and that of english sentences is 13",
    "appliqu\u00e9e"
  ],
  [
    "62 ter points reduction on a chinese?\nenglish tm database",
    "appliqu\u00e9e"
  ],
  [
    " \n2011aa01a207, 2012aa011101, and \n2012aa011102 and also supported by the key \nproject of knowledge innovation program of \nchinese academy of sciences under grant \nno",
    "appliqu\u00e9e"
  ],
  [
    " a framework of a mechanical \ntranslation between japanese and english by anal-\nogy principle",
    "appliqu\u00e9e"
  ],
  [
    " likelihoods\n(the quantity to be minimized) arising in training\ndeficient and nondeficient models (for europarl\ngerman | english, training scheme 15h53545)",
    "appliqu\u00e9e"
  ],
  [
    " , fj)\nwith j words and an english one e = ei1 =\n(e1, ",
    "appliqu\u00e9e"
  ],
  [
    " , ei) with i words, the (conditional) proba-\nbility p(fj1 |ei1) of getting the foreign sentence as a\ntranslation of the english one is modeled by intro-\nducing the word alignment a as a hidden variable:\np(fj1 |ei1) =\n?\na\np(fj1 ,a|ei1)\nall ibm models restrict the space of alignments\nto those where a foreign word can align to at most\none target word",
    "appliqu\u00e9e"
  ],
  [
    " the resulting alignment is then\nwritten as a vector aj1 , where each aj takes integral\nvalues between 0 and i , with 0 indicating that fj\nhas no english correspondence",
    "appliqu\u00e9e"
  ],
  [
    "\nthe fertility-based models ibm-3, ibm-4\nand ibm-5 factor the (conditional) probability\np(fj1 , aj1 |ei1) of obtaining an alignment and a\ntranslation given an english sentence according to\nthe following generative story:\n23\n1",
    "appliqu\u00e9e"
  ],
  [
    " since each foreign word be-\nlongs to exactly one english position (includ-\ning 0), the foreign sequence is now known to\nbe of length j = ?ii=0 ?i",
    "appliqu\u00e9e"
  ],
  [
    "2 ibm-4\nthe distortion model of the ibm-4 is a first order\none that generates the di,k of each english position\ni in ascending order (i",
    "appliqu\u00e9e"
  ],
  [
    "\nthe ibm-4 has two sub-distortion models, one\nfor the first aligned word (k = 1) of an english po-\nsition and one for all following words (k > 1, only\n24\nif ?i > 1)",
    "appliqu\u00e9e"
  ],
  [
    " now, the distortion probability for the\nfirst word (k = 1) is\np=1(di,1|\f[i],a(fi,1),b(e[i]), j) ,\nwhere a gives the word class of a foreign word\nand b the word class of an english word (there are\ntypically 50 classes per language, derived by ma-\nchine learning techniques)",
    "appliqu\u00e9e"
  ],
  [
    " with\nthis strategy words can no longer be placed out-\nside the sentence, but a lot of probability mass is\nstill wasted on configurations where at least one\nforeign (or predicted) position j aligns to two or\nmore positions i, i? in the english (or given) lan-\nguage (and consequently there are more unaligned\n4if the set is empty, instead a sentence start probability\nis used",
    "appliqu\u00e9e"
  ],
  [
    " for p=1(?) we have one prob-\nlem for each foreign class ? and each english class\n?, of the form\nmax\n{p=1(j|j?,?,?)}\n?\nj,j?,j\nwj,j?,j,?,? log\n(\np=1(j|j?, ?, ?, j)\n)\nfor reduced deficiency (with p=1(j|j?, ?, ?, j) as\nin (3) ) and of the form\nmax\n{p=1(j|j?,?,?)}\n?\nj,j?,j\nwj,j?,j ,?,? log\n(\np=1(j|j?, ?, ?,j )\n)\n28\nmodel degree of deficiency de|en en|de es|en en|es\nhmm nondeficient (our) 73",
    "appliqu\u00e9e"
  ],
  [
    "\n5 experiments\nwe test the proposed methods on subsets of the\neuroparl corpus for german and english as well\nas spanish and english, using lower-cased cor-\npora",
    "appliqu\u00e9e"
  ],
  [
    "2 effect on translation performance\nwe also check the effect of the various align-\nments (all produced by regaligner) on trans-\nlation performance for phrase-based translation,\nrandomly choosing translation from german to\nenglish",
    "appliqu\u00e9e"
  ],
  [
    "84\ntable 2: evaluation of phrase-based translation\nfrom german to english with the obtained align-\nments (for 100",
    "appliqu\u00e9e"
  ],
  [
    " in conference on\nempirical methods in natural language processing\n(emnlp), prague, czech republic, june",
    "appliqu\u00e9e"
  ],
  [
    " the english source sen-\ntences are a subset of wmt09-12 test sets",
    "appliqu\u00e9e"
  ],
  [
    " the\nspanish mt outputs were created using a standard\npbsmt moses engine",
    "appliqu\u00e9e"
  ],
  [
    " it contains 299 english sen-\ntences translated into spanish using two or more\nof eight mt systems randomly selected from all\nsystem submissions for wmt11 (callison-burch\net al, 2011)",
    "appliqu\u00e9e"
  ],
  [
    " in the 45th annual meeting of the associ-\nation for computational linguistics, prague, czech\nrepublic",
    "appliqu\u00e9e"
  ],
  [
    "\nnote that while we use english phrases, like to\nthe left of, to refer to particular bins of particular\nfeatures, and we have object detectors which we\ntrain on samples of a particular object class such\nas backpack, such phrases are only mnemonic of\nthe clustering and object-detector training process",
    "appliqu\u00e9e"
  ],
  [
    " higgins and sadock (2003), which\nwe refer to as hs03, developed the first statisti-\ncal qsd system for english",
    "appliqu\u00e9e"
  ],
  [
    " handling scope ambiguities in\nenglish",
    "appliqu\u00e9e"
  ],
  [
    " a corpus of scope-disambiguated english\ntext",
    "appliqu\u00e9e"
  ],
  [
    "\ngiven an english text document, an event ex-\ntraction system should predict event triggers with\nspecific subtypes and their arguments from each\nsentence",
    "appliqu\u00e9e"
  ],
  [
    " brown clusters that are learned from ace english corpus (brown et al, 1992; miller et\nal",
    "appliqu\u00e9e"
  ],
  [
    " language specific\nissue and feature exploration in chinese event ex-\ntraction",
    "appliqu\u00e9e"
  ],
  [
    " joint modeling for\nchinese event extraction with rich linguistic features",
    "appliqu\u00e9e"
  ],
  [
    " nyu?s english ace 2005 system description",
    "appliqu\u00e9e"
  ],
  [
    " employing compositional seman-\ntics and discourse consistency in chinese event ex-\ntraction",
    "appliqu\u00e9e"
  ],
  [
    " we achieve state-of-the-art ac-\ncuracy on all languages in the tempeval-\n2 temporal normalization task, reporting\na 4% improvement in both english and\nspanish accuracy, and to our knowledge\nthe first results for four other languages",
    "appliqu\u00e9e"
  ],
  [
    " of these, heideltime (stro?tgen and gertz,\n2010) and sutime (chang and manning, 2012)\nprovide a strong comparison in english",
    "appliqu\u00e9e"
  ],
  [
    "\nin addition, there has been work on pars-\ning spanish expressions; uc3m (vicente-d??ez et\nal",
    "appliqu\u00e9e"
  ],
  [
    " of the systems entered in the\noriginal task, tipsem (llorens et al, 2010) was\nthe only system to perform bilingual interpreta-\ntion for english and spanish",
    "appliqu\u00e9e"
  ],
  [
    "\nto approximate the m step, we define a multi-\nclass hinge loss l(?) over the beam, and optimize\nusing stochastic gradient descent with adagrad\n(duchi et al, 2010):\nl(?) = max\n0?i<k\n1[?i 6= ??] + p?(?i)? p?(??) (2)\nwe proceed to describe our features",
    "appliqu\u00e9e"
  ],
  [
    "76\ntable 3: english results for tempeval-2 attribute\nscores for our system and four previous systems",
    "appliqu\u00e9e"
  ],
  [
    "76\ntable 4: spanish results for tempeval-2 attribute\nscores for our system and the best known previ-\nous system",
    "appliqu\u00e9e"
  ],
  [
    "\n5 evaluation\nwe evaluate our model on all six languages in\nthe tempeval-2 task a dataset (verhagen et al,\n2010), comparing against state-of-the-art systems\nfor english and spanish",
    "appliqu\u00e9e"
  ],
  [
    "\nthe dataset annotates six languages: english,\nspanish, italian, french, chinese, and korean; of\nthese, english and spanish are the most mature",
    "appliqu\u00e9e"
  ],
  [
    "\nwe describe each of these languages, along with\nrelevant quirks, below:\nenglish the english dataset consists of 1052\ntraining examples, and 156 test examples",
    "appliqu\u00e9e"
  ],
  [
    "\nspanish the spanish dataset consists of 1092\ntraining examples, and 198 test examples",
    "appliqu\u00e9e"
  ],
  [
    "\nitalian the italian dataset consists of 523 train-\ning examples, and 126 test examples",
    "appliqu\u00e9e"
  ],
  [
    " evaluation\nwas identical to english and spanish",
    "appliqu\u00e9e"
  ],
  [
    "\nchinese the chinese dataset consists of 744\ntraining examples, and 190 test examples",
    "appliqu\u00e9e"
  ],
  [
    "\nthe chinese, korean, and french corpora had\nnoticeable inconsistencies in the timex3 anno-\ntation",
    "appliqu\u00e9e"
  ],
  [
    " thus, evaluations are reported according\n89\ntrain test\nlanguage # examples type value # examples type value\nenglish 1052 0",
    "appliqu\u00e9e"
  ],
  [
    "76\nspanish 1092 0",
    "appliqu\u00e9e"
  ],
  [
    "76\nitalian 523 0",
    "appliqu\u00e9e"
  ],
  [
    "48\nchinese (clean)? 659 0",
    "appliqu\u00e9e"
  ],
  [
    " chinese is divided into two\nresults: one for the entire corpus, and one which considers only examples for which a temporal value\nis annotated",
    "appliqu\u00e9e"
  ],
  [
    "\nkorean the korean dataset consists of 287\ntraining examples, and 91 test examples",
    "appliqu\u00e9e"
  ],
  [
    " evaluation was done\nidentically to the chinese data",
    "appliqu\u00e9e"
  ],
  [
    "\nfrench lastly, a dataset for french temporal\nexpressions was compiled from the tempeval-2\ndata",
    "appliqu\u00e9e"
  ],
  [
    " unlike the other 5 languages, the french\ndata included only the raw timex3 annotated\nnewswire documents, encoded as xml",
    "appliqu\u00e9e"
  ],
  [
    " evaluation was\ndone identically to the chinese and korean data",
    "appliqu\u00e9e"
  ],
  [
    "2 results\nwe compare our system with state-of-the-art sys-\ntems for both english and spanish",
    "appliqu\u00e9e"
  ],
  [
    "\n? sutime (chang and manning, 2012), a more\nrecent rule-based system for english",
    "appliqu\u00e9e"
  ],
  [
    "\n? uc3m (vicente-d??ez et al, 2010), a rule-\nbased system for spanish",
    "appliqu\u00e9e"
  ],
  [
    "\nresults for the english corpus are shown in ta-\nble 3",
    "appliqu\u00e9e"
  ],
  [
    " results for spanish are shown in table 4",
    "appliqu\u00e9e"
  ],
  [
    " this is consistent with what would be\nexpected from a discriminatively trained model\nin data-impoverished settings; however, the con-\nsistent training accuracy suggests that the model\nnonetheless captures the phenomena it sees in\n90\nerror class english spanish\npragmatics 29% 23%\ntype error 16% 5%\nincorrect number 10% 5%\nrelative range 7% 2%\nincorrect parse 19% 36%\nmissing context 16% 23%\nbad reference time 3% 6%\ntable 6: a summary of errors of our system,\nby percentage of incorrect examples for the en-\nglish and spanish datasets",
    "appliqu\u00e9e"
  ],
  [
    "3 discussion\nwe characterize the examples our system parses\nincorrectly on the english and spanish datasets in\ntable 6, expanding on each class of error below",
    "appliqu\u00e9e"
  ],
  [
    "\ntype error another large class of errors ? par-\nticularly in the english dataset ? arise from not\nmatching the annotation?s type, but otherwise pro-\nducing a reasonable response",
    "appliqu\u00e9e"
  ],
  [
    " a small sub-\nset of these errors (notably, 6% on the spanish\ndataset) are a result of the grammar being insuf-\nficiently expressive with the preterminals we de-\nfined",
    "appliqu\u00e9e"
  ],
  [
    " in the\n93\nthe turkish government fell after mob-tie allegations",
    "appliqu\u00e9e"
  ],
  [
    "\nthese two tasks were performed on docu-\nments extracted from the english test part of the\nconll 2012 shared task (pradhan et al, 2012)",
    "appliqu\u00e9e"
  ],
  [
    "\nthe system was trained on the english training\npart of the conll 2012 shared task filtered in the\nsame way as the test part",
    "appliqu\u00e9e"
  ],
  [
    " schwarm and mari ostendorf",
    "appliqu\u00e9e"
  ],
  [
    " for\nexample, in the case of the pronunciation prob-\nlem where the number of phonemes for english\nis in the order of 50, the number of classes is 50\nl\n",
    "appliqu\u00e9e"
  ],
  [
    " to generate\nthe data we chose an arbitrary markov chain over\nthe english alphabet and sampled 40,000 random\nsequences each consisting of 10 symbols",
    "appliqu\u00e9e"
  ],
  [
    " in\nparticular, we generated 40,000 random sequences\nover the english alphabet in the same way as for\nads1 and ads2",
    "appliqu\u00e9e"
  ],
  [
    " in both sets, each\nexample is an english word, typically a proper\nname",
    "appliqu\u00e9e"
  ],
  [
    " our model obtains the best\nresults to date on recent shared task data\nfor arabic, chinese, and english",
    "appliqu\u00e9e"
  ],
  [
    " the com-\nbination of this modification with non-local fea-\ntures leads to further improvements in the cluster-\ning accuracy, as we show in evaluation results on\nall languages from the conll 2012 shared task ?\narabic, chinese, and english",
    "appliqu\u00e9e"
  ],
  [
    "\n7 experimental setup\nwe apply our model to the conll 2012 shared\ntask data, which includes a training, develop-\nment, and test set split for three languages: ara-\nbic, chinese and english",
    "appliqu\u00e9e"
  ],
  [
    " we follow the closed\ntrack setting where systems may only be trained\non the provided training data, with the exception\nof the english gender and number data compiled\nby bergsma and lin (2006)",
    "appliqu\u00e9e"
  ],
  [
    "\nthe english development set as a function of num-\nber of training iterations with two different beam\nsizes, 20 and 100, over the local and non-local fea-\nture sets",
    "appliqu\u00e9e"
  ],
  [
    "\n9\nin figure 4 we compare early update with laso\nand delayed laso on the english development set",
    "appliqu\u00e9e"
  ],
  [
    " arabic and english show considerable\nimprovements, and the conll average increases\n9\nalthough the early systems still seem to show slight in-\ncreases after 50 iterations, it needs a considerable number of\niterations to catch up with the baseline ? after 100 iterations\nthe best early system is still more than half a point behind the\nbaseline",
    "appliqu\u00e9e"
  ],
  [
    "\nearlylasodelayed laso\nfigure 4: comparison of learning algorithms eval-\nuated on the english development set",
    "appliqu\u00e9e"
  ],
  [
    "67\nchinese\nlocal 65",
    "appliqu\u00e9e"
  ],
  [
    "5\nenglish\nlocal 69",
    "appliqu\u00e9e"
  ],
  [
    " for chinese the gains are gen-\nerally not as pronounced, though the muc metric\ngoes up by more than half a point",
    "appliqu\u00e9e"
  ],
  [
    "\n10\nspecifically, this includes fernandes et al?s (2012)\nsystem for arabic and english (denoted fernan-\ndes), and chen and ng?s (2012) system for chi-\nnese (denoted c&n)",
    "appliqu\u00e9e"
  ],
  [
    " for english we also com-\npare it to the berkeley system (durrett and klein,\n2013), which, to our knowledge, is the best pub-\nlicly available system for english coreference res-\nolution (denoted d&k)",
    "appliqu\u00e9e"
  ],
  [
    "72\nchinese\nb&f 58",
    "appliqu\u00e9e"
  ],
  [
    "06\nenglish\nb&f 65",
    "appliqu\u00e9e"
  ],
  [
    "\nwe use these noise samples as follows:\ne\nhl\n(a, b, n) = [m+ e\nbi\n(a, b)? e\nbi\n(a, n)]\n+\nwhere [x]\n+\n= max(x, 0) denotes the standard\nhinge loss and m is the margin",
    "appliqu\u00e9e"
  ],
  [
    " this corpus contains\nenglish transcriptions and multilingual, sentence-\naligned translations of talks from the ted confer-\nence",
    "appliqu\u00e9e"
  ],
  [
    " in total, this amounts to 1,678,219 non-\nenglish sentences (the number of unique english\nsentences is smaller as many documents are trans-\nlated into multiple languages and thus appear re-\npeatedly in the corpus)",
    "appliqu\u00e9e"
  ],
  [
    "uk/tedcldc/\n4\nenglish to arabic, german, french, spanish, italian,\ndutch, polish, brazilian portuguese, romanian, russian and\nturkish",
    "appliqu\u00e9e"
  ],
  [
    "2\ntable 1: classification accuracy for training on english and\ngerman with 1000 labeled examples on the rcv corpus",
    "appliqu\u00e9e"
  ],
  [
    " the add+ model uses an additional 500k\nparallel sentences from the english-french cor-\npus, resulting in one million english sentences,\neach paired up with either a german or a french\nsentence, with bi and bi+ trained accordingly",
    "appliqu\u00e9e"
  ],
  [
    "\na similar idea exists in machine translation where\nenglish is frequently used to pivot between other\nlanguages (cohn and lapata, 2007)",
    "appliqu\u00e9e"
  ],
  [
    "\nthe actual cldc experiments are performed\nby training on english and testing on german doc-\numents and vice versa",
    "appliqu\u00e9e"
  ],
  [
    " it it interesting to note that results improve\nin both directions of the task, even though no addi-\ntional german data was used for the ?+? models",
    "appliqu\u00e9e"
  ],
  [
    " in the english case\nwe train twelve individual classifiers, each using\nthe training data of a single language pair only",
    "appliqu\u00e9e"
  ],
  [
    " to exemplify, this means the de?ar\nresult is produced by training a translation system\nfrom arabic to german",
    "appliqu\u00e9e"
  ],
  [
    " the arabic test set is\ntranslated into german",
    "appliqu\u00e9e"
  ],
  [
    " a classifier is then trained\n7\nwe use the implementation in mallet (mccallum, 2002)\n62\nsetting languages\narabic german spanish french italian dutch polish pt-br roman",
    "appliqu\u00e9e"
  ],
  [
    " russian turkish\nen? l2\nmt system 0",
    "appliqu\u00e9e"
  ],
  [
    "\ntraining\nlanguage\ntest language\narabic german spanish french italian dutch polish pt-br rom?n russian turkish\narabic 0",
    "appliqu\u00e9e"
  ],
  [
    "397\ngerman 0",
    "appliqu\u00e9e"
  ],
  [
    "443\nspanish 0",
    "appliqu\u00e9e"
  ],
  [
    "382\nfrench 0",
    "appliqu\u00e9e"
  ],
  [
    "398\nitalian 0",
    "appliqu\u00e9e"
  ],
  [
    "352\ndutch 0",
    "appliqu\u00e9e"
  ],
  [
    "395\npolish 0",
    "appliqu\u00e9e"
  ],
  [
    "408\nportuguese 0",
    "appliqu\u00e9e"
  ],
  [
    "431\nromanian 0",
    "appliqu\u00e9e"
  ],
  [
    "402\nrussian 0",
    "appliqu\u00e9e"
  ],
  [
    "447\nturkish 0",
    "appliqu\u00e9e"
  ],
  [
    "\nsetting languages\nenglish arabic german spanish french italian dutch polish pt-br roman",
    "appliqu\u00e9e"
  ],
  [
    " russian turkish\nraw data nb 0",
    "appliqu\u00e9e"
  ],
  [
    " the left chart shows results for\nthese models when trained on german data and evaluated on english data, the right chart vice versa",
    "appliqu\u00e9e"
  ],
  [
    "\non the german training data and evaluated on the\ntranslated arabic",
    "appliqu\u00e9e"
  ],
  [
    "\nthis suggests that the joint mode improves the\nquality of the english embeddings more than it\naffects the l2-embeddings",
    "appliqu\u00e9e"
  ],
  [
    " even though\nboth of these sets of embeddings were trained on\nmuch larger datasets than ours, our models outper-\nform these baselines on all languages?even out-\nperforming the na??ve bayes system on on several\n64\nfigure 4: t-sne projections for a number of english, french\nand german words as represented by the bi+ model",
    "appliqu\u00e9e"
  ],
  [
    " even\nthough the model did not use any parallel french-german\ndata during training, it learns semantic similarity between\nthese two languages using english as a pivot, and semanti-\ncally clusters words across all languages",
    "appliqu\u00e9e"
  ],
  [
    " figure 4 shows the t-sne projec-\ntions for a number of english, french and german\nwords",
    "appliqu\u00e9e"
  ],
  [
    " we use the english the presi-\ndent and gender-specific expressions mr president\nand madam president as well as gender-specific\nequivalents in french and german",
    "appliqu\u00e9e"
  ],
  [
    " the projec-\ntion demonstrates a number of interesting results:\nfirst, the model correctly clusters the words into\nthree groups, corresponding to the three english\nforms and their associated translations",
    "appliqu\u00e9e"
  ],
  [
    " in the case of the\npresident and its translations, this effect becomes\neven clearer, with the neutral english expression\nbeing projected close to the mid-point between\neach other language?s gender-specific versions",
    "appliqu\u00e9e"
  ],
  [
    " this system operates over\nthe normalized semantic representations provided\nby the lingo english resource grammar (erg;\nflickinger, 2000)",
    "appliqu\u00e9e"
  ],
  [
    "\n11\nin this work, we have\ntreated the erg as an off-the-shelf system, but\ncoverage could certainly be straightforwardly im-\nproved by adding analyses for phenomena partic-\nular to turn-of-the-20th-century british english",
    "appliqu\u00e9e"
  ],
  [
    " the negated verb in that sen-\ntence is know, and its first semantic argument is\nthe german",
    "appliqu\u00e9e"
  ],
  [
    " prague, czech republic",
    "appliqu\u00e9e"
  ],
  [
    "it),\na mid-2009 dump of the english wikipedia (en",
    "appliqu\u00e9e"
  ],
  [
    "\n4 conclusion\nwe introduced an approach to compositional dis-\ntributional semantics based on a linguistically-\nmotivated syntax-to-semantics type mapping, but\nsimple and flexible enough that it can produce rep-\nresentations of english sentences of arbitrary size\nand structure",
    "appliqu\u00e9e"
  ],
  [
    "\n1 introduction\nmorphological segmentation is considered to be\nindispensable when translating between english\nand morphologically complex languages such as\narabic",
    "appliqu\u00e9e"
  ],
  [
    " since our focus here is on integrating seg-\nmentation into the decoding process, we simply\nadopt the segmentation strategies recommended\nby previous work: the penn arabic treebank\nscheme for english-arabic (el kholy and habash,\n2012a), and an unsupervised scheme for english-\nfinnish (clifton and sarkar, 2011)",
    "appliqu\u00e9e"
  ],
  [
    "\n102\n0 1b+ 2lebp\n5\n+hm\n4+ha\n3\naltfl\n(a)\t\n ?\n(b)\t\n ?\n(c)\t\n ?\n1\naltfl:altfl\n0b+:<epsilon>\n2\nlebp:<epsilon>\n<epsilon>:blebp\n+ha:blebtha\n+hm:blebthm\n0\n5blebthm\n4blebtha\n2\nblebp\n3altfl\ntransduces\t\n ?\ninto\t\n ?\nfigure 1: the finite state pipeline for a lattice translating the english fragment ?with the child?s game?",
    "appliqu\u00e9e"
  ],
  [
    " finnish does not require a ta-\nble, as all words can be desegmented with sim-\nple concatenation",
    "appliqu\u00e9e"
  ],
  [
    " for the sake\nof symmetry with the unambiguous finnish case,\nwe augment arabic n-best lists or lattices with\nonly the most frequent desegmentation y ",
    "appliqu\u00e9e"
  ],
  [
    " as these evaluation sets are intended for\narabic-to-english translation, we select the first\nenglish reference to use as our source text",
    "appliqu\u00e9e"
  ],
  [
    "\nfor finnish, we adopt the unsup l-match seg-\nmentation technique of clifton and sarkar (2011),\nwhich uses morfessor (creutz and lagus, 2005)\nto analyze the 5,000 most frequent finnish words",
    "appliqu\u00e9e"
  ],
  [
    "\nthe analysis is then applied to the finnish side of\nthe parallel text, and a list of segmented suffixes\nis collected",
    "appliqu\u00e9e"
  ],
  [
    " this category is challenging for the de-\ncoder because english prepositions tend to corre-\nspond to multiple possible forms when translated\ninto arabic",
    "appliqu\u00e9e"
  ],
  [
    "\nwe have also applied our approach to english-to-\nfinnish translation, and although segmentation in\ngeneral does not currently help, we are able to\nshow significant improvements over a 1-best de-\nsegmentation baseline",
    "appliqu\u00e9e"
  ],
  [
    "\nacknowledgments\nthanks to ann clifton for generously provid-\ning the data and segmentation for our english-to-\nfinnish experiments, and to marine carpuat and\nroland kuhn for their helpful comments on an\nearlier draft",
    "appliqu\u00e9e"
  ],
  [
    " in proceedings of the second\nworkshop on statistical machine translation, pages\n232?239, prague, czech republic, june",
    "appliqu\u00e9e"
  ],
  [
    " in proceedings of the 45th annual meeting of\nthe association of computational linguistics, pages\n144?151, prague, czech republic, june",
    "appliqu\u00e9e"
  ],
  [
    " in proceedings of the 2007\njoint conference on empirical methods in natural\nlanguage processing and computational natural\nlanguage learning (emnlp-conll), pages 868?\n876, prague, czech republic, june",
    "appliqu\u00e9e"
  ],
  [
    " in proceedings of the 45th annual meeting of\nthe association for computational linguistics com-\npanion volume proceedings of the demo and poster\nsessions, pages 177?180, prague, czech republic,\njune",
    "appliqu\u00e9e"
  ],
  [
    " in proceedings of the 45th annual meet-\ning of the association of computational linguistics,\npages 128?135, prague, czech republic, june",
    "appliqu\u00e9e"
  ],
  [
    "\nin proceedings of the second workshop on statis-\ntical machine translation, pages 25?32, prague,\nczech republic, june",
    "appliqu\u00e9e"
  ],
  [
    " second, the first issue becomes more\nproblematic with languages that have a rich set of\nwords such as german or other highly inflected\nlanguages",
    "appliqu\u00e9e"
  ],
  [
    " the dcu-\nictcas mt system at wmt 2014 on german-\nenglish translation task",
    "appliqu\u00e9e"
  ],
  [
    " the rwth aachen german-\nenglish machine translation system for wmt 2014",
    "appliqu\u00e9e"
  ],
  [
    " our exper-\niments on the wmt?14 english to french\ntranslation task show that this method pro-\nvides a substantial improvement of up to\n2",
    "appliqu\u00e9e"
  ],
  [
    " , a e?te? pris le jeudi matin\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\nfigure 1: example of the rare word problem ? an english source sentence (en), a human translation to\nfrench (fr), and a translation produced by one of our neural network systems (nn) before handling oov\nwords",
    "appliqu\u00e9e"
  ],
  [
    " on the english to french wmt?14\ntranslation task, this approach provides an im-\nprovement of up to 2",
    "appliqu\u00e9e"
  ],
  [
    "1 training data\nto be comparable with the results reported by pre-\nvious work on neural machine translation systems\n(sutskever et al, 2014; cho et al, 2014; bahdanau\net al, 2015), we train our models on the same\ntraining data of 12m parallel sentences (348m\nfrench and 304m english words), obtained from\n(schwenk, 2014)",
    "appliqu\u00e9e"
  ],
  [
    "\ndue to the computationally intensive nature of\nthe naive softmax, we limit the french vocabulary\n(the target language) to the either the 40k or the\n80k most frequent french words",
    "appliqu\u00e9e"
  ],
  [
    " on the source\nside, we can afford a much larger vocabulary, so\nwe use the 200k most frequent english words",
    "appliqu\u00e9e"
  ],
  [
    " we\n3\nwhen the french vocabulary has 40k words, there are\non average 1",
    "appliqu\u00e9e"
  ],
  [
    "8 on the newstest2014 test set\nfor english to french language pair (see table 2)",
    "appliqu\u00e9e"
  ],
  [
    "5 bleu outperforms all other nmt\nsystems by a arge margin, and more importanly,\nour system has established a new record on the\nwmt?14 english to french translation",
    "appliqu\u00e9e"
  ],
  [
    " note, however, that english and french\nhave similar word order structure, so it would\nbe interesting to experiment with other language\npairs, such as english and chinese, in which the\nword order is not as monotonic",
    "appliqu\u00e9e"
  ],
  [
    "\nc?2015 association for computational linguistics\nencoding source language with convolutional neural network for\nmachine translation\nfandong meng\n1\nzhengdong lu\n2\nmingxuan wang\n1\nhang li\n2\nwenbin jiang\n1\nqun liu\n3,1\n1\nkey laboratory of intelligent information processing,\ninstitute of computing technology, chinese academy of sciences\n{mengfandong,wangmingxuan,jiangwenbin,liuqun}@ict",
    "appliqu\u00e9e"
  ],
  [
    "\nlet us use the example in figure 1, where\nthe task is to translate the chinese sentence\ninto english",
    "appliqu\u00e9e"
  ],
  [
    "0 million\nchinese words and 6",
    "appliqu\u00e9e"
  ],
  [
    "8 million english words",
    "appliqu\u00e9e"
  ],
  [
    "\ntoolkit (stolcke and others, 2002) to train a\n4-gram language model with modified kneser-\nney smoothing on the xinhua portion of the\nenglish gigaword corpus (306 million words)",
    "appliqu\u00e9e"
  ],
  [
    "\nwe parse the chinese sentences with stanford\nparser into projective dependency trees",
    "appliqu\u00e9e"
  ],
  [
    "\noptimization of nn: in training the neural\nnetwork, we limit the source and target vocab-\nulary to the most frequent 20k words for both\nchinese and english, covering approximately\n97% and 99% of two corpus respectively",
    "appliqu\u00e9e"
  ],
  [
    " in pro-\nceedings of the 45th annual meeting of the asso-\nciation for computational linguistics compan-\nion volume proceedings of the demo and poster\nsessions, pages 177?180, prague, czech repub-\nlic, june",
    "appliqu\u00e9e"
  ],
  [
    "8 bleu\npoints for arabic-english and chinese-\nenglish translation over a state-of-the-art\nsystem that already includes neural net-\nwork features",
    "appliqu\u00e9e"
  ],
  [
    " the tuning and test sets consist\nof roughly 5000 segments each, with 2 indepen-\ndent references for arabic and 3 for chinese",
    "appliqu\u00e9e"
  ],
  [
    "3 nist openmt12\nour nist system is compatible with the\nopenmt12 constrained track, which consists of\n10m words of high-quality parallel training for\narabic, and 25m words for chinese",
    "appliqu\u00e9e"
  ],
  [
    " for test, we use the ?arabic-to-\nenglish original progress test? (1378 segments)\nand ?chinese-to-english original progress test +\nopenmt12 current test? (2190 segments), which\nconsists of a mix of newswire and web data",
    "appliqu\u00e9e"
  ],
  [
    " they show very large\nimprovements on arabic-english and chinese-\nenglish web forum and newswire baselines",
    "appliqu\u00e9e"
  ],
  [
    " in proceedings of the 2007 joint con-\nference on empirical methods in natural language\nprocessing and computational natural language\nlearning (emnlp-conll), pages 61?72, prague,\nczech republic, june",
    "appliqu\u00e9e"
  ],
  [
    " max-\nmargin tensor neural network for chinese word seg-\nmentation",
    "appliqu\u00e9e"
  ],
  [
    "2 generating a sense-annotated corpus\nas our corpus we used the september-2014 dump\nof the english wikipedia",
    "appliqu\u00e9e"
  ],
  [
    " thanks to its use of babel-\nnet, babelfy inherently features multilinguality;\nhence, our representation approach is equally ap-\nplicable to languages other than english",
    "appliqu\u00e9e"
  ],
  [
    " men contains two sets of english\nword pairs, together with human-assigned similar-\nity judgments, obtained by crowdsourcing using\namazon mechanical turk",
    "appliqu\u00e9e"
  ],
  [
    " in proceedings of the 45th\nacl, pages 960?967, prague, czech republic",
    "appliqu\u00e9e"
  ],
  [
    " in in proceedings of the emnlp-\nconll, pages 678?687, prague, czech republic",
    "appliqu\u00e9e"
  ],
  [
    "6%-25% higher f-score over state-of-\nthe-art english slot filling methods",
    "appliqu\u00e9e"
  ],
  [
    " our promis-\ning results on chinese slot filling can serve\nas a new benchmark",
    "appliqu\u00e9e"
  ],
  [
    "\nexperiments on english and chinese demonstrate\nthat our approach dramatically advances state-of-\nthe-art results for both pre-defined kbp slot types\nand new slot types",
    "appliqu\u00e9e"
  ],
  [
    "1 data and scoring metric\nin order to evaluate the quality of our proposed\nframework and its portability to a new language,\nwe use tac-kbp2013 english slot filling (esf),\ntac-kbp 2015 english cold start slot filling\n(cssf) and tac-kbp2015 chinese slot filling\n(csf) data sets for which we can compare with the\nground truth and state-of-the-art results reported\nin previous work",
    "appliqu\u00e9e"
  ],
  [
    "3 ?\ntable 3: english slot filling f\n1\n(%) (kbp2013 sf\ndata set)",
    "appliqu\u00e9e"
  ],
  [
    "2 english slot filling\nwe apply stanford corenlp (manning et al,\n2014) for english part-of-speech (pos) tagging,\nname tagging, time expression extraction, depen-\ndency parsing and coreference resolution",
    "appliqu\u00e9e"
  ],
  [
    " in\ntable 3 we compare our approach with two state-\nof-the-art english slot filling methods: a distant\nsupervision method (roth et al, 2013) and a hy-\nbrid method that combines distant and partial su-\npervision (angeli et al, 2014b)",
    "appliqu\u00e9e"
  ],
  [
    " kbp2015\nenglish cold start slot filling is a task which\ncombines entity mention extraction and slot fil-\ning (surdeanu and ji, 2014)",
    "appliqu\u00e9e"
  ],
  [
    "6\ntable 4: english cold start slot filling f\n1\n(%)\n(kbp2015 cssf data set)",
    "appliqu\u00e9e"
  ],
  [
    "5 chinese slot filling\nas long as we have the following resources: (1)\na pos tagger, (2) a name tagger, (3) a dependen-\n1 \n1 2 3 4 5 640\n42\n44\n46\n48\n50\n52\n54\n56\n58\nf-sc\nore \n(%)\ntop n candidates as triggers\n threshold tuning affinity propagation\nfigure 5: the effect of the number of trigger\ncandidates on esf",
    "appliqu\u00e9e"
  ],
  [
    "\nwe demonstrate the portability of our frame-\nwork to chinese since all the resources men-\ntioned above are available",
    "appliqu\u00e9e"
  ],
  [
    " we apply stanford\ncorenlp (manning et al, 2014) for chinese pos\ntagging, name tagging (wang et al, 2013) and\ndependency parsing (levy and manning, 2003)",
    "appliqu\u00e9e"
  ],
  [
    "\nto explore the impact of the quality of annotation\nresources, we also use a chinese language analysis\ntool: language technology platform (ltp) (che\net al, 2010)",
    "appliqu\u00e9e"
  ],
  [
    " we use the full set of chinese\ntrigger gazetteers published by yu et al (2015)",
    "appliqu\u00e9e"
  ],
  [
    "\nhowever, the performance of chinese sf is\nheavily influenced by the relatively low perfor-\nmance of name tagging since our method return-\ns an empty result if it fails to find any query\nmetnion",
    "appliqu\u00e9e"
  ],
  [
    "\none reason is that many chinese names are also\ncommon words",
    "appliqu\u00e9e"
  ],
  [
    " for example, in chinese a\nsingle sentence about a person?s biography often\ncontains more than five co-ordinated clauses, each\nof which includes a trigger",
    "appliqu\u00e9e"
  ],
  [
    " therefore a dependen-\ncy parser adapted from english often mistakenly\nidentifies one of the triggers as a main predicate of\nthe sentence",
    "appliqu\u00e9e"
  ],
  [
    "\nin addition, chinese is a very concise language",
    "appliqu\u00e9e"
  ],
  [
    "3\ntable 7: chinese slot filling f\n1\n(%) (kbp2015\ncsf data set)",
    "appliqu\u00e9e"
  ],
  [
    "\nfinally, compared to english, chinese tends to\nhave more variants for some types of triggers (e",
    "appliqu\u00e9e"
  ],
  [
    "\nacknowledgement\nwe would like to thank chris callison-burch\nfor providing english and chinese paraphrase\nresources",
    "appliqu\u00e9e"
  ],
  [
    " ltp: a\nchinese language technology platform",
    "appliqu\u00e9e"
  ],
  [
    " is it harder to\nparse chinese, or the chinese treebank? in proc",
    "appliqu\u00e9e"
  ],
  [
    " overview of the\nenglish slot filling track at the tac2014 knowledge\nbase population evaluation",
    "appliqu\u00e9e"
  ],
  [
    " using\nhausa and chinese as the lls and en-\nglish as the hl, experiments show that our\napproach achieves 36",
    "appliqu\u00e9e"
  ],
  [
    "1% higher hausa\nname tagging f-score over a costly super-\nvised model, and 9",
    "appliqu\u00e9e"
  ],
  [
    ",\nlocations where ebola outbreaks from hausa doc-\numents)",
    "appliqu\u00e9e"
  ],
  [
    " for clel we choose chinese\nas the ll and english as hl because chinese-\nto-english is one of the few language pairs for\nwhich we have ground-truth annotations from offi-\ncial shared tasks (e",
    "appliqu\u00e9e"
  ],
  [
    "\nsince chinese name tagging is a well-studied\nproblem, we choose hausa instead of chinese\nas the ll for name tagging experiment, because\nwe can use the ground truth from the darpa\nlorelei program\n1\nfor evaluation",
    "appliqu\u00e9e"
  ],
  [
    " for example, in the hausa\ndocument in figure 1, it would be challenging\nto identify the location name ?najeriya? directly\nfrom the hausa document because it?s different\nfrom its english counterpart",
    "appliqu\u00e9e"
  ],
  [
    " for\nexample, when a child is watching a cartoon and\nshifting between versions in two languages, s/he\ncan easily infer translation pairs for the same con-\nfigure 2: examples of cartoons in chinese (left)\nand english (right)",
    "appliqu\u00e9e"
  ],
  [
    ", abstract\nmeaning representation (amr) (banarescu et al,\n2013)) and large-scale knowledge bases for en-\nglish entity linking, but not for other languages,\nincluding some medium-resource ones such as\nchinese",
    "appliqu\u00e9e"
  ],
  [
    "\nfrom the ll documents we may only be able\nto construct co-occurrence based knowledge graph\nand thus it?s difficult to link rare entity mentions\nsuch as ??? (reeva)? and ???? (tshwane)?\nto an english knowledge base (kb)",
    "appliqu\u00e9e"
  ],
  [
    " moreover,\nif we start to walk through the kb, we can eas-\nily reach from english related entities to the enti-\nties mentioned in ll documents",
    "appliqu\u00e9e"
  ],
  [
    " using hausa and chi-\nnese as the lls and english as hl for case study,\nexperiments demonstrate that our approach can\nachieve 36",
    "appliqu\u00e9e"
  ],
  [
    "1% higher hausa name tagging over a\ncostly supervised model trained from 337 docu-\nments, and 9",
    "appliqu\u00e9e"
  ],
  [
    " it shows three english\ndocuments retrieved for the first image in figure 1",
    "appliqu\u00e9e"
  ],
  [
    " for example, a hausa doc-\nument about ?arab spring? includes protests that\nhappened in algeria, bahrain, iran, libya, yemen\nand jordan",
    "appliqu\u00e9e"
  ],
  [
    " then\nwe apply an amr based entity linker (pan et al,\n2015) to link all english entity mentions to the\ncorresponding entities in the english kb",
    "appliqu\u00e9e"
  ],
  [
    "3 entity prior acquisition\ngiven the english entities discovered from the\nabove, we aim to automatically mine related en-\n57\ntities to further expand the expected entity set",
    "appliqu\u00e9e"
  ],
  [
    " we\nuse a large english corpus and english knowledge\nbase respectively as follows",
    "appliqu\u00e9e"
  ],
  [
    "\nif a name n\nh\nappears frequently in these re-\ntrieved english documents,\n2\nwe further mine other\nrelated names n\n?\nh\nwhich are very likely to appear\nin the same context as n\nh\nin a large-scale news cor-\npus (we use english gigaword v5",
    "appliqu\u00e9e"
  ],
  [
    " if p(n\n?\nh\n|n\nh\n) is larger than a\nthreshold,\n4\nand n\n?\nh\nis a person name, then we add\nn\n?\nh\ninto the expected english name set",
    "appliqu\u00e9e"
  ],
  [
    ", e\nn\n} be the set of entities in\nthe kb that all mentions in english documents are\nlinked to",
    "appliqu\u00e9e"
  ],
  [
    " then we extend the\nexpected english entity set as e\n0\n? e\n1\n",
    "appliqu\u00e9e"
  ],
  [
    "\n5 knowledge transfer for name tagging\nin this section we will present the first case study\non name tagging, using english as hl and hausa\nas ll",
    "appliqu\u00e9e"
  ],
  [
    "1 name projection\nafter expanding the english expected name set us-\ning entity prior, next we will try to carefully select,\nmatch and project each expected name (n\nh\n) from\nenglish to the one (n\nl\n) in hausa documents",
    "appliqu\u00e9e"
  ],
  [
    " we\nscan through every n-gram (n in the order 3, 2, 1)\nin hausa documents to see if any of them match an\nenglish name based on the following multi-media\nlanguage-independent low-cost heuristics",
    "appliqu\u00e9e"
  ],
  [
    " for example, using\nthe textual clues above is not sufficient to find the\nhausa equivalent ?majalisar dinkin duniya? for\n?united nations?, because their pronunciations\nare quite different",
    "appliqu\u00e9e"
  ],
  [
    " this visual similarity compu-\ntation method, though seemingly simple, has been\n5\nalthough existing machine translation (mt) tools like\ngoogle translate can correctly translate this example phrase\nfrom hausa to english, here we use it as an example to illus-\ntrate the low-resource setting when direct mt is not available",
    "appliqu\u00e9e"
  ],
  [
    "\n6 knowledge transfer for entity linking\nin this section we will present the second case\nstudy on entity linking, using english as hl and\nchinese as ll",
    "appliqu\u00e9e"
  ],
  [
    "1 baseline ll entity linking\nwe apply a state-of-the-art language-independent\ncross-lingual entity linking approach (wang et al,\n2015b) to link names from chinese to an en-\nglish kb",
    "appliqu\u00e9e"
  ],
  [
    "2 representation and structured\nknowledge transfer\nthen for each expected english entity e\nh\n, if there\nis a cross-lingual link to link it to an ll (chinese)\nentry e\nl\nin the kb, we added the title of the ll\nentry or its redirected/renamed page c\nl\nas its ll\ntranslation",
    "appliqu\u00e9e"
  ],
  [
    " in this way we are able to collect a\nset of pairs of ?c\nl\n, e\nh\n?, where c\nl\nis an expected ll\nname, and e\nh\nis its corresponding english entity\nin the kb",
    "appliqu\u00e9e"
  ],
  [
    "\nbeijing ???\n??(beijing) 553\n???(beijing city) 227\n??(yanjing) 15\n??(jingshi) 3\n??(beiping) 2\n??(capital) 1\n?(ji) 1\n??(yan capital) 1\nchina\ncen-\ntral\ntv\n??\n??\n??\n?\n??(central tv) 19\ncctv 16\n?????(central tv) 13\n????(china central tv) 3\ntable 2: representation and structured knowl-\nedge transfer for expected english entities ?bei-\njing? and ?china central tv?",
    "appliqu\u00e9e"
  ],
  [
    "1 data\nfor name tagging, we randomly select 30 hausa\ndocuments from the darpa lorelei program\nas our test set",
    "appliqu\u00e9e"
  ],
  [
    " for this test set, in\ntotal we retrieved 810 topically-related english\ndocuments",
    "appliqu\u00e9e"
  ],
  [
    " we found that 80% names in the\nground truth appear at least once in the retrieved\nenglish documents, which shows the effectiveness\nof our image-anchored comparable data discovery\nmethod",
    "appliqu\u00e9e"
  ],
  [
    "\nfor comparison, we trained a supervised\nhausa name tagger based on conditional ran-\ndom fields (crfs) from the remaining 337 la-\nbeled documents, using lexical features (character\nngrams, adjacent tokens, capitalization, punctua-\ntions, numbers and frequency in the training data)",
    "appliqu\u00e9e"
  ],
  [
    "\nwe learn entity priors by running the stanford\nname tagger (manning et al, 2014) on english gi-\ngaword v5",
    "appliqu\u00e9e"
  ],
  [
    "\nfor cross-lingual entity linking, we use\n30 chinese documents from the tac-kbp2015\nchinese-to-english entity linking track (ji et al,\n2015) as our test set",
    "appliqu\u00e9e"
  ],
  [
    " the english kb is derived from basekb,\na cleaned version of english freebase",
    "appliqu\u00e9e"
  ],
  [
    " using the\nmulti-media approach, we retrieved 235 topically-\nrelated english documents",
    "appliqu\u00e9e"
  ],
  [
    "\n? hausa document: ?yansanda sun dauki\n6\nhttps://catalog",
    "appliqu\u00e9e"
  ],
  [
    " both of our hl\nand ll name taggers mistakenly label ?haiyan?\nas a person in the following documents:\n? hausa document: ?",
    "appliqu\u00e9e"
  ],
  [
    ")?\n? retrieved english comparable document:\n?as haiyan heads west toward vietnam, the\nred cross is at the forefront of an interna-\ntional effort to provide food, water, shelter\nand other relief",
    "appliqu\u00e9e"
  ],
  [
    "\nentity priors successfully provide more detailed\nand richer background knowledge than the compa-\nrable english documents",
    "appliqu\u00e9e"
  ],
  [
    " for example, the main\ntopic of one hausa document is the former pres-\nident of nigeria olusegun obasanjo accusing the\ncurrent president goodluck jonathan, and a com-\nment by the former 1990s military administrator of\nkano bawa abdullah wase is quoted",
    "appliqu\u00e9e"
  ],
  [
    " however, based on entity priors\nwe observe that ?bawa abdullah wase? appears\nfrequently in the same contexts as ?nigeria? and\n?kano?, and thus we successfully project it back\nto the hausa sentence: ?haka ma bawa abdul-\nlahi wase ya ce akawai abun dubawa a kalamun\n60\nsystem\nidentification f-score classification\naccuracy\noverall\nf-score\nper org loc\n7\nall\nsupervised 36",
    "appliqu\u00e9e"
  ],
  [
    " the impact of entity priors\non person names is much more significant than\nother categories because multiple person entities\noften co-occur in some certain events or related\ntopics which might not be fully covered in the re-\ntrieved english documents",
    "appliqu\u00e9e"
  ],
  [
    " in contrast most ex-\npected organizations and locations already exist in\nthe retrieved english documents",
    "appliqu\u00e9e"
  ],
  [
    "\nfor the same local topic, hausa documents usu-\nally describe more details than english documents,\nand include more unsalient entities",
    "appliqu\u00e9e"
  ],
  [
    " for example,\nfor the president election in ivory coast, a hausa\ndocument mentions the officials of the electoral\nbody such as ?damana picasse?: ?wani wakilin\nhukumar zaben daga jamiyyar shugaba gbagbo,\ndamana picasse, ya kekketa takardun sakamakon\na gaban yan jarida, ya kuma ce ba na halal ba ne",
    "appliqu\u00e9e"
  ],
  [
    " in contrast, no english comparable\ndocuments mention their names",
    "appliqu\u00e9e"
  ],
  [
    " an\nexample about the ebola scenario is presented in\nfigure 8, including entity nodes extracted from\nboth hausa (ll) and english (hl), anchored by\nimages; and edges extracted from english",
    "appliqu\u00e9e"
  ],
  [
    " some other methods also utilized global\nknowledge in the english kb to improve linking\naccuracy via quantifying link types (wang et al,\n2015b), computing pointwise mutual information\nfor the wikipedia categories of consecutive pairs\nof entities (sil et al, 2015), or using linking as\nfeedback to improve name classification (sil and\nyates, 2013; heinzerling et al, 2015; besancon et\nal",
    "appliqu\u00e9e"
  ],
  [
    " cea list participation at tac edl\nenglish diagnostic task",
    "appliqu\u00e9e"
  ],
  [
    " automatic identification of\nword translations from unrelated english and ger-\nman corpora",
    "appliqu\u00e9e"
  ],
  [
    "\n7 experimental results\nwe evaluate our models and methods for english-\nfrench and english-german on two domains: soft-\nware and news",
    "appliqu\u00e9e"
  ],
  [
    " also, the nmt engine often pro-\nduces better german grammar and morphological\nagreement, e",
    "appliqu\u00e9e"
  ],
  [
    "\na direct correspondence in the english source, but\nmakes the sentence feel more natural in german",
    "appliqu\u00e9e"
  ],
  [
    " fig-\nure 1(a) shows an example: the chinese word\n?gu?anb`?? is over translated to ?close(d)? twice,\nwhile ?b`eip`o? (means ?be forced to?) is mistak-\nenly untranslated",
    "appliqu\u00e9e"
  ],
  [
    " in conven-\ntional nmt without coverage, the chinese word ?gu?anb`?? is over translated to ?close(d)? twice, while\n?b`eip`o? (means ?be forced to?) is mistakenly untranslated",
    "appliqu\u00e9e"
  ],
  [
    "9m chinese\nwords and 34",
    "appliqu\u00e9e"
  ],
  [
    "5m english words respectively",
    "appliqu\u00e9e"
  ],
  [
    "\nfor efficient training of the neural networks, we\nlimit the source and target vocabularies to the most\nfrequent 30k words in chinese and english, cov-\nering approximately 97",
    "appliqu\u00e9e"
  ],
  [
    ", top-right corner for the first four chinese words",
    "appliqu\u00e9e"
  ],
  [
    "\nfor example, the first four chinese words are as-\nsigned lower alignment probabilities (i",
    "appliqu\u00e9e"
  ],
  [
    "\nfor the experiments with synthetic parallel\ndata, we back-translate a random sample of\n3 600 000 sentences from the german monolin-\ngual data set into english",
    "appliqu\u00e9e"
  ],
  [
    " for experiments\nin german?english, we back-translate 4 200 000\nmonolingual english sentences into german, us-\ning the english?german system +synthetic",
    "appliqu\u00e9e"
  ],
  [
    "\ng?l?ehre et al (2015) segment the turkish text\nwith the morphology tool zemberek, followed by\na disambiguation of the morphological analysis\n(sak et al, 2007), and removal of non-surface to-\nkens produced by the analysis",
    "appliqu\u00e9e"
  ],
  [
    " for both turkish and english, we\nrepresent rare words (or morphemes in the case of\nturkish) as character bigram sequences (sennrich\net al, 2016)",
    "appliqu\u00e9e"
  ],
  [
    " to\ninvestigate this question, we back-translate the\nsame german monolingual corpus with three dif-\nferent german?english systems:\n? with our baseline system and greedy decod-\ning\n? with our baseline system and beam search\n(beam size 12)",
    "appliqu\u00e9e"
  ],
  [
    " for instance, the english?german sys-\ntems translate the english phrase civil rights pro-\ntections as a single compound, composed of three\nsubword units: b?rger|rechts|schutzes\n12\n, and we\nanalyze how many of these multi-unit words that\nthe translation systems produce are well-formed\ngerman words",
    "appliqu\u00e9e"
  ],
  [
    " additionally, the main authors,\na native speaker of german, annotated a random\nsubset (n = 100) of unattested words of each sys-\ntem according to their naturalness\n13\n, distinguish-\ning between natural german words (or names)\nsuch as literatur|klassen ?literature classes?, and\nnonsensical ones such as *as|best|atten (a miss-\nspelling of astbestmatten ?asbestos mats?)",
    "appliqu\u00e9e"
  ],
  [
    "\nin proceedings of the acl-2007 demo and poster\nsessions, pages 177?180, prague, czech republic",
    "appliqu\u00e9e"
  ],
  [
    "\nmorphological disambiguation of turkish text with\nperceptron algorithm",
    "appliqu\u00e9e"
  ],
  [
    " experi-\nments on chinese?english and german?\nenglish tasks show that our system is\nsignificantly better than the phrase-based\nmodel by up to +1",
    "appliqu\u00e9e"
  ],
  [
    " however, one of the\nsignificant weaknesses in conventional pb models\nis that only continuous phrases are used, so gen-\neralizations such as french ne ",
    "appliqu\u00e9e"
  ],
  [
    " pas to english\nnot cannot be learned",
    "appliqu\u00e9e"
  ],
  [
    "\nbigram relations are implied in sequences and\nprovide local and sequential information on pairs\n98\n2010\n2010nian\nfifa\nfifa\nworld cup\nshijiebei\nin\nzai\nsouth africa\nnanfei\nsuccessfully\nchenggong\nheld\njuxing\nfigure 2: an example graph for a chinese sen-\ntence",
    "appliqu\u00e9e"
  ],
  [
    " each node includes a chinese word and its\nenglish meaning",
    "appliqu\u00e9e"
  ],
  [
    " the stanford\nchinese word segmenter (chang et al, 2008) is\nused to segment chinese sentences",
    "appliqu\u00e9e"
  ],
  [
    " the stan-\nford dependency parser (chang et al, 2009) parses\na chinese sentence into a projective dependency\ntree which is then converted to a graph by adding\nbigram relations",
    "appliqu\u00e9e"
  ],
  [
    " we\nuse mate-tools\n2\nto perform morphological analy-\nsis and parse german sentences (bohnet, 2010)",
    "appliqu\u00e9e"
  ],
  [
    " we use srilm (stolcke, 2002)\nto train a 5-gram language model on the xinhua\nportion of the english gigaword corpus 5th edi-\ntion with modified kneser-ney discounting (chen\nand goodman, 1996)",
    "appliqu\u00e9e"
  ],
  [
    "\nsince discontinuous phrases produced by us-\ning syntactic information are fewer in number but\n102\n1 2 3 4 5 6 7\n5\n10\n15\nmt02\n1 2 3 4 5 6 7\n5\n10\n15\nwmt11\n[\nl\no\ng\n2\n]\np\nh\nr\na\ns\ne\nc\no\nu\nn\nt\nnumber of english words per phrase\npbmt treelet dtu gbmt\nfigure 5: phrase length histogram for mt02 and wmt11",
    "appliqu\u00e9e"
  ],
  [
    " exam-\nple 1 shows that systems which allow discontin-\nuous phrases (namely treelet, dtu, gbmt, and\ngsm) successfully translate a chinese colloca-\ntion ?yu ",
    "appliqu\u00e9e"
  ],
  [
    " discriminative re-\nordering with chinese grammatical relations fea-\ntures",
    "appliqu\u00e9e"
  ],
  [
    " what can syntax-based mt learn\nfrom phrase-based mt? in proceedings of the 2007\njoint conference on empirical methods in natural\nlanguage processing and computational natural\nlanguage learning (emnlp-conll), pages 755?\n763, prague, czech republic, june",
    "appliqu\u00e9e"
  ],
  [
    " in proceedings of the 45th annual meeting\nof the acl on interactive poster and demonstration\n106\nsessions, pages 177?180, prague, czech republic,\njune",
    "appliqu\u00e9e"
  ],
  [
    " in proceedings\nof the 2007 joint conference on empirical meth-\nods in natural language processing and com-\nputational natural language learning (emnlp-\nconll), pages 746?754, prague, czech republic,\njune",
    "appliqu\u00e9e"
  ],
  [
    " for instance, though new york and united states are expressed as \u7ebd\u7ea6 and \u7f8e\u56fd respectively in chinese,\nboth americans and chinese share the fact that\n\u201cnew york is a city of usa",
    "appliqu\u00e9e"
  ],
  [
    " according to the distant supervision data in\nour experiments3 , we \ufb01nd that over half of chinese\n\nrelation extraction has been widely used\nfor \ufb01nding unknown relational facts from\nthe plain text",
    "appliqu\u00e9e"
  ],
  [
    "org/\n\nliu\n\n(li-\n\n3\n\nthe data is generated by aligning wikidata with chinese\n\n34\nproceedings of the 55th annual meeting of the association for computational linguistics, pages 34\u201343\nvancouver, canada, july 30 - august 4, 2017",
    "appliqu\u00e9e"
  ],
  [
    "18653/v1/p17-1004\n\n\frelation\nenglish\nchinese\n\ncity in\n1",
    "appliqu\u00e9e"
  ],
  [
    "\nin experiments, we build training instances via\ndistant supervision by aligning wikidata with chinese baidu baike and english wikipedia articles\nand evaluate the performance of relation extraction\nin both english and chinese",
    "appliqu\u00e9e"
  ],
  [
    "\n\ntable 1: an example of chinese sentences and english sentence about the same relational fact (new\nyork, cityof, united states)",
    "appliqu\u00e9e"
  ],
  [
    "\n\nand english sentences are longer than 20 words,\nin which only several words are related to the relational facts",
    "appliqu\u00e9e"
  ],
  [
    " the\n\ufb01rst chinese sentence has over 20 words, in which\nonly \u201c\u7ebd\u7ea6\u201d (new york) and \u201c \u7f8e\u56fd\n\u201d (is the biggest city in the united states) actually directly re\ufb02ect the relational fact cityof",
    "appliqu\u00e9e"
  ],
  [
    "2% relational facts in\nenglish data and 41",
    "appliqu\u00e9e"
  ],
  [
    "6% ones in chinese data are\nunique",
    "appliqu\u00e9e"
  ],
  [
    " lin\n\nbaidu baike and english wikipedia articles, which will be\nintroduced in details in the section of experiments",
    "appliqu\u00e9e"
  ],
  [
    "\n\n35\n\n\f1\n\n2\n\ns11\n\ns1\n\ns 22\n\ns2\n\noutput representation\n\nmono-lingual and\ncross-lingual attention\natt\n\natt\n\natt\n\natt\n\nrelation embedding\nenglish\nsentence representation\n\nchinese\n1\n\nx1\n\nn\n\n2\n\nx11\n\nx1\n\nenglish\n\n1\n\nx2\n\n2\n\nx2\n\nn\n\nx22\n\nchinese\n\nfigure 1: overall architecture of our multi-lingual attention which contains two languages including\nenglish and chinese",
    "appliqu\u00e9e"
  ],
  [
    "\nwithout loss of generality, the experiments focus on relation extraction from two languages including english and chinese",
    "appliqu\u00e9e"
  ],
  [
    " in this dataset,\nthe chinese instances are generated by aligning\nchinese baidu baike with wikidata, and the english instances are generated by aligning english\nwikipedia articles with wikidata",
    "appliqu\u00e9e"
  ],
  [
    " and we set both validation and testing sets for chinese and english parts contain the\nsame facts",
    "appliqu\u00e9e"
  ],
  [
    "\ndataset\nenglish\n\nchinese\n\n#rel\ntrain\nvalid\ntest\ntrain\nvalid\ntest\n\n176\n\n176\n\n#sent\n1,022,239\n80,191\n162,018\n940,595\n82,699\n167,224\n\ntable 3: parameter settings",
    "appliqu\u00e9e"
  ],
  [
    " and we compare the performance of our framework with the [p]cnn model\ntrained with only english data ([p]cnn-en),\nonly chinese data ([p]cnn-zh), a joint model\n([p]cnn+joint) which predicts using [p]cnn-en\nand [p]cnn-zh jointly, and another joint model\nwith shared embeddings ([p]cnn+share) which\ntrains [p]cnn-en and [p]cnn-zh with common\nrelation embedding matrices",
    "appliqu\u00e9e"
  ],
  [
    " it indicates that utilizing chinese and english sentences jointly is\nbene\ufb01cial to extracting novel relational facts",
    "appliqu\u00e9e"
  ],
  [
    "\n1907\n\u56fd\n1920\n\u7f8e (barzun\nwas born in a french intellectual family in 1907 and went to america in 1920",
    "appliqu\u00e9e"
  ],
  [
    "35\n\nto demonstrate the effectiveness of considering pattern complementarity among languages,\nwe empirically compare the following methods\nthrough held-out evaluation: mnre for english\n(mnre-en) and mnre for chinese (mnre-zh)\nwhich only use the mono-lingual vectors to predict\nrelations, and [p]cnn-en and [p]cnn-zh models",
    "appliqu\u00e9e"
  ],
  [
    " it indicates that by jointly training\nwith multi-lingual attention, both chinese and\nenglish relation extractors are bene\ufb01cial from\nthose sentences from the other language",
    "appliqu\u00e9e"
  ],
  [
    "\n(2) for the relation headquarterslocation of which the number of chinese training instances is only 1/9 of english ones, cnn-zh even\ncannot predict any correct results",
    "appliqu\u00e9e"
  ],
  [
    " the reason is\nperhaps that, cnn-zh of the relation is not suf\ufb01ciently trained because there are only 210 chinese training instances for this relation",
    "appliqu\u00e9e"
  ],
  [
    "\n(3) for the relations father and countryofcitizenship of which the sentence number\nin english and chinese are not so un-balanced, our\nmnre can still improve the performance of relation extraction on both english and chinese sides",
    "appliqu\u00e9e"
  ],
  [
    "\n\nnese and english relation extractors can take full\nadvantages of texts in both languages via our propose multi-lingual attention scheme",
    "appliqu\u00e9e"
  ],
  [
    "\ntable 5 shows the detailed results (in precision@1) of some speci\ufb01c relations of which the\ntraining instances are un-balanced on english and\nchinese sides",
    "appliqu\u00e9e"
  ],
  [
    " from the table, we can see that:\n(1) for the relation contains of which the\nnumber of english training instances is only 1/7\nof chinese ones, cnn-en gets much worse performance as compared to cnn-zh due to the lack\nof training data",
    "appliqu\u00e9e"
  ],
  [
    " (2) mnre can be \ufb02exibly implemented\nin the scenario of multiple languages, and this paper focuses on two languages of english and chinese",
    "appliqu\u00e9e"
  ],
  [
    " this work is also funded by the\nnatural science foundation of china (nsfc) and\nthe german research foundation(dfg) in project\ncrossmodal learning, nsfc 61621136008 / dfc\ntrr-169",
    "appliqu\u00e9e"
  ],
  [
    " this is not always considered\nwhen techniques are evaluated on languages such\nas english or chinese, which do not have rich morphology",
    "appliqu\u00e9e"
  ],
  [
    ",\ngerman word inflections katalanisch, katalanischem, katalanischer denote the same semantic concept in different grammatical roles), and antonymy\n(e",
    "appliqu\u00e9e"
  ],
  [
    "18653/v1/p17-1006\n\n\fen_expensive\ncostly\ncostlier\ncheaper\nprohibitively\npricey\nexpensiveness\ncostly\ncostlier\nruinously\nunaffordable\n\nde_teure\nteuren\nkostspielige\naufw\u00e4ndige\nkostenintensive\naufwendige\nteures\nteuren\nteurem\nteurer\nteurerer\n\nit_costoso\ndispendioso\nremunerativo\nredditizio\nrischioso\ncostosa\ncostosa\ncostose\ncostosi\ndispendioso\ndispendiose\n\nen_slow\nfast\nslowness\nslower\nslowed\nslowing\nslowing\nslowed\nslowness\nslows\nidle\n\nde_langsam\nallm\u00e4hlich\nrasch\ngem\u00e4chlich\nschnell\nexplosionsartig\nlangsamer\nlangsames\nlangsame\nlangsamem\nlangsamen\n\nit_lento\nlentissimo\nlenta\ninesorabile\nrapidissimo\ngraduale\nlenti\nlente\nlenta\nveloce\nrapido\n\nen_book\nbooks\nmemoir\nnovel\nstorybooks\nblurb\nbooked\nrebook\nbooking\nrebooked\nbooks\n\nde_buch\nsachbuch\nbuches\nromandeb\u00fct\nb\u00fcchlein\npamphlet\nb\u00fccher\nb\u00fcch\nb\u00fcche\nb\u00fcches\nb\u00fcchen\n\nit_libro\nromanzo\nracconto\nvolumetto\nsaggio\necclesiaste\nlibri\nlibra\nlibrare\nlibre\nlibrano\n\ntable 1: the nearest neighbours of three example words (expensive, slow and book) in english, german\nand italian before (top) and after (bottom) morph-fitting",
    "appliqu\u00e9e"
  ],
  [
    ", italian words rispettoso\nand irrispetosa should be far apart in the trans-\n\nrispettosa\nrispettoso\n\nrispettosi\n\nirrispettosa\nirrispettoso\n\nirrispettosi\n\nfigure 1: morph-fitting in italian",
    "appliqu\u00e9e"
  ],
  [
    " we\nreport an improvement of 4% on italian, and 6% on\ngerman when using morph-fitted vectors instead of\nthe distributional ones, setting a new state-of-theart dst performance for the two datasets",
    "appliqu\u00e9e"
  ],
  [
    "3\n\n1\nfor instance, the vector for the word katalanischem which\noccurs only 9 times in the german wikipedia will be pulled\ncloser to the more reliable vectors for katalanisch and katalanischer, with frequencies of 2097 and 1383 respectively",
    "appliqu\u00e9e"
  ],
  [
    "\n2\nrepresentation models that do not distinguish between\nsynonyms and antonyms may have grave implications in downstream language understanding applications such as spoken\ndialogue systems: a user looking for \u2018an affordable chinese\nrestaurant in west cambridge\u2019 does not want a recommendation for \u2018an expensive thai place in east oxford\u2019",
    "appliqu\u00e9e"
  ],
  [
    "\n\n3\n\n57\n\nthere are no readily available dst datasets for russian",
    "appliqu\u00e9e"
  ],
  [
    "\n\n\f2\n\nmorph-fitting: methodology\n\npreliminaries in this work, we focus on four languages with varying levels of morphological complexity: english (en), german (de), italian (it),\nand russian (ru)",
    "appliqu\u00e9e"
  ],
  [
    "1\n\n(xl ,xr )\u2208ba\n\n+\n\nitalian\n\n(schottisch, schottischem)\n(damalige, damaligen)\n(kombiniere, kombinierte)\n(schweigt, schweigst)\n(hacken, gehackt)\n\n(golfo, golfi)\n(minato, minata)\n(mettere, metto)\n(crescono, cresci)\n(crediti, credite)\n\n(dressed, undressed)\n(similar, dissimilar)\n(formality, informality)\n\n(stabil, unstabil)\n(geformtes, ungeformt)\n(relevant, irrelevant)\n\n(abitata, inabitato)\n(realt\u00e0, irrealt\u00e0)\n(attuato, inattuato)\n\nwords from the in-batch attract constraints to\nbe closer to one another than to any other word in\nthe current mini-batch",
    "appliqu\u00e9e"
  ],
  [
    "\nif ba denotes the current mini-batch of attract\nexamples, this term can be expressed as:\nx\n\ngerman\n\n(discuss, discussed)\n(laugh, laughing)\n(pacifist, pacifists)\n(evacuate, evacuated)\n(evaluate, evaluates)\n\ntable 2: example synonymous (inflectional; top)\nand antonymous (derivational; bottom) constraints",
    "appliqu\u00e9e"
  ],
  [
    "\n\nthe attract-r epel model\n\na(ba ) =\n\nenglish\n\nr(br ) =\n\nx\n\n(xl ,xr )\u2208br\n\n+\n\n(relu (\u03b4rpl + xl xr \u2212 xl tr )\nrelu (\u03b4rpl + xl xr \u2212 xr tr ))\n\nin this case, each word\u2019s \u2018negative\u2019 example is the\n(in-batch) word vector furthest away from it (and\ndistinct from the word\u2019s target antonym)",
    "appliqu\u00e9e"
  ],
  [
    "\n\n58\n\n\fenglish\ngerman\nitalian\nrussian\n\n|w |\n\n|a|\n\n|r|\n\n1,368,891\n1,216,161\n541,779\n950,783\n\n231,448\n648,344\n278,974\n408,400\n\n45,964\n54,644\n21,400\n32,174\n\nif w1 ends with the letter e and w1 \u2208 wen and\nw2 \u2208 wen , where w2 = w1 [: \u22121] + ing/ed, then\nadd (w1 , w2 ) and (w2 , w1 ) to a",
    "appliqu\u00e9e"
  ],
  [
    " besides these, another\nset of rules is used for german and russian: (5)\nregular declension (e",
    "appliqu\u00e9e"
  ],
  [
    " in this work, we\nuse translations of this dataset to italian and german, released by mrk\u0161ic\u0301 et al",
    "appliqu\u00e9e"
  ],
  [
    "15\n\n(a) english\n\n0",
    "appliqu\u00e9e"
  ],
  [
    "60\n\n(b) german\n\n0",
    "appliqu\u00e9e"
  ],
  [
    "60\n\n(c) italian\n\ndistrib\n\nmfix\nmfit-a\nru word vector space\n\nmfit-ar\n\n(d) russian\n\nfigure 3: an overview of the results (spearman\u2019s \u03c1 correlation) for four languages on simlex-999 (grey\nbars, left y axis) and the downstream dst performance (dark bars, right y axis) using sgns - large vectors\n(d = 300), see tab",
    "appliqu\u00e9e"
  ],
  [
    "\n\nenglish performance shows little variation\nacross the four word vector collections investigated\nhere",
    "appliqu\u00e9e"
  ],
  [
    " this corroborates our intuition that, as a morphologically simpler language, english stands to\ngain less from fine-tuning the morphological variation for downstream applications",
    "appliqu\u00e9e"
  ],
  [
    " additional discrepancies between simlex and downstream dst\nperformance are detected for german and italian",
    "appliqu\u00e9e"
  ],
  [
    " finally, we have shown that the use of morph-fitted\nvectors boosts the performance of downstream language understanding models which rely on word\nrepresentations as features, especially for morphologically rich languages such as german",
    "appliqu\u00e9e"
  ],
  [
    "\n\noren melamud, jacob goldberger, and ido dagan",
    "appliqu\u00e9e"
  ],
  [
    "\nderivbase: inducing and evaluating\na derivational morphology resource for german",
    "appliqu\u00e9e"
  ],
  [
    "the state of the art in semantic representation\n\nomri abend\n\nari rappoport\n\ndepartment of computer science, the hebrew university of jerusalem\n{oabend|arir}@cs",
    "appliqu\u00e9e"
  ],
  [
    ", 2014, 2015) include corpora\nannotated with the pdt-tl, and dependencies extracted from the hpsg grammars enju (miyao,\n2006) and the lingo english reference grammar\n(erg; flickinger, 2002)",
    "appliqu\u00e9e"
  ],
  [
    " for instance, the dependencies derived\nfrom erg in the sdp corpus use the same label\nfor different senses of the english possessive construction, regardless of whether they correspond\nto ownership (e",
    "appliqu\u00e9e"
  ],
  [
    "\nconsider phrase-based syntactic structures,\ncommon examples of which, such as the penn\ntreebank for english (marcus et al",
    "appliqu\u00e9e"
  ],
  [
    ", 1993) and\nthe penn chinese treebank (xue et al",
    "appliqu\u00e9e"
  ],
  [
    "\n\n7\n\neneko agirre, carmen banea, claire cardie, daniel\ncer, mona diab, aitor gonzalez-agirre, weiwei\nguo, rada mihalcea, german rigau, and janyce\nwiebe",
    "appliqu\u00e9e"
  ],
  [
    "\n\nido dagan, oren glickman, and bernardo magnini",
    "appliqu\u00e9e"
  ],
  [
    " in bernardo magnini joaquin quin\u0303onero\ncandela, ido dagan and florence d\u2019alche\u0301 buc,\neditors, machine learning challenges, springer,\nberlin, volume 3944 of lecture notes in computer\nscience, pages 177\u2013190",
    "appliqu\u00e9e"
  ],
  [
    "\na procedure for quantitatively comparing the syntactic coverage of english grammars",
    "appliqu\u00e9e"
  ],
  [
    "\n\nido dagan, dan roth, and mark sammons",
    "appliqu\u00e9e"
  ],
  [
    " a large-scale classification of\nenglish verbs",
    "appliqu\u00e9e"
  ],
  [
    " english as a formal language",
    "appliqu\u00e9e"
  ],
  [
    " not an\nintelingua, but close: comparison of english amrs\nto chinese and czech",
    "appliqu\u00e9e"
  ],
  [
    " the best-performing kbp 2016 system on\nenglish trigger detection achieved only an f-score\nof 47 (lu and ng, 2016)",
    "appliqu\u00e9e"
  ],
  [
    " their performances are not particularly impressive, however: the best english event coreference f-score (averaged over four scoring metrics)\nis only around 30%",
    "appliqu\u00e9e"
  ],
  [
    " our model achieves the\nbest results to date on the kbp 2016 english and chinese datasets",
    "appliqu\u00e9e"
  ],
  [
    "\nas is commonly known, trigger detection is\nanother challenging task that is far from being\n\n1\n\nthis is the best english nugget type result in kbp 2016",
    "appliqu\u00e9e"
  ],
  [
    " second, our model\nachieves the best results to date on the kbp 2016\nenglish and chinese event coreference tasks",
    "appliqu\u00e9e"
  ],
  [
    "\ngiven this formulation, we define three types of\noutput variables:\n\ncorpora\n\ngiven our focus on the kbp 2016 event nugget\ndetection and coreference task, we employ the\nenglish and chinese corpora used in this task for\nevaluation, referring to these corpora as the kbp\n2016 english and chinese corpora for brevity",
    "appliqu\u00e9e"
  ],
  [
    "\nthe test set for english consists of 169\nnewswire and discussion forum documents with\n4155 event mentions distributed over 3191 event\ncoreference chains",
    "appliqu\u00e9e"
  ],
  [
    " the test set for chinese consists of 167 newswire and discussion forum documents with 2518 event mentions distributed over\n1912 event coreference chains",
    "appliqu\u00e9e"
  ],
  [
    " finally, for\nthe chinese trigger detector, we additionally create two features from each character in t, one encoding the character itself and the other encoding\nthe entry number of the corresponding character in\na chinese synonym dictionary",
    "appliqu\u00e9e"
  ],
  [
    " each feature is used to train models for both\nenglish and chinese unless otherwise stated",
    "appliqu\u00e9e"
  ],
  [
    "1 experimental setup\nwe perform training and evaluation on the kbp\n2016 english and chinese corpora",
    "appliqu\u00e9e"
  ],
  [
    " for english,\nwe train models on 509 of the training documents,\ntune parameters on 139 training documents, and\nreport results on the official kbp 2016 english test\nset",
    "appliqu\u00e9e"
  ],
  [
    "00\n\nenglish\nblanc avg-f\n22",
    "appliqu\u00e9e"
  ],
  [
    "80\nchinese\nblanc avg-f\n17",
    "appliqu\u00e9e"
  ],
  [
    "\n\nkbp 2016 chinese test set",
    "appliqu\u00e9e"
  ],
  [
    " the top half of the table shows\nthe results on the english evaluation set",
    "appliqu\u00e9e"
  ],
  [
    " using the extracted triggers, it then applies\na pipeline of three sieves, each of which is a one-\n\nthe bottom half of table 2 shows the results on\nthe chinese evaluation set",
    "appliqu\u00e9e"
  ],
  [
    " the top kbp 2016\nevent coreference system on chinese is also the\nlu and ng (2016) system",
    "appliqu\u00e9e"
  ],
  [
    "80\n\nenglish\ntrigger anaph\n48",
    "appliqu\u00e9e"
  ],
  [
    "95\n\nchinese\ntrigger\n39",
    "appliqu\u00e9e"
  ],
  [
    " like its english counterpart, our chinese joint model outperforms the top kbp system for both event coreference and trigger detection",
    "appliqu\u00e9e"
  ],
  [
    "7 table 3 shows the results on the english and chinese datasets when we\nadd each type of joint factors to the independent\nmodel and remove each type of joint factors from\nthe full joint model",
    "appliqu\u00e9e"
  ],
  [
    "\n\n7\nchen and ng (2013) also performed ablation on their\nace-style chinese event coreference resolver",
    "appliqu\u00e9e"
  ],
  [
    " the situation\nis further aggravated in chinese documents, where\nzero pronouns are prevalent",
    "appliqu\u00e9e"
  ],
  [
    "\nwhen evaluated on the kbp 2016 english and\nchinese corpora, our model not only outperforms\nthe independent models but also achieves the best\nresults to date on these corpora",
    "appliqu\u00e9e"
  ],
  [
    " chinese event\ncoreference resolution: understanding the state of\nthe art",
    "appliqu\u00e9e"
  ],
  [
    " chinese event\ncoreference resolution: an unsupervised probabilistic model rivaling supervised resolvers",
    "appliqu\u00e9e"
  ],
  [
    " (the original data is\nin chinese, we translate this sample into english for clarity)\n\u2192\n\u2212\n\u2190\n\u2212 \u2190\u2212\u2212\u2212\n\u2212\u2212\u2212\u2192\nhs = gru (e(x)); hs = gru (e(x))\n\u2192\n\u2212 \u2190\n\u2212\nhs = [hs ; hs ]\n\n\u2022 pre-training stage: by using large-scale training data to train the neural network model,\nwe can learn richer word embeddings, as well\nas relatively reasonable weights in neural networks than just training with a small amount\nof zero pronoun resolution task training data;\n\nhquery\n\nn\n1x\n=\nhquery (t)\nn t=1\n\n(5)\n\nfor the document, we place a soft attention over\nall words in document (bahdanau et al",
    "appliqu\u00e9e"
  ],
  [
    "\n\n\u2022 overall performance\nwe employ four chinese zp resolution baseline\nsystems on ontonotes 5",
    "appliqu\u00e9e"
  ],
  [
    "\n\nrelated work\nzero pronoun resolution\n\nfor chinese zero pronoun (zp) resolution, early\nstudies employed heuristic rules to chinese zp\nresolution",
    "appliqu\u00e9e"
  ],
  [
    " zhao and ng\n(2007) first present a supervised machine learning approach to the identification and resolution\nof chinese zps",
    "appliqu\u00e9e"
  ],
  [
    " kong and zhou (2010) develop\na tree-kernel based approach for chinese zp resolution",
    "appliqu\u00e9e"
  ],
  [
    " chen and ng (2015)\npropose an end-to-end unsupervised probabilistic\nmodel for chinese zp resolution, using a salience\nmodel to capture discourse information",
    "appliqu\u00e9e"
  ],
  [
    " ferra\u0301ndez and peral (2000) proposed a\nset of hand-crafted rules for spanish zp resolution",
    "appliqu\u00e9e"
  ],
  [
    " recently, supervised approaches have been\nexploited for zp resolution in korean (han, 2006)\nand japanese (isozaki and hirao, 2003; iida et al",
    "appliqu\u00e9e"
  ],
  [
    " iida\nand poesio (2011) developed a cross-lingual approach for japanese and italian zps where an ilpbased model was employed to zero anaphora detection and resolution",
    "appliqu\u00e9e"
  ],
  [
    " ltp:\na chinese language technology platform",
    "appliqu\u00e9e"
  ],
  [
    " chinese zero pronoun resolution: some recent advances",
    "appliqu\u00e9e"
  ],
  [
    " chinese zero pronoun resolution: an unsupervised approach combining ranking and integer linear programming",
    "appliqu\u00e9e"
  ],
  [
    " chinese zero pronoun resolution: a joint unsupervised discourseaware model rivaling state-of-the-art resolvers",
    "appliqu\u00e9e"
  ],
  [
    " japanese\nzero pronoun resolution based on ranking rules and\nmachine learning",
    "appliqu\u00e9e"
  ],
  [
    " chinese zero pronoun resolution with deep neural networks",
    "appliqu\u00e9e"
  ],
  [
    "\nfang kong and guodong zhou",
    "appliqu\u00e9e"
  ],
  [
    " a tree kernelbased unified framework for chinese zero anaphora\nresolution",
    "appliqu\u00e9e"
  ],
  [
    " pronominal anaphora resolution in chinese ",
    "appliqu\u00e9e"
  ],
  [
    " a computational approach to zero-pronouns in spanish",
    "appliqu\u00e9e"
  ],
  [
    " korean zero pronouns: analysis\nand resolution",
    "appliqu\u00e9e"
  ],
  [
    " a discriminative approach to japanese zero anaphora resolution with large-scale lexicalized case frames",
    "appliqu\u00e9e"
  ],
  [
    " identification and resolution of chinese zero pronouns: a machine learning approach",
    "appliqu\u00e9e"
  ],
  [
    " latin roots), producing accurate representations of rare, misspelt, or even unseen words",
    "appliqu\u00e9e"
  ],
  [
    " probabilistic fasttext outperforms both fast t ext, which has no\nprobabilistic model, and dictionary-level\nprobabilistic embeddings, which do not\nincorporate subword structures, on several word-similarity benchmarks, including english rareword and foreign language datasets",
    "appliqu\u00e9e"
  ],
  [
    "\n\ntraining details\n\nwe train our models on both english and foreign language datasets",
    "appliqu\u00e9e"
  ],
  [
    "\nfor foreign languages, we demonstrate the\ntraining of our model on french, german, and italian text corpuses",
    "appliqu\u00e9e"
  ],
  [
    "\nwe adjust the hyperparameters on the english\ncorpus and use them for foreign languages",
    "appliqu\u00e9e"
  ],
  [
    "1, 1, 10, 100} and\n1\n1\n1\n1\n\u03b1 \u2208 { 5\u00d710\n\u22123 , 10\u22123 , 2\u00d710\u22124 , 1\u00d710\u22124 } on our english corpus",
    "appliqu\u00e9e"
  ],
  [
    " for example, piano in italian\ncan mean \u201cfloor\u201d or \u201cslow\u201d",
    "appliqu\u00e9e"
  ],
  [
    " we use italian w ord s im 353 and italian s im l ex -999 (leviant and reichart, 2015) for\nitalian models, gur350 and gur65 (gurevych,\n2005) for german models, and french w ord s im 353 (finkelstein et al",
    "appliqu\u00e9e"
  ],
  [
    ", 2002) for french models",
    "appliqu\u00e9e"
  ],
  [
    "\nin proceedings of the ieee international conference on acoustics, speech, and signal processing,\nicassp 2011, may 22-27, 2011, prague congress\ncenter, prague, czech republic",
    "appliqu\u00e9e"
  ],
  [
    "355\n\ntable 1: spearman\u2019s \u03c1 correlation scores for three standard english distributional vectors spaces on\nenglish simlex-999 (sl) and simverb-3500 (sv), using explicit retrofitting models with two different\nobjective functions (er-msd and er-cnt, cf",
    "appliqu\u00e9e"
  ],
  [
    "\n\nitalian\n\ncroatian\n\n",
    "appliqu\u00e9e"
  ],
  [
    "315\n\ntable 3: spearman\u2019s \u03c1 correlation scores for german, italian, and croatian embeddings in the transfer setup: the vectors are specialized using the models trained on english constraints and evaluated on\nrespective language-specific simlex-999 variants",
    "appliqu\u00e9e"
  ],
  [
    "\ntor space6 containing word vectors of three other\nlanguages \u2013 german, italian, and croatian \u2013 along\nwith the english vectors",
    "appliqu\u00e9e"
  ],
  [
    "7 concretely, we map the\nitalian cbow vectors (dinu et al",
    "appliqu\u00e9e"
  ],
  [
    ", 2015), german\nfasttext vectors trained on german wikipedia (bojanowski et al",
    "appliqu\u00e9e"
  ],
  [
    ", 2017), and croatian skip-gram\nvectors trained on hrwac corpus (ljubes\u030cic\u0301 and\nerjavec, 2011) to the g love -cc english space",
    "appliqu\u00e9e"
  ],
  [
    "\nwe create the translation pairs needed to learn the\nprojections by automatically translating 4,000 most\nfrequent english words to all three other languages\nwith google translate",
    "appliqu\u00e9e"
  ],
  [
    " we then employ the er\nmodel trained to specialize the g love -cc space\nusing the full set of english constraints, to specialize the distributional spaces of other languages",
    "appliqu\u00e9e"
  ],
  [
    "2\n\ngerman\n\nresults",
    "appliqu\u00e9e"
  ],
  [
    ", by 13% for german vector\nspace) over distributional spaces also in the language transfer setup without seeing a single constraint in the target language",
    "appliqu\u00e9e"
  ],
  [
    " this is why we also investigate zeroshot specialization: we test if it is possible, with the\nhelp of cross-lingual word embeddings, to transfer\nthe specialization knowledge learned from english\nconstraints to languages without any training data",
    "appliqu\u00e9e"
  ],
  [
    " the more sophisticated contrastive er-cnt model variant again\noutperforms the simpler er-msd variant, and it\ndoes so for all three languages, which is consistent\nwith the findings from the monolingual english\nexperiments (see table 1)",
    "appliqu\u00e9e"
  ],
  [
    " we plug into l ight-ls both\nunspecialized and specialized variants of three previously used english embedding spaces: g lov e cc, fast t ext, and sgns-w2",
    "appliqu\u00e9e"
  ],
  [
    "\nomer levy, yoav goldberg, and ido dagan",
    "appliqu\u00e9e"
  ],
  [
    " hrwac\nand slwac: compiling web corpora for croatian and\nslovene",
    "appliqu\u00e9e"
  ],
  [
    "unsupervised neural machine translation with weight sharing\nzhen yang1,2 , wei chen1 , feng wang1,2\u2217, bo xu1\ninstitute of automation, chinese academy of sciences\n2\nuniversity of chinese academy of sciences\n{yangzhen2014, wei",
    "appliqu\u00e9e"
  ],
  [
    " to guarantee no exact correspondence between the source and target monolingual sets, we\nbuild monolingual corpora by selecting english\nsentences from 15m random pairs, and selecting\nthe french sentences from the complementary set",
    "appliqu\u00e9e"
  ],
  [
    ", 2015b), which has an english vocabulary of about 32000 tokens, and french vocabulary of about 33000 tokens",
    "appliqu\u00e9e"
  ],
  [
    " since the data set is not big enough, we just\nbuild the monolingual data set by randomly shuf\ufb02ing the chinese and english sentences respectively",
    "appliqu\u00e9e"
  ],
  [
    " both the chinese and english sentences are\nencoded with byte-pair encoding",
    "appliqu\u00e9e"
  ],
  [
    " we get an english vocabulary of about 34000 tokens, and chinese vocabulary of about 38000 tokens",
    "appliqu\u00e9e"
  ],
  [
    "6k bilingual sentence pairs of english-hebrew, since hebrew is a rare language",
    "appliqu\u00e9e"
  ],
  [
    " if french is introduced\nas the third language, we can have another lowresource bilingual data of french-hebrew (116",
    "appliqu\u00e9e"
  ],
  [
    "\narabic (ar) and spanish (es) are used as two\nsimulated rare languages z",
    "appliqu\u00e9e"
  ],
  [
    "\niwslt20121 : english-french is used as the\nrich-resource pair (x, y ), and two rare languages\nz are hebrew (he) and romanian (ro) in our\n\np(z|y)\n\u2207\u03b8z|y log p(z|y)\n= ez\u223cp(z|y) log\np(z|x)\nsimilar to reinforcement learning, models\np(z|x) and p(z|y) are trained using samples generated by the models themselves",
    "appliqu\u00e9e"
  ],
  [
    "\n\ntable 5: english to spanish translation sampled in the e-step as well as its time-step rewards",
    "appliqu\u00e9e"
  ],
  [
    " it should\nbe noted, however, that chinese and japanese have\nno explicit word boundaries and moses tokenizer\ndoes not segment sentences into words, and hence\nsubword segmentations are trained almost from\nunsegmented raw sentences in these languages",
    "appliqu\u00e9e"
  ],
  [
    " as\nthe output sentences are not segmented in chinese and japanese, we segment them with characters and kytea11 for chinese and japanese respectively before calculating bleu scores",
    "appliqu\u00e9e"
  ],
  [
    " as german is a morphologically rich\nlanguage and needs a huge vocabulary for word\nmodels, subword-based algorithms perform a\ngain of more than 1 bleu point than word\nmodel",
    "appliqu\u00e9e"
  ],
  [
    " japanese\nand korean voice search",
    "appliqu\u00e9e"
  ],
  [
    " a stochastic japanese morphological analyzer using a forward-dp backward-a* nbest search algorithm",
    "appliqu\u00e9e"
  ],
  [
    ", 2015) which is a multi-turn english conversation data set constructed from chat\nlogs of the ubuntu forum",
    "appliqu\u00e9e"
  ],
  [
    ", 2017) that consists of multiturn chinese conversations collected from douban\ngroup1 ",
    "appliqu\u00e9e"
  ],
  [
    "\n\nconclusions and future work\n\ngao huang, zhuang liu, laurens van der maaten, and\nkilian q weinberger",
    "appliqu\u00e9e"
  ],
  [
    "improving multi-turn dialogue modelling with utterance rewriter\nhui su1\u2217, xiaoyu shen2\u2217, rongzhi zhang3 , fei sun4 , pengwei hu5\ncheng niu1 and jie zhou1\n1\npattern recognition center, wechat ai, tencent inc, china\n2\nmpi informatics & spoken language systems (lsv), saarland informatics campus\n3\ninstitute of software, university of chinese academy of science\n4\n5\nalibaba group\nibm research, china\naaronsu@tencent",
    "appliqu\u00e9e"
  ],
  [
    " one\nmost important difficulty is the frequently occurred coreference and information omission in\nour daily conversations, especially in pro-drop\nlanguages like chinese or japanese",
    "appliqu\u00e9e"
  ],
  [
    " from our preliminary study of 2,000 chinese multi-turn con\u2217\n\nboth authors contributed equally",
    "appliqu\u00e9e"
  ],
  [
    "\nto get supervised training data for the utterance\nrewriting, we construct a chinese dialogue dataset\ncontaining 20k multi-turn dialogues",
    "appliqu\u00e9e"
  ],
  [
    " (2019)\nadopts a similar idea on english conversations to\nsimplify the downstream slu task by reformulating the original utterance",
    "appliqu\u00e9e"
  ],
  [
    " length of rewritten utterance:\n\ndataset\n\nto get parallel training data for the sentence\nrewriting, we crawled 200k candidate multi-turn\nconversational data from several popular chinese\nsocial media platforms for human annotators to\nwork on",
    "appliqu\u00e9e"
  ],
  [
    " length is counted in the\nunit of chinese characters",
    "appliqu\u00e9e"
  ],
  [
    "\ngeneral setup we built our vocabulary based\non character-based segmentation for chinese\nscripts",
    "appliqu\u00e9e"
  ],
  [
    " the\nresulting vocabulary size is 5629 (4813 chinese\n\ncompared models\n\nwhen choosing compared models, we are mainly\ncurious to see (1) whether the self-attention based\ntransformer architecture is superior to other networks like lstms, (2) whether the pointer-based\n\n2\nwe tried increasing the dimension but find it degrades\nthe performance",
    "appliqu\u00e9e"
  ],
  [
    " for this variant, we\nfeed the transcriptions to the google text2speech\napi, using the 6 available us english wavenet\nvoices (van den oord et al",
    "appliqu\u00e9e"
  ],
  [
    "hk\n\nplaylist\n\nabstract\n\no\n\nb\n\ni\n\ni\n\ncan you put this tune onto latin dance cardio\n\nas an essential task in task-oriented dialog\nsystems, slot filling requires extensive training\ndata in a certain domain",
    "appliqu\u00e9e"
  ],
  [
    "\nmusic item\nstep 2\n\nplaylist\nstep 2\n\ncan you put this tune onto latin dance cardio\nstep 1\n\nslot entity o o o o\n\nb\n\no\n\nb\n\ni\n\ni\n\n(b) our proposed framework, coach",
    "appliqu\u00e9e"
  ],
  [
    "\n\nutterance\nrepresentation\n\nutterance can you put this tune onto latin dance cardio\ncorrect\nincorrect\n\nrepresentation\n\nrepresentation\n\nencoder\n\nencoder\n\nregularization loss\n\ntemplate generation\n\ntemplate\nrepresentations\n\ncan you put this music item onto playlist\ncan you put this object name onto city\n\nsimilarity\ncomparison\n\n",
    "appliqu\u00e9e"
  ],
  [
    "\ntune\n\ncan you put this restaurant type onto artist\nstep one\n\nlatin dance cardio\nstep two\n\nfigure 2: illustration of our framework, coach, and the template regularization approach",
    "appliqu\u00e9e"
  ],
  [
    " we utilize the conll-2003 english named\nentity recognition (ner) dataset as the source domain (tjong kim sang and de meulder, 2003), and\nthe cbs scitech news ner dataset from jia et al",
    "appliqu\u00e9e"
  ],
  [
    "\n\naaron jaech, larry heck, and mari ostendorf",
    "appliqu\u00e9e"
  ],
  [
    "\nwhile in dataset duconv, a chinese dialogue\ndataset with structured knowledge, we compare\nto the baselines referred in (wu et al",
    "appliqu\u00e9e"
  ],
  [
    " metric f1 evaluates the performance at\nthe character level, which mainly uses in chinese\ndataset duconv",
    "appliqu\u00e9e"
  ],
  [
    " wong4 ,\nqihang feng1 , junhong huang1 , baoxun wang1\n1\nplatform and content group, tencent\n2\npeking university, beijing, china\n3\nuniversity of chinese academy of sciences\n4\nnlp2 ct lab / department of computer and information science, university of macau\n{jasonbwwu,jasoawang,careyfeng,vincenthuang,asulewang}@tencent",
    "appliqu\u00e9e"
  ],
  [
    "1 datasets\nto evaluate the performance of our proposed\nmethod, we implement experiments on a chinese social networking service (sns) corpus and\nthe cornell movie dialogues corpus (danescuthe chiniculescu-mizil and lee, 2011)",
    "appliqu\u00e9e"
  ],
  [
    "\nnese sns corpus is crawled from a chinese\nsocial network service douban,1 containing totally 1,022,592 single-turn dialogues from 12,857\nusers; while the cornell movie dialogues corpus consists of conversations from movie scrips",
    "appliqu\u00e9e"
  ],
  [
    "4 human evaluation results on the\ncornell corpus\nas shown in table 5, on the english dataset, the\ncomparison results are almost consistent with that\nin section 5",
    "appliqu\u00e9e"
  ],
  [
    "\nxiaoyu shen, hui su, vera demberg, and shuzi niu",
    "appliqu\u00e9e"
  ],
  [
    " the translated english version of the samples are listed on the right",
    "appliqu\u00e9e"
  ],
  [
    " \nstatement of the problem \nthe task of kds is to generate english text under the \nfo l low ing  constraints: \n1",
    "appliqu\u00e9e"
  ],
  [
    ", computer generation of \nmultl-paraq~raph english text, in preparation",
    "appliqu\u00e9e"
  ],
  [
    " \n3) few words in english are reserved for describing the \nabstract world only",
    "appliqu\u00e9e"
  ],
  [
    " reconstruct ion - the \ncentral issue \nthere appear to be a small number of general metaphors \n(on the order of fifty) that pervade commonly spoken \nenglish",
    "appliqu\u00e9e"
  ],
  [
    " \nfor example, a situational formula is a handy way to \nsignal familiar meaning, but i f  the formula is not known \nthe meaning may be lost entirely,  as when a greek says \nto an american cook, \"health to your hands",
    "appliqu\u00e9e"
  ],
  [
    " for example, \nwhen l iving in greece and discussing the merits of buy- \ning an icebox with a greek friend, i asked, \"doesn't the \niceman cometh?\" after giggling alone in the face of his \npuzzled look, i ended up feeling i hadn't communicated \nat a l l ",
    "appliqu\u00e9e"
  ],
  [
    " one more example wil l  be presented, \nbased on spontaneous conversation taped during thanks- ? \ngiving dinner, among native speakers of english from \ndifferent ethnic and geographic backgrounds",
    "appliqu\u00e9e"
  ],
  [
    "  grammars for  a large subset of  \nenglish have been wr i t ten  using this formal ism \\ [9 \\ ] ,  and its \ncomputat iona l  v iab i l i ty  has been demonstrated \\ [6 \\ ] ",
    "appliqu\u00e9e"
  ],
  [
    "  an \nexample of how an apsg can encode a large subset of english \nis the diagram grammar \\ [9 \\ ] ",
    "appliqu\u00e9e"
  ],
  [
    "  var iables in the mf phrase-s t ructure  \nare used to indicate ido f l l t  care a parts of the grammar rule \nphrase-s t ructure ,  while constants must match exact ly ",
    "appliqu\u00e9e"
  ],
  [
    " \nwe were especially concerned: \n- to check the perspicuity of metarules for describing \nsignif icant fragments of english using the above \nrepresentation for grammar rules",
    "appliqu\u00e9e"
  ],
  [
    " preliminary tests \nindicate that the system satisfies both these concerns; indeed, \nthe metarules worked so well that they exposed gaps in a \nphrase-structure grammar that was painstakingly developed \nover a f ive year period and was thought to be reasonably \ncomplete for a large subset of english 19\\]",
    "appliqu\u00e9e"
  ],
  [
    " the \nfirst rules acquired handle simple\" few-word sentences and \nexpand the basic phrase structure for english",
    "appliqu\u00e9e"
  ],
  [
    " \nfirst, from an engineering standpoint, the program succeeds \nadmirably; starting with no grammar ules and just two base \nschema rules, the currently implemented version (dubbed \nlparsifal) acquires from positive example sentences many of \nthe grammar rules in a \"core grammar\" of english originally \nhand-written by ",
    "appliqu\u00e9e"
  ],
  [
    " the currently acquired rules are \nsufficient to parse simple declaratives, much of the english \nauxiliary system including auxiliary verb inversion, simple \npassives, simple wh",
    "appliqu\u00e9e"
  ],
  [
    " \nacquired base rules include those for noun phrases, verb phrases, \nprepositional phrases, and a substantial part of the english \nauxiliary verb system",
    "appliqu\u00e9e"
  ],
  [
    " it is marcus' claim that \nthe addition of the look-ahead buffer enables parsifal to \nalways correctly decide what to do next - at least for english",
    "appliqu\u00e9e"
  ],
  [
    " this would seem essential if one is interested in the \nacquisition of phrase structure rules for languages whose \ncanonical subject-verb-object ordering is different from that of \nenglish",
    "appliqu\u00e9e"
  ],
  [
    " \n(n) (v) (n) \nonly one possible verb phrase rule expansion can successfully be \nmatched against the sample string, verb \nphrase->noun phrase(np)verb(v) - exactly the right result \nfor english",
    "appliqu\u00e9e"
  ],
  [
    " this ability to incrementally \nrefine a set of grammar rules rests upon the incremental \nproperties of the marcus parser, which in turn might reflect the \ncharacteristics of the english language itself",
    "appliqu\u00e9e"
  ],
  [
    " a transformational approach to english syntax",
    "appliqu\u00e9e"
  ],
  [
    " \nthe sri connection \nat sri international the~thor was responsible for the \ndevelopment of the english front-end for the ladder \nsystem \\[hendrix e ta l ",
    "appliqu\u00e9e"
  ],
  [
    " ladder was developed as \na prototype system for understanding questions posed in \nenglish about a naval domain; i t  translated each english \nquestion into one or more relational database queries, \nprosecuted the queries on a remote computer, and \nresponded with the requested information in a readable \nformat tailored to the characteristics of the answer",
    "appliqu\u00e9e"
  ],
  [
    " for \nexample, assuming a grammar for english in a traditional \nstyle, and the sentence, \"the old man ate fish,\" an \nordinary bottom-up parser will propose three s phrases, \none each for: \"man ate fish,\" \"old man ate fish,\" and \n\"the old man ate fish",
    "appliqu\u00e9e"
  ],
  [
    " \nthe grammars \nthe \"semantic grammar\" employed in the sri experiments \nhad been developed for the specific purpose of answering \nquestions posed in english about the domain of ships at \nsea \\[sacerdoti, 1977\\]",
    "appliqu\u00e9e"
  ],
  [
    " \nthe grammar \nthe grammar employed uring the lrc experiment was the \ngerman analysis grammar being developed at the lrc for \n? use in machine translation \\[lehmann et e l ",
    "appliqu\u00e9e"
  ],
  [
    " given the amount of text described by \nthe lrc german grammar, i t  may be presumedto operate in \na fashion reasonably representative of the general \ngrammar for german yet to be written? \nthe sentences \nthe sentences employed in the lrc experiment were \nextracted from three different technical texts on which \nthe lrc mt system had been previously tested",
    "appliqu\u00e9e"
  ],
  [
    " the sentences con- \ntalned therein may reasonably be expected to constitute \na nearly-representative sample of text in that domain, \nand presumably constitute a somewhat less-representative \n(but by no means t r iv ia l )  sample of the types of syntac- \nt ic structures encountered in more general german text",
    "appliqu\u00e9e"
  ],
  [
    "corepresentational grammar and parsing english comparatives \nkaren p#an \nuniversity of )linnesota \nsec",
    "appliqu\u00e9e"
  ],
  [
    " 3 corepresentational grammar (corg) \nmarcus \\[3\\] notes that the syntax of english comparative \nconstructions is highly complex, and claims that both \nsyntactic end semantic information must be available for \nthem to be parsed",
    "appliqu\u00e9e"
  ],
  [
    "performance comparison of component algorithms \nfor the phonemicization of orthography \njared bernstein larry nessly \ntelesensory speech systems university of north carolina \npalo alto, ca 94304 chapel hi l l ,  nc 27514 \na system for converting english text \ninto synthetic speech can be divided into two \nprocesses that operate in series: \ni) a text-to-phoneme converter, and \n2) a phonemic-input speech synthesizer",
    "appliqu\u00e9e"
  ],
  [
    " \nhunnicutt's algorithm is an adaptation of \nhalle's cyclic stress rules for english",
    "appliqu\u00e9e"
  ],
  [
    " nessly's \ndefault stress is quite similar to latin \nstress and to the \"first approximation\" stress \nrule discussed twoard the beginning of chomsky \n& halle's chapter three (1968, pp",
    "appliqu\u00e9e"
  ],
  [
    " norwood crout \nartificial intelligence corporation \nthe intellect natura l  language database  query  sys tem,  a \nproduct of artificial intelligence corporation, is the \nonly commercially available system with true english \nquery capability",
    "appliqu\u00e9e"
  ],
  [
    " \nintellect's basic function is to translate typed english \nqueries into retrieval commands for a database manage- \nment system, then present the retrieved data, or answers \nbased on it, to the terminal user",
    "appliqu\u00e9e"
  ],
  [
    " \nartificial intelligence corporation was founded about \nfive years ago, for the specific purpose of developing \nand marketing an english language database query pro- \nduct",
    "appliqu\u00e9e"
  ],
  [
    " \nwe also test its fluency: its ability to understand, re- \ntrieve, and process requests that  are expressed in a \nwide variety of english phrasings",
    "appliqu\u00e9e"
  ],
  [
    " such a file of queries will contain, in addition \nto reasonable english sentences, both sentence fragments \nand unnatural phrasings",
    "appliqu\u00e9e"
  ],
  [
    " this kind of test is desir- \nable, since users who are familiar with the system will \nfrequently enter only those words and phrases chat are \nnecessary to express their needs, with little regard for \nenglish syntax, in order to minimize the number of key- \nstrokes",
    "appliqu\u00e9e"
  ],
  [
    " \na b ig  advantage of english language query systems is the \nabsence of training as a requirement for its use; this \npermits people to access data who are unwilling or un- \nable to learn how to use a structured query system",
    "appliqu\u00e9e"
  ],
  [
    "translat ing english into logical  form'  \nstanley j",
    "appliqu\u00e9e"
  ],
  [
    " the scheme is the \nbasis for an english translation system called parr and was used to \nspecify a semantically interesting fragment of english, including such \nconstructs as tense, aspect, modals, and various iexically controlled verb \ncomplement s ructures",
    "appliqu\u00e9e"
  ],
  [
    " in our \nformalism, translation types are associated with the phrasal categories \nof english in much the way that logical-denotation types are associated \nartificial intelligence center \nsri international \n333 raveoswood avenue \nmenlo park, ca 94025 \nwith phrasal categories in model-theoretic semantics",
    "appliqu\u00e9e"
  ],
  [
    ", the translations of english \nphrases",
    "appliqu\u00e9e"
  ],
  [
    " \niii experiments in producing and us ing \nlogical  form \na a work ing  grammar  \nto illustrate the ease with which diverse semantic features \ncould be handled, a grammar was written that defines a semantically \ninteresting fragment of english along with its translation into logical \nform \\[moore, 1981\\]",
    "appliqu\u00e9e"
  ],
  [
    " our strategy was to first translate english \ninto logical formulas of the type discussed in \\[moore, 1981\\], which \nwere then postprocessed into a form suitable for a first-order deduc- \ntion system",
    "appliqu\u00e9e"
  ],
  [
    " morphological \nanalysis of finnish by computer",
    "appliqu\u00e9e"
  ],
  [
    " sample  grammar  rules \nthe following is a portion of a test grammar for the patr \nenglish translation system",
    "appliqu\u00e9e"
  ],
  [
    " in adopting these terms we mean to be speaking very \ngenerally; thus we mean to avoid, for example, any claim that tokens \nof english are internalised (a term we will use for o) into \nrecognisable tokens of mentalese",
    "appliqu\u00e9e"
  ],
  [
    " in particular, the proper account \nof e for humans could well simply describe how the field of \nmentalese structures, in some configuration, is transformed into some \nother configuration, upon being presented with a particular english \nsentence; this would still count, on our view, as a theory of o",
    "appliqu\u00e9e"
  ],
  [
    " all in all, we cannot \nignore the attempt on the computationalists' part to provide complex \nmechanisms so strikingly similar to the complex ways we use noun \nphrases in english",
    "appliqu\u00e9e"
  ],
  [
    " thus they too will need semantics; the internalisation \nof english into a computer (o) is a translation relationship (in the \nsense of preserving ~, presumably) - -  even if it is wildly contextual, \nand even if the internal anguage is very different in structure from \nthe st",
    "appliqu\u00e9e"
  ],
  [
    "rucmre of english",
    "appliqu\u00e9e"
  ],
  [
    " \nconsider for example the zlone language presented by \nbrachman et al 21 although no semantics for klone has been \npresented, either procedural or declarative, its proponents have \nworked both in investigating the o-sehaantics (how to translate \nenglish into klone), and in developing an informal account of the \nprocedural spects",
    "appliqu\u00e9e"
  ],
  [
    " the \nmodel-theoretic semantics used here is that given \nin the proper treatment of quantification in \nordinar~ english (ptq) \\[montague 1973\\], but the \nproblems and results discussed here apply to \nsimilar systems and theories",
    "appliqu\u00e9e"
  ],
  [
    " \nthis need to correctly identl~y equivalent \nexpressions presents a problem because even within \nthe subset of expressions that are the translations \nof english phrases in the ptq fragment, equivalence \nis undec ldab le  \\[warren 1979\\]",
    "appliqu\u00e9e"
  ],
  [
    " this \nmechanism can also be viewed as using an \n* while the fragment of english used in ptq is \nlarge enough to demonstrate the introduction of \ninconsistent information, it is viewed as not being \nlarge enough to permit interesting claims about \nwhat are useful techniques for testing \nequivalences",
    "appliqu\u00e9e"
  ],
  [
    " in each case, the english question is \nthe same, but the required database query is \nradically different",
    "appliqu\u00e9e"
  ],
  [
    ", \"who is the manager such that he \nmanages each department?\" the main issues are: \nwhat would be a suitable representation for the \nmeaning of this sort of question, and what would \nbe the formal semantics of that representation? \nv querying semantically complex fields \nnatural-language query systems usually assume \nthat the concepts represented by database fields \nwill always be expressed in english by single \nwords or fixed phrases",
    "appliqu\u00e9e"
  ],
  [
    " \nin my discussion, i will assume the use of a \ngeneral grammar of english rather than a semantic \ngrammar, and also that the interpretation of \nqueries will pass through an intermediate stage in \nwhich a database-lndependent representation of the \nmeaning of the query is derived before \nconstructing the formal database query",
    "appliqu\u00e9e"
  ],
  [
    " \nquerying se~iantically complex fields \nin posing this problem, the session chairman \npointed out that natural language query systems usu- \nally assume that the concepts represented by data- \nbase fields will always be expressed in english by \nsingle words or fixed phrases",
    "appliqu\u00e9e"
  ],
  [
    " )), and the logical variables that \ncan be pulled all the way forward correspond to \ninformation implicitly requested in english queries",
    "appliqu\u00e9e"
  ],
  [
    "english words and data bases: how to bridge the gap \nremko j",
    "appliqu\u00e9e"
  ],
  [
    " system tries to transform an eng- \nlish question directly into the simplest possible \nformulation of the corresponding data base query, \ndiscrepancies between the english lexicon and the \nstructure of the data base cannot be handled well",
    "appliqu\u00e9e"
  ],
  [
    " system is therefore, how to embody in the \nsystem the necessary knowledge about the relation \nbetween english words and data base notions",
    "appliqu\u00e9e"
  ],
  [
    " \nin designing the phliqai system, bridging the \ngap between free english input and an equally un- \nconstrained data base structure was one of the main \ngoals",
    "appliqu\u00e9e"
  ],
  [
    " \nat the highest of these levels,the meaning of \nthe question is represented by an expression of the \nenglish-oriented formal language (efl); this lan- \nguage uses semantic primitives which correspond to \nthe descriptive lexical items of english",
    "appliqu\u00e9e"
  ],
  [
    " \nthe formula (3), or a logically equivalent dne, may \nthen be derived on the basis of a specification of \nthe relation between the english word meanings used \nin (i) and the primitive concepts at the data base \nlevel",
    "appliqu\u00e9e"
  ],
  [
    " \nit is clear that this data base, because of \nits greater \"distance\" to the english lexicon, re- \nquires a more extensive set of simplification rules \nif the dbl query produced by the translation rules \nis to be transformed into its simplest possible \nform",
    "appliqu\u00e9e"
  ],
  [
    " using the techniques of introducing \"prox- \nies\" (section v) and \"complementary constants\" \n(section vi) in dbl, a considerable distance be- \ntween the english lexicon and the data base struc- \nture can be covered by means of local translation \nrules",
    "appliqu\u00e9e"
  ],
  [
    " bipin \nindurkhya (1981) implemented a program which shows \nhow this approach accommodates the meaning postu- \nlates of montague's ptq and similar fragments of \nenglish",
    "appliqu\u00e9e"
  ],
  [
    " a com- \npiler or interpreter), of considerable complexity, \nwill be needed for the interpretation of computer \ninput in either prolog or japanese",
    "appliqu\u00e9e"
  ],
  [
    " \nchomsky took this as an argument for non-cf-ness in \nenglish, since he thought all string contrasting \nlanguages were non-cf (see chomsky 1963, 378-379), \nbut it can be reinterpreted as an attempt to show \nthat english is (at least) profligate",
    "appliqu\u00e9e"
  ],
  [
    " (it could \neven be reconstituted as a formally valid argument \nthat english was non-cf if supplemented by a \ndemonstration that the class of phrases from which \nthe bracketed sequences are drawn is not only\" \ninfinite but non-regular; of",
    "appliqu\u00e9e"
  ],
  [
    " hence these examples do not show that \nthere is a homomorphism mapping english onto some \nprofligate string contrasting language",
    "appliqu\u00e9e"
  ],
  [
    " for example, if english \nhad pp - s\" order in verb phrases (explain to him \n~a~ he'll have to leave) but had s\" - pp order in \nadjectives (so that lucky for us we found you had \nthe form lucky we found you for us), the grammar of \nenglish would not have the ecpo property",
    "appliqu\u00e9e"
  ],
  [
    " there are also some poten- \ntially interesting implications for parsing, stu- \ndied by shieber (1983a), who shows that a modified \nearley algorithm can be used to parse id/lp format \ngr----mrs d i rec t ly?  \none putative challenge to any claim that cf- \npsg's can be strongly adequate descriptions for \nhuman languages comes from dutch and has been d is -  \ncussed recent ly  by bresnan, kaplan, peters ,  and \nzaenen (1982)",
    "appliqu\u00e9e"
  ],
  [
    " dutch has construct ions l ike \n(7) dat jan pier marie zag leren zwemmen \nthat jan pier marie saw teach swim \n\"that jan saw pier teach marie to swim\" \nthese seem to involve crossing dependencies over a \ndomain of potentially arbitrary length, a confi- \nguration that is syntactically not expressible by a \ncf-psg",
    "appliqu\u00e9e"
  ],
  [
    " accept, \nthe actual dependencies in dutch are not syntactic",
    "appliqu\u00e9e"
  ],
  [
    " what is really at issue is \nwhether a cf-psg can assign syntactic qtructures to \nsentences of dutch in a way that supports semantic \ninterpretation",
    "appliqu\u00e9e"
  ],
  [
    " under this view too, \nthere is nothing about the syntax of dutch that \nmakes it non-cf, and there is not necessarily any- \nthing in the grammar that makes it non-ecpo",
    "appliqu\u00e9e"
  ],
  [
    " \nhenry thompson \"also discusses the dutch problem \nfrom the gpsg standpoint (in this volume)",
    "appliqu\u00e9e"
  ],
  [
    " pollard has shown \nthat this provides for an elegant syntactic treat- \nment of the dutch facts",
    "appliqu\u00e9e"
  ],
  [
    "  mention at the end of their paper \non dutch a set of potential candidates: the so \ncalled \"free word order\" or \"nonconfigurational\" \nlanguages, particularly australian languages like \ndyirbal and walbiri, which can allegedly distribute \nelements of a phrase at random throughout a sen- \ntence in almost any order",
    "appliqu\u00e9e"
  ],
  [
    " cross-serial dependencies in \ndutch",
    "appliqu\u00e9e"
  ],
  [
    " dutch subordinate \nclauses",
    "appliqu\u00e9e"
  ],
  [
    " dutch subordinate \nclauses for non-transformational theories of \ngrammar",
    "appliqu\u00e9e"
  ],
  [
    " \nin a recent paper (bresnan kaplsn peters end \nzaenen 1982) (hereafter bkpz), a solution to the \ndutch problem was presented in terms of lfg (kaplan \nand bresnan 1982), which is known to have \nconsiderably more than context-free power",
    "appliqu\u00e9e"
  ],
  [
    " this is essentially the \nstructure we will produce for the dutch examples as \nwell, so it is important to point out exactly how \nthe crossed dependencies are captured",
    "appliqu\u00e9e"
  ],
  [
    " application to dutch \ngiven the limited space available, i can present \nonly a very high-level account of how this \nextension to gpsg can provide an account of crossed \nserial dependencies in dutch",
    "appliqu\u00e9e"
  ],
  [
    " 1 the dutch data \ndiscussion of the phenomenon of crossed serial \ndependencies in dutch subordinate clauses is \nbedeviled by considerable disagreement about just \nwhat the facts are",
    "appliqu\u00e9e"
  ],
  [
    " \nwith the proviso that (i) is often judged \nquestionable, at least on stylistic grounds, this \npattern of judgements seems fairly stable among \nnative speakers of dutch from the netherlands",
    "appliqu\u00e9e"
  ],
  [
    " \nthere is some suggestion that this is not  the \npattern of judgements typical of native speakers of \ndutch from belgium",
    "appliqu\u00e9e"
  ],
  [
    "2 grammar rules for the dutch data \nthis pattern leads us to propose the following \nbasic rules for subordinate clauses: \na) s' -> omdat np vp \nb) vp -> v vp (probeer) \nc) vp -> np v vp (leren) \nd) vp -> np v (spreken)",
    "appliqu\u00e9e"
  ],
  [
    "3 semantic rules for the dutch data \nthe semantics follows that in section ii",
    "appliqu\u00e9e"
  ],
  [
    " on the other hand, i do not \nbelieve they can account for all of the following \nconjunction judgement, the first three based on \n(4), the next two on (3), whereas under the \nstandard gpsg treatment of conjunction they all \nfall out of our analysis: \n6) omdat ik nikki nederlanda wil leren spreken \nen frans wil laten schrijven \nbecause i want to teach nikki to speak dutch \nand let \\[nikki\\] write french \n7) * omdat ik nikki nedrelands wil leren spreken \nen frans laten schrijven \n8) omdat ik nikki nederlands wil leren spreken \nen carla frans wil laten schrijven \nbecause i want to teach nikki to speak dutch \nand let carla write french",
    "appliqu\u00e9e"
  ],
  [
    " \n9) omdat ik nikki wil leren nederlands te spreken \nen frans te schrijven \nbecause i want to teach nikki to speak dutch \nand to write french \nio) * omdat ik nikki wil leren nederlands te \nspreken en carla frans te schrijven \nor \n",
    "appliqu\u00e9e"
  ],
  [
    " it does seem to me to offer a \nreasonably concise and satisfying account of at \nleast the dutch phenomena without radically \naltering the grammatical framework of gpsg",
    "appliqu\u00e9e"
  ],
  [
    " predicate raising in french and \nsundry languages",
    "appliqu\u00e9e"
  ],
  [
    " on the generality of the \nnested dependency constraint and the \nreason for an exception in dutch",
    "appliqu\u00e9e"
  ],
  [
    " one of the few analyses that \nrelies on the lexical-head constraint is a recent gpsg analysis of \ncoordination and extraction in english (gazdar, 1981\\]",
    "appliqu\u00e9e"
  ],
  [
    " as a hypothetical example of this phenomenon, let \nus suppose that english allowed relative clauses to be extraposed \nin general from noun phrases, instead of allowing just one ex- \ntraposifion",
    "appliqu\u00e9e"
  ],
  [
    " the following \ngerman sentence is an extreme xample of this phenomenon \n\\[uszkoreit, 1982\\]",
    "appliqu\u00e9e"
  ],
  [
    " as an example, let us consider \nthe japanese causative",
    "appliqu\u00e9e"
  ],
  [
    " furthermore, japanese allows the nps \nto order freely relative to one another (subject o considerations \nof ambiguity and focus), so that a fiat structure with some kind \nof extrinsic ordering is presumably preferable",
    "appliqu\u00e9e"
  ],
  [
    " the ~rst c~e includes those liberation \nrules that figure in analyses of free-word-order phenomena, plus \nsuch other rules as the subject-auxiliary-inversion metarule in \nenglish",
    "appliqu\u00e9e"
  ],
  [
    " the second case (those in which the categories on the \nright- and left-hand sides are the same) includes such analyses \nas the passive in english",
    "appliqu\u00e9e"
  ],
  [
    " 1982: ~processing english with a generalized \nphrase structure grammar,\" in proceedings a/ the 20th \nannual ,$feetin7 of the association /or computational linfuistic$, \nuniversity of toronto, toronto, canada (15-18 june}",
    "appliqu\u00e9e"
  ],
  [
    ", 1980- \"a phr~me structure analysis of the japanese \nlanguage,\" m",
    "appliqu\u00e9e"
  ],
  [
    " one \nis that both are committed to formulating \nmathematically rigorous semantic accounts of \nenglish",
    "appliqu\u00e9e"
  ],
  [
    " what made a \nfragment of english of interest to montague, then, \nwas that it contained loads of such contexts",
    "appliqu\u00e9e"
  ],
  [
    " \nmoreover, and not independently, for any attempt to \napply their overall philosophical picture to the \nsemantics of natural language, the propositional \nattitude contexts pose a crucial and seemingly \ni\"a fragment of situation semantics, will contain \na treatment of certain kinds of english \ninterrogatives ; further out in the future, \nsituation ~ will contain such a more \nextensive treatment",
    "appliqu\u00e9e"
  ],
  [
    " ,  that its leg is broken, \nso too does an utterance by the doctor of the \nsentence \"it's bone is broken\", in a context in \nwhich that same individual is what's referred to by \n? it\"",
    "appliqu\u00e9e"
  ],
  [
    " but surely it doesn't seem to \nde an asuse of english to call, say, a platypus \n\"david israel\"",
    "appliqu\u00e9e"
  ],
  [
    " this \nis the decision of b&p to let english sentences be \nthe domain of their purely compositional semantic \nfunctions",
    "appliqu\u00e9e"
  ],
  [
    " for montague, the \"normal form\" \nsemantic interpretation of english went by way of a \ntranslation from english into some by now \"fairly \nstandard\" logical language",
    "appliqu\u00e9e"
  ],
  [
    " still, his practice \nleaves one with the taste of a search for hidden \nlogical forms of a familiar type underlying the \ngrammmtical forms of english sentences",
    "appliqu\u00e9e"
  ],
  [
    " has more \nof the structure of english than any other \nartificial language we know, but it does \nnot pretend to be  a fragment of english, or \nany sort of \"logical form\" of english",
    "appliqu\u00e9e"
  ],
  [
    " \nnext, and centrally, there is english",
    "appliqu\u00e9e"
  ],
  [
    " the \ndecision to present a semantic theory of english \ndirectly may make the end product look even more \ndifferent than it is",
    "appliqu\u00e9e"
  ],
  [
    " for \ninstance, are english quantifiers logical \nconstants, and if so, which ones? which english \nquantlfiers correspond to which \"formal\" \nquantiflers? ? is there really a sententlai negation \noperator in english? well, surely nit is not the \ncase that\" seems to qualify; but how about \"not\"? \nand how about conjunction? \nconsider, fo r  example, a statement made \nwith the sentence (i) joe admires sarah and \nshe admires him",
    "appliqu\u00e9e"
  ],
  [
    " indeed, i assume many of you will simply \nwant to wait until you can look at least at some \ntreatment of some fragment of english",
    "appliqu\u00e9e"
  ],
  [
    " \nthe proper treatment of quantification in \nordinary english",
    "appliqu\u00e9e"
  ],
  [
    "using %-calculus to represent mf~knings in logic grammars* \ndavid scott warren \ncomputer science department \nsuny at stony brook \nstony brook, ny 11794 \nabstract \nthis paper descrlbes how meanings are repre- \nsented in a semantic grammar for a fragment of \nenglish in the logic programming language prolog",
    "appliqu\u00e9e"
  ],
  [
    " this phase takes the english text input \nand transforms it into structures in some internal \nmeaning-representation language",
    "appliqu\u00e9e"
  ],
  [
    " \nthe meaning of the english sentence is identified \nwith the meaning that the formula has in the in- \ntended interpretations for the mrfol",
    "appliqu\u00e9e"
  ],
  [
    " this ability to go from a \nmeaning formula back to an english phrase that \nwould produce it is one of the attractive proper- \nties of logic grammars",
    "appliqu\u00e9e"
  ],
  [
    ", give a l-term that is a meaning, and have \nthe prolog system find the english phrase that has \nthat meaning",
    "appliqu\u00e9e"
  ],
  [
    " we suggested how such an \nintegration might allow grammars to be executed \nbackwards, generating english sentences from input \nlogical forms",
    "appliqu\u00e9e"
  ],
  [
    " \ndahl, veronica \\[1981\\] translating spanish into \nlogic through logic, american journal of \ncomputational linguistics, vol 7, no 3, (jul- \nsep 1981), 149-164",
    "appliqu\u00e9e"
  ],
  [
    " \\[1982\\] \ntranslating english into logical form, \nproceedings of the 20th annual meeting of the \nassociation for comp-~ational linguistics, \njune 1982, toronto, 1-8",
    "appliqu\u00e9e"
  ],
  [
    " \\[1982\\] from \nenglish to logic: context-free computation of \n'conventional' logical translation, american \njournal of computational linguistics, vol 8, \nno 1, (jan-mar 1982), 27-44",
    "appliqu\u00e9e"
  ],
  [
    "an improper treatment of quantification in ordinary english \njerry r",
    "appliqu\u00e9e"
  ],
  [
    " \njohn wants to marry any swedish woman",
    "appliqu\u00e9e"
  ],
  [
    " \n* john wants to marry every swedish woman",
    "appliqu\u00e9e"
  ],
  [
    " determining the scope of \nenglish quantlflers",
    "appliqu\u00e9e"
  ],
  [
    " montague  semant ics  \nin his well-known \"ptq\" paper (montague 1973), \nrichard montague presented the complete syntax and \nsemantics for a small fragment of english",
    "appliqu\u00e9e"
  ],
  [
    " \nthese semantic objects were represented by expres- \nsions of intensional logic; that is, instead of translat- \ning english directly into these objects, a sentence was \nfirst translated to an expression of intensional ogic, \nfor which, in turn, there existed an interpretation i\nterms of these semantic objects",
    "appliqu\u00e9e"
  ],
  [
    " for ex- \nample, the possessive in english is highly dependent \nupon pragmatics; the phrase nadia's penguin could \nrefer, in different circumstances, to the penguin that \nnadia owns, to the one that she is carrying but doesn't \nactually own, or to the one that she just bet on at the \npenguin races",
    "appliqu\u00e9e"
  ],
  [
    "  \nlogodden (1981) in f~ct uses them for s imple t rans la t ion  bet- \nween thai  and engl ish",
    "appliqu\u00e9e"
  ],
  [
    " however, it is not \npossible to maintain the one-to-one correspondence of \nrules when we replace montague's imple syntax with \nthe much larger english grammar of the paragram \nparser",
    "appliqu\u00e9e"
  ],
  [
    " this fol- \nlows from the uniform typing; the correspondence b t- \nween syntactic and semantic rules that maintains this \nuniformity; and there being a unique semantic object \ncorresponding to each word of english i~ (see dowty e~ \nal 1981:180-181)",
    "appliqu\u00e9e"
  ],
  [
    " their approach is to modify montague's \ntranslation from english to intensional logic so that \nthe resulting expressions have a canonical interpreta- \ntion in conceptual dependency",
    "appliqu\u00e9e"
  ],
  [
    " =evmuatmg english sentences in \na",
    "appliqu\u00e9e"
  ],
  [
    " \n\"processing english with a",
    "appliqu\u00e9e"
  ],
  [
    " montag~? grgmmar ~nd \nmachine er~nslation between english and thai",
    "appliqu\u00e9e"
  ],
  [
    " =questions in montague english",
    "appliqu\u00e9e"
  ],
  [
    " \"the proper treatment of \nquantification in ordinary english",
    "appliqu\u00e9e"
  ],
  [
    " \"translating english into logical form",
    "appliqu\u00e9e"
  ],
  [
    " \n\"from english to logic: context-free computation of \n'conventional' logical translation",
    "appliqu\u00e9e"
  ],
  [
    " thus the letter form \n\"c\"' is used in the russian alphabet to represent \nthe sound /s/, but it is not the same information \nunit as english \"c\", so it has a distinct code",
    "appliqu\u00e9e"
  ],
  [
    " they \nhave an unusually small number of basic letters, \nand to represent a larger number of sounds they use \ndigraphs like english sh, ch, th, or diacritics as \nin czech ~, ~",
    "appliqu\u00e9e"
  ],
  [
    " \nindeed english, french, german and scandinavian \nalphabets do alphabetize their digraphs just like \na sequence, s__ plus h etc",
    "appliqu\u00e9e"
  ],
  [
    " spanish, hungarian, \npolish, croatian and albanian treat their native \ndigraphs as single letters for purposes of alpha- \nbetical order",
    "appliqu\u00e9e"
  ],
  [
    " spanish i i  is not & sequence of \ntwo l's, but a new letter which follows all io, l~u \nsequences! similarly ch follows all c sequences, & \nfollows all ~ sequences as a separate letter",
    "appliqu\u00e9e"
  ],
  [
    " the umlauted letter ~ is \nalphabetized as a separate letter following _o in \nhungarian, and at the end of the alphabet in \nswedish, but in german it is mixed in with o",
    "appliqu\u00e9e"
  ],
  [
    " in \nspanish, ~ is treated as a separate letter, but the \nslovak ~_ ~epresenting the same sound is mixed in \nwith ordinary n",
    "appliqu\u00e9e"
  ],
  [
    " those in parentheses are alphabetized am a \nsequence of two or more letters or (slovak and \nczech i', n, ~ ~t', d_~ are treated as equivalent to \nthe simpler letter, completely disregarding the \ndiacritic",
    "appliqu\u00e9e"
  ],
  [
    " (in russian, palatal consonants are marked \nby choice of special vowel letters, while turkish \nhas a different kind of contrast, hence the blanks~ \neven when a digraph or trigraph is treated as \na sequence of letters for alphabetization, there \nmay be other evidence that it functions as a single \ninformation unit",
    "appliqu\u00e9e"
  ],
  [
    " in syllable division (hyphena- \ntion), english never divides the digraphs sh, oh, \nor th when they function as single units (~t~-er ,  \n~er)  but does when they represent two ~its \nt-house)",
    "appliqu\u00e9e"
  ],
  [
    " thus spanish e mr czech \n~_, _~, ~_ are produced by single keys, n~t by ~ g  \na diacritic to a base letter",
    "appliqu\u00e9e"
  ],
  [
    " mechanical limits \nhave forced a sequence of two letters (like the \nspanish oh, ~ to be typed with two separate key- \ns~rokes whether or not they represent a single \nfunctional unit, but occasionally we see excep- \ntions, an in dutch where the ~ digraph appears an \na ligature on a single key and is printed in one \nsound \" \nspace not  two",
    "appliqu\u00e9e"
  ],
  [
    " \nunit tmanalyzable letters exist in serbian \nand macedonian for most of the sound types (the \ncolumns) of table i",
    "appliqu\u00e9e"
  ],
  [
    " icelandic has single letters \n\"thorn\" and \"edh\" for the two rightmost columns",
    "appliqu\u00e9e"
  ],
  [
    " the im~inciple stated on the \npreceding page thus implies that unique codes be \navailable for english s h, c h, t_~h and unitary \ndigraphs in other languages so these can be used \nwhen needed in information processing",
    "appliqu\u00e9e"
  ],
  [
    " (informa- \ntion processing is not the shuffling of bits of \nscribal ink:) the principle does not compel use \nof those cedes -- english t h can be recorded first \nas a sequence of two cedes, then converted into a \nsingle cede only when needed, by a program which \nhas a dictions~y listing all wu~is containing \nmatary  t_h",
    "appliqu\u00e9e"
  ],
  [
    " some consonant characters in europe \nr~ l~ f ~ ~ ~ ~ ~ ~ ~ s ~ ts d,  o \"% \nrussian \nmacedonian \nserbian \nlu y~: q \\[,a~3 c x ~ \\[,,3\\] \nlu ~ q ~ c ",
    "appliqu\u00e9e"
  ],
  [
    "x q, s \nhungarian -- ly \ncroatian -- lj \ns'j",
    "appliqu\u00e9e"
  ],
  [
    "ovak -- (i') \nczech \nlatvian r i \npolish -- 1 \nc~man \nny \nnj \n(~)  \nn \n(~i)  \nty  gy \n( t ' )  (d ' )  \n(~)  (d ' )  \n6 (dg) \n(c i )  (d~)  \ns ,s  cs \\ [dzs\\]  sz - -  c \\ [dz\\ ]  - -  - -  \n~ ~ d~ s h c \\ [dz\\ ]  \n~ ~ (d~) s oh o \\ [d , \\ ]  ",
    "appliqu\u00e9e"
  ],
  [
    "  \nalbanian -- lj nj ",
    "appliqu\u00e9e"
  ],
  [
    "q gj \nturkish \nrom~i~ - -  ( ",
    "appliqu\u00e9e"
  ],
  [
    "  \nfrench - \"  ( ' ' ' )s ( ' ' ' )  ",
    "appliqu\u00e9e"
  ],
  [
    "  \nspanish -- ii ~ ",
    "appliqu\u00e9e"
  ],
  [
    " \nthe korean alphabet alanges its letters in \nsyllabic groups, so that mascot \nwould be a shown to  the r ight  m a c o \nif ~ritten in the k~rean manner, s t \nthe independently functioning \ninfcm~ation units are still consonants and vowels, \nfor which we need codes, and we need one additional \ncode to  m~k the division between syllables",
    "appliqu\u00e9e"
  ],
  [
    " this \ni s  jus t  as much an a lphabet  as o~ f~ l~r  english \nand is not a syll~hary",
    "appliqu\u00e9e"
  ],
  [
    "  even in  europe, spanish accented  vowels \n~, ~, ~_, _6, ~ show a v ~ l  sup~mpomit i~ of \nthe basic vowels with a functionally independent \nsymbol of accentnation",
    "appliqu\u00e9e"
  ],
  [
    " ~since \"c\" in \nczech represents the sound /ts/, it is not the same \nunit as ~ l l sh  \"c\"! in l i~ary processing it is \nimpcm~cant to  know that german den and di__~e are \narticles like ~ l i sh  the, to be disregarded in \nf i l i ng ,  but  engl ish  den and d ie  are  headwords",
    "appliqu\u00e9e"
  ],
  [
    "60-61 plus additions from \nafrican and vietnamese alphabets",
    "appliqu\u00e9e"
  ],
  [
    " a printer with only tamil \nletters can simply ~int  a tamil transliteration \nof an incoming hindl message",
    "appliqu\u00e9e"
  ],
  [
    " transliteration-equivalent information \n0 i 2 3 a \nin any t~ansliteration of his choice, either one \nusing many diacritic characters like c~oatlan and \nspecial symbols to avoid ambiguity, ~ one m~e \nadapted to his native alphabet, f~  example f~ench \ncr hungarian",
    "appliqu\u00e9e"
  ],
  [
    " \nthe r ight  128 blocks  of  256 codes each remain fa r  \nchinese/ japanese ch~acters  cr other  p~rposes,  but \neven these  can be coded a lphabet ica l l y  in  terms of \ncharacter components and arrangements (partly \nachieved in a keyboard now installed at stanford \nand the l l~:ary  of  confess ) ",
    "appliqu\u00e9e"
  ],
  [
    "transforming english interfaces to other natural languages: \nan experiment with portuguese \ngabriel pereira lopes (1) \ndepartamento de matem~tica \n? instituto superior de agronomia \ntapada da ajuda - 1399 lisboa codex, portugal \nabstract \nnowadays i t  is common the construction of \nenglish understanding systems (interfaces) that soo- \nner or later one has to re-use, adapting and conve~ \nting them to other natural languages",
    "appliqu\u00e9e"
  ],
  [
    " in this paper an experiment hat was \naccomplished for portuguese language is reported \nand some conclusions are expl ic itely stated",
    "appliqu\u00e9e"
  ],
  [
    " a know \nledge information processing system, known as ssipa, \nwith natural language comprehension capabilities \nthat interacts with users in portuguese through a \nportuguese interface, luso, was bui l t ",
    "appliqu\u00e9e"
  ],
  [
    " introduction \nthe chat-80 program for english (warren & \npereira, 1981; pereira, 1983) was transformed and a \ndapted to portuguese",
    "appliqu\u00e9e"
  ],
  [
    " logic programming as a mental \naid, and prolog (coelho, 1983; clocksin & melish , \n1981) and extraposition grammars (pereira, 1983) as \npractical tools, were adopted to implement a natu- \nral language interface for portuguese",
    "appliqu\u00e9e"
  ],
  [
    " \nssipa is a complex knowledge information processing \nsystem with natural language comprehension and syn- \nthesis capabilitites that interacts with users in \nportuguese due to the l inguist ic knowledge that is \nlogically organized and codified in the above men- \ntioned ssipa's interface ca\\]led luso",
    "appliqu\u00e9e"
  ],
  [
    " do bra= \ns i l ,  1799 lisboa codex, portugal \n(2) simulating system of a portuguese automatic in- \nterlocutor",
    "appliqu\u00e9e"
  ],
  [
    " all these features require a very power \nful portuguese language interface whosemain moron~ \n-syntact ic  features are pointed out in this pa- \nper",
    "appliqu\u00e9e"
  ],
  [
    " \nin a f i r s t  step i t  performs the syntactical analy- \nsis of an input portuguese sequence of words",
    "appliqu\u00e9e"
  ],
  [
    " \nthe design of luso input subsystem re - \nflects the following hypothesis: \n? morphological analysis of portuguese \nconstructs is syntactically driven; \n? l inguist ic semantic analysis of portu- \nguese constructs is lexical ly (functio \nnally) driven (in a quasi-bresnamian, \nsense (bresnam, 1981; pereira, 1983;lo \npes, 1984)); \n? cognitive semantic analysis of portu - \nguese constructs depends on syntacti - \ncal and l inguist ic  semantic analysis \npreviously achieved for portuguese cons \ntructs",
    "appliqu\u00e9e"
  ],
  [
    " \nthis suggests ssipa as a formal system \nthat already theorizes some aspects of portuguese \nlanguage while luso specificates the form of for- \nmal functions whose cognitive content and formal ap \ntitude for transforming system state are defined at \nthe semantic level of the formal system",
    "appliqu\u00e9e"
  ],
  [
    " morpho-syntactical analysis and synthe - \nsis of portuguese language constructs \nthe morpho-syntactical analysis of portu \nguese language constructs is application indepen - \ndent and is based on the various concepts develo- \nped by chomsky and followers in the framework of \nthe extended standard theory of generative grammar \n(chomsky, 1980, 1981a, 1981b; rouveret, 1983 and \nmany others)? as i t  was already mentioned in this \npaper, one of the crucial hypothesis behind luso's \ndesign reflects the idea that morphological analy- \nsis of portuguese constructs is syntactically dri- \nven",
    "appliqu\u00e9e"
  ],
  [
    " a syn- \ntagmatic marker for each input portuguese construct \nis f i l l ed  with word basic forms and correspon - \ndingsyntactic features information (person, gender \nand number for noun phrases; tense, mode, aspect , \nvoice and negation for verbs; etc",
    "appliqu\u00e9e"
  ],
  [
    " this means \nthat, departing from a syntagmatic marker lexical- \nlp f i l led  with basic forms of portuguese words, u- \nsing the syntactic features that are expl ic i te l ly  \nconsidered into that marker, luso output subsystem \ncoines the corresponding sequence of portuguese \nwords in its final output form ready to be sent to \nthe user with whom the system is interacting",
    "appliqu\u00e9e"
  ],
  [
    " \nextraposition grammars, the formalism d e \nveloped by pereira (1983), were used to implement \nthe analyser and the synthesizer for portuguese",
    "appliqu\u00e9e"
  ],
  [
    " as a matter of fact phrase constituents or- \nder in portuguese sentences is quite free",
    "appliqu\u00e9e"
  ],
  [
    " having \nthis in mind, portuguese language seriously compe- \ntes with english because i t  rises quite important \nsyntactic, semantic and pragmatic problems similar \nto problems risen by lat in,  slavonic and germanic \nlanguages",
    "appliqu\u00e9e"
  ],
  [
    ", \"an intell igent monitor \ninteracting in portuguese language\", short paper \naccepted for ecai-84, pisa",
    "appliqu\u00e9e"
  ],
  [
    " a brief exposition of the method \nwith some preliminary results, whenused as a device \nfor disamblguatingparsing english texts picked from \nnatural corpus, will be given",
    "appliqu\u00e9e"
  ],
  [
    " \\[ \ni ! \nthis catalan number is essentially exponentlal and \n\\[martin\\] reported a syntactically amblguous sentence \nwith 455 parses: \nlist the sales of products produced in 1973 i \ni \nwith the products produced in 1972",
    "appliqu\u00e9e"
  ],
  [
    " terence  langendoen \nyed ldyah langsam \ndepartments of english and computer & information science \nbrooklyn college of the city university of new york \nbrooklyn, new york 11210 u",
    "appliqu\u00e9e"
  ],
  [
    " this idea lies at the heart of \nug, lfg, and the patr-ii grammar for english \\[shieber, \net al, 83\\] constructed at sri",
    "appliqu\u00e9e"
  ],
  [
    " \nthe first example, \\[case: -dat\\], arises in the plu- \nral paradigm of words like \"kind\" child in german",
    "appliqu\u00e9e"
  ],
  [
    " \nthe ~econd example is from english",
    "appliqu\u00e9e"
  ],
  [
    " although the fea- \ntures \"number\" and \"person\" are both clearly needed in \nenglish verb morphology, most verbs are very incompletely \nspecified for them",
    "appliqu\u00e9e"
  ],
  [
    " \nthe system of articles in german provides many ex- \namples that call for disjunctive feature specifications",
    "appliqu\u00e9e"
  ],
  [
    "applications of a lexicographical data base for german \nwolfgang teubert \ninstitut f~r deutsche sprache \nfr iedr ich-kar l -str ",
    "appliqu\u00e9e"
  ],
  [
    "  12 \n6800 mannheim i, west germany \nabstract \nthe institut fhr deutsche sprache \nrecently has begun sett ing up a \nlexicographica l  data base for german \n(leda)",
    "appliqu\u00e9e"
  ],
  [
    " leda thus consists \nof the three components tezt bank, \ndiationary bank and resuzt bank and \nserves as a tool to suppport monol ingual  \ngerman dict ionary projects at the \ninstitute and elsewhere",
    "appliqu\u00e9e"
  ],
  [
    " it \nwas therefore a logical step to devise \nlexicographical  data base for german \n(leda) as a tool for the compi lat ion of \nnew dict ionaries",
    "appliqu\u00e9e"
  ],
  [
    " as sel f -evident as \nthis c la im seems to be, it is nonetheless \ntrue for most german monol ingual  \nd ict ionar ies on the market that they have \nbeen compi led without any corpus; this is \napparent ly  even the case for the new six \nvolume brockhaus-wahrig,  as has been \npointed out by wiegand/kucera  (1981 and \n1982)",
    "appliqu\u00e9e"
  ],
  [
    " for a general  d ict ionary of \n34 \ncontemporary german containing about \n200 000 lemmata, the homburger thesen \n(1978) asked for a corpus of not less than \n50 mi l l ion words (tokens)",
    "appliqu\u00e9e"
  ],
  [
    " \nat present, a number of machine readable \ncorpora in unif ied codif icat ion are \navailable at the institute, including the \nmannheim corpora of contemporary written \nlanguage, the freiburg corpus of spoken \nlanguage and the east/west german \nnewspaper corpus, total l ing altogether \nabout 7 mil l ion running words of text",
    "appliqu\u00e9e"
  ],
  [
    " towards a \ncumulated word data base for the german \nlanguage",
    "appliqu\u00e9e"
  ],
  [
    " the struc- \nture of the word data base for the \ngerman language",
    "appliqu\u00e9e"
  ],
  [
    " for example, english has a rich vocabu- \nlary of values for a relation called ma~n (from \nlatin magnus) that denotes the superlative degree \nof its argument: magn (sit) = ti6ht, magn (black) \n= je t ,  pitch, coal, magn (left) = hard, magn---~ay) \n= for all you're worth, and on and on",
    "appliqu\u00e9e"
  ],
  [
    " \n2 huichol transcription follows spanish except \nhigh back unrounded, ' glottal stop, ? high tone, \nw long syllable, ~ rhythm break, ~ voiced retro- \nflex alveopalatal fricative, ~ retroflex flap, cuv \nlabiovelar stop",
    "appliqu\u00e9e"
  ],
  [
    " \nbesides the major project in huichol, the system \nwas used by students for original lexicographic \nwork in dinka of the sudan, korean, and isnag of \nthe philippines",
    "appliqu\u00e9e"
  ],
  [
    " tolkovo-kombinatornyj slovar' russkogo \njazyka (with english introduction)",
    "appliqu\u00e9e"
  ],
  [
    "lexicon features for japanese syntactic analysis in mu-project-je \nyoshiyuki sakamoto \nelectrotechnical \nlaboratory  \nsakura-mura,  \nn i ihar i -gun ,  \ni bs rak i ,  japan \nmasayuki satoh \nthe japan information \ncenter of  science and \ntechnology \nnagata-cho, chiyeda-ku \ntokyo, japan \ntetsuya ishikawa \nuniv",
    "appliqu\u00e9e"
  ],
  [
    " abstract \nin this paper, we focus on the features of a \nlexicon for japanese syntactic analysis in \njapanese-to-english translation",
    "appliqu\u00e9e"
  ],
  [
    " japanese word \norder is almost unrestricted and kc~uio-~ti  \n(postpos i t iona l  case  par t i c le )  i s  an impor tant  \ndevice which acts as the case label(case marker)  \nin japanese sentences",
    "appliqu\u00e9e"
  ],
  [
    " therefore case grammar is \nthe most effective grammar for japanese syntactic \nanalysis",
    "appliqu\u00e9e"
  ],
  [
    " \nthe case frame governed by )buc~n and having \nsurface case(kakuio-shi), deep case(case label) \nand semantic markers for nouns is analyzed here to \nillustrate how we apply case grammar to japanese \nsyntactic analysis in our system",
    "appliqu\u00e9e"
  ],
  [
    " \nanalysis, morphological analysis divides the \nsentence into lexical items and then proceeds with \nsemantic analysis on the basis of case grammar in \njapanese",
    "appliqu\u00e9e"
  ],
  [
    " in the second phase, transfer, lexical \nfeatures are transferred and at the same time, the \nsyntactic structures are also transferred by \nmatching tree pattern from japanese to english, in \nthe final generation phase, we generate the \nsyntactic structures and the morphological \nfeatures  in english",
    "appliqu\u00e9e"
  ],
  [
    " coac_~pt of_~_deoendencv structure based on \ncase gramma\\[_/n jap_a_d~ \nin japan, we have come to the conclusion that \ncase grammar is most suitable grammar for japanese \nsyntactic analysis for machine translation \nsystems",
    "appliqu\u00e9e"
  ],
  [
    " this type of grammar had been proposed \nand studied by japanese linguists before \nfillmore's presentation",
    "appliqu\u00e9e"
  ],
  [
    " \nas word order is heavily restricted in \nenglish syntax, atng~augmented transition network \ngrammar) based on cfg~context free grammar ) is \nadequate for syntactic analysis in english",
    "appliqu\u00e9e"
  ],
  [
    " on the \nother hand, japanese word order is almost \nunrestricted and k~l!,jlio--shi play an important role \nas case labels in japanese sentences",
    "appliqu\u00e9e"
  ],
  [
    " therefore \ncase grammar is the most effective grammar for \njapanese syntactic analysis",
    "appliqu\u00e9e"
  ],
  [
    " \nin japanese syntactic structure, the word \norder is free except for a predicate(verb or verb \nphrase) located at the end of a sentence",
    "appliqu\u00e9e"
  ],
  [
    "by_ j:hu~/c_ll \nthe case frame governed by !_baag_<tn and having \nl~/_~luio:~hi, case label and semantic markers for\" \nnouns is analyzed here to illustrate how we apply \ncase grmlmlar to japanese syntactic analysis in our \nsystem",
    "appliqu\u00e9e"
  ],
  [
    " l~bkujo ,~hi include inner case and outer' \ncase markers in japanese syntax",
    "appliqu\u00e9e"
  ],
  [
    " \n42 \nas a result of categorizing deep cases, 33 \njapanese case labels have been determined as shown \nin table i",
    "appliqu\u00e9e"
  ],
  [
    "_fo_~_ve~bal_ca_se~_rames \nenglish label examples \n~~- \n1980 ~?(c \n~\\ [t~n",
    "appliqu\u00e9e"
  ],
  [
    "~,a~ -~ ~ ,5 \n~ <--9 ~ ,~', - lr r~\\] b-u \njapanese label \n(2) \";h~ objec~ \n(3) ~-~-  recipient \n(4l ~-z",
    "appliqu\u00e9e"
  ],
  [
    "~ 8 \nnote :  the capitalized letters form \nenglish acronym for that case label",
    "appliqu\u00e9e"
  ],
  [
    " semantic markimz of nouna \nwe analyze semantic features, and assign \nsemantic markers to japanese words classified as \nnouns and pronouns",
    "appliqu\u00e9e"
  ],
  [
    " \n4) features  of  adverb: sub-category  of  \nadverb( /ouk~,  te ido ,  (~2~iaiufsu, s~mr~10~?) \ncons ider ing  modal i ty ,  aspect ,  tense  and \ngradab i l i ty  \n5) features of other taigen: sub-category of \nrcnluj_z~hi( demonstrative, interrogative, \ndefinitive, or adjectival) and conjunction(phrase \nor sentence \n6i features o f /~k~l=~l* i (aux i l i a ry  verb):  \njodo~=%bi are sub classified by sub-category \non semantic feature:  \nmodality~negation, necessity, suggestion, \nprohibition ",
    "appliqu\u00e9e"
  ],
  [
    " \nin the same thing, there are problems how to \nfind an english term corresponding to the japanese \ntechnical terms not stored in dictionary, how to \ncollect a large number of technical terms \neffectively and to decide the length of compound \nwords, and how to edit this lexicon data base \neasily, accurately, safely and speedily",
    "appliqu\u00e9e"
  ],
  [
    "; \nana lys i s  grammar o f  japanese fo r  mu-pro jec t ",
    "appliqu\u00e9e"
  ],
  [
    " : japanese syntaetlc  lexiccm \nin mu project",
    "appliqu\u00e9e"
  ],
  [
    " we assume that a syntactic \ncomponent could be developed to translate explicit \ntemporal references in english (e",
    "appliqu\u00e9e"
  ],
  [
    " the ult imate real  is \nto a l low the user  of the expert system to enter  \ndata into the system by means of nl text which \nfol lows the l inguist ic convent ions of english",
    "appliqu\u00e9e"
  ],
  [
    "2 the f low o f  cont ro l  \nin addition to domain-specif ic knowledge, \na person reading a text also uses his linguistic \nknowledge of the english grammar",
    "appliqu\u00e9e"
  ],
  [
    " \nan intelligent analyzer and underscander \nof english",
    "appliqu\u00e9e"
  ],
  [
    " the english progressive may have a \nsecond meamng m addit,on to that cnaractenzed by prog above",
    "appliqu\u00e9e"
  ],
  [
    "classif icat ion of  modality  function and its appl icat ion \nto japanese language analys is  \nshozo narro ,  ak i ra  shimazu, and hirosato nomura \nmusashino electr ical  communicat ion laborator ies,  n",
    "appliqu\u00e9e"
  ],
  [
    " \n3-9-11, midori-cho, musashino-shi ,  tokyo, 180, japan  \nabstract \nthis paper proposes an analysis method for \njapanese modality",
    "appliqu\u00e9e"
  ],
  [
    " in this purpose, meaning of \njapanese modality is classified into four semantic \ncategories and the role of it is formalized into five \nmodality functions",
    "appliqu\u00e9e"
  ],
  [
    " this analysis method has \nbeen applied to japanese analysis for machine \ntranslation",
    "appliqu\u00e9e"
  ],
  [
    " the aim of this paper is to \nclarify the function of modality and to propose a method \nfor analyzing the modality in japanese sentences",
    "appliqu\u00e9e"
  ],
  [
    " \nstructure of a japanese complex sentence can be \nformalized roughly by iterative concatenation of simple \nsentences",
    "appliqu\u00e9e"
  ],
  [
    " finally, we exemplify the \nanalysis by showing translations from japanese into \nenglish",
    "appliqu\u00e9e"
  ],
  [
    " the method has been used to analyze \njapanese sentences in a machine translation system",
    "appliqu\u00e9e"
  ],
  [
    " :0-! this \nclassification is not sufficient for the deep analysis of \nthe meaning structure of a sentence, however, because \nit does not account for the role of japanese modal \nparticles",
    "appliqu\u00e9e"
  ],
  [
    " each category \ncan be further classif ied into subcategories, and those \nare shown in table 2 through table 5 (each table gives \nboth examples of japanese expressions and their  \nengl ish equivalents)",
    "appliqu\u00e9e"
  ],
  [
    " each example sentence is succeeded by an \nenglish translation and a logical representation ",
    "appliqu\u00e9e"
  ],
  [
    " tense \njapanese meaning ,expression \npast  ta \nnon-past ru \nenglish expression \n-ed (past ense) \npresent tense, or future tense \n(s2) hiroko ga hashit  teiru",
    "appliqu\u00e9e"
  ],
  [
    ") \nmeaning japanese xpressi",
    "appliqu\u00e9e"
  ],
  [
    " implicature \nmeaning \nlimitation \ndegree \nextreme-example \njapanese expression \nshika, kin, dake, bakari, \nmade, kurai \ndake, bakari, hodo, kurai \nsac, demo, datte, made \nenglish \nexpression \nonly \nas, about \neven \nstress sae, ha, too, koso even \nexample demo, nado, nari for example \nparallel yara, ya, mo and \naddition i sae, made also \nselection earl, ka or \nuncertainty ~ara, ka some \ndistinction ha us for \nthe modal particle \"wa\" determines the role of the \nauxi l iary verb \"nai\" as a partial negation while the case \nparticle \"ga\" determines it as total negation",
    "appliqu\u00e9e"
  ],
  [
    "japanese expression english expression meaning ",
    "appliqu\u00e9e"
  ],
  [
    "japanese expression \nnegation nai, zu not",
    "appliqu\u00e9e"
  ],
  [
    " \" \ntry \n!command \nquestion \nnasal, \\[imperative \nform of verbl \nka \nenglish expression \ntry \n\\[imperative form of \nverbl \n\\[ interrogative \ntransformationl \nrequest tekure, retai please ",
    "appliqu\u00e9e"
  ],
  [
    "3 application to japanese analysis \n(i) extended case analysis \nwe have already proposed a method named \nextended case analysis for japanese sentences",
    "appliqu\u00e9e"
  ],
  [
    " \nan  english sentence corresponding to this semantic \nstructure is shown in (s22)",
    "appliqu\u00e9e"
  ],
  [
    " conclusion \nwe proposed an analysis method for japanese \nmodality",
    "appliqu\u00e9e"
  ],
  [
    " \nwe have applied this modality analysis method to \nthe japanese sentence analysis in the japanese- \nenglish experimental machine translation system, \nlute",
    "appliqu\u00e9e"
  ],
  [
    " : toward a modern theory qf case \nand other articles, japanese edition, 1975",
    "appliqu\u00e9e"
  ],
  [
    " : a study of japanese adverbial particles \nin montague grammar, \"linguistic journal of \nkorea\", vol",
    "appliqu\u00e9e"
  ],
  [
    " nornura : japanese \nlanguage semantic analyser based on an extended \ncase frame model, proc",
    "appliqu\u00e9e"
  ],
  [
    " lhts method recovers clztn~ ~md identity \ninlbrmution from ~)rdinary english sentences",
    "appliqu\u00e9e"
  ],
  [
    " \n35 \ntheory is deployed in a natural hmguage system that \nnarscs sentences and bttilds a :~cmantic model from them, \nreiatus bccotncs, among other things, a system ibr \nacquiring class structure inlbrmation fi'om ordinary \nenglish texts",
    "appliqu\u00e9e"
  ],
  [
    "ai'us explt>its the \nencoding scheme underlying english usage of ct>l)ular \n'",
    "appliqu\u00e9e"
  ],
  [
    " the grammar formalism includes \ntwo devices which cause the automatical ly built \nsyntactic structures to differ from derivation trees \nin two ways: \\[i) there is a shift operator, for \ndeal ing with left-embedding constructions such as \nenglish possessive noun phrases while using right- \nrezursive rules (which are appropriate for prolog \nparsing)",
    "appliqu\u00e9e"
  ],
  [
    " \nthe syntactic formalism includes a t device, \ncalled the shift operator, for dealing with \nleft-embedding constructions such as english \npossessive noun phrases (\"my wife's brother's \nfriend's car\") and japanese relative clauses",
    "appliqu\u00e9e"
  ],
  [
    " \nthe value of the \"changing\" method over the \n\"adding\" method would appear to hinge a lot on the \nquestion of parse-time efficiency, because the \n\"changing\" method seems more complicated conceptu- \nally",
    "appliqu\u00e9e"
  ],
  [
    " (1981) \"translating spanish into logic \nthrough logic,\" american journal of computational \nlinguistics, vol",
    "appliqu\u00e9e"
  ],
  [
    " (1981) natural language information \nprocessing: a computer grammar of english and its \napplications, addison-wesley",
    "appliqu\u00e9e"
  ],
  [
    " to fatal- \nliarize the reader with the dcg notation, i discuss a fragment for \nenglish in this section",
    "appliqu\u00e9e"
  ],
  [
    " \na non-configurationa\\[ language dilfer~ front configurational \nlanguages like english in that morphological form (eg",
    "appliqu\u00e9e"
  ],
  [
    " \n(7) yarraga-aga~ mu-n gudaa gunda-y biiba-ngun \nboy-gen-mu-erg dog+abs hit-past father-l~rg \n'the boy's father hit the dog' \nthe idea, then, is that in these languages morphological form \nplays the same rule that word order does in a configurational \nlanguage like english",
    "appliqu\u00e9e"
  ],
  [
    " the morphologies/ form features eem to pose no particu- \nlar problem: they can be handled in a similia~ way to the genitive \nfeature in the mini-dcg for english in (3) (although a full account \nwould have to deal with the dual ergative/ahsohtive and \nnominative/accusative systems that guugu yimidhirr possesses)",
    "appliqu\u00e9e"
  ],
  [
    " \nsuppose, for example, guugu yimidhirr allowed stacked np \npoeseesors, in the same way that english allows them in construc- \ntions like my mother's lather'8 brother, except that, because the \nlanguage is non-configurational, the lexical elements could be scat- \ntered throughout the entire sentence",
    "appliqu\u00e9e"
  ],
  [
    "\" \nthe ia lets users manipulate databases and \nproduce reports by issuing commands or \nasking questions in english",
    "appliqu\u00e9e"
  ],
  [
    "time and tense in english \nmary p",
    "appliqu\u00e9e"
  ],
  [
    " harper and eugene charniak \nbrown university \ndepartment ofcomputer science \nbox 1910 \nprovidence, ri 02912 \nabst ract  \ntense, temporal adverbs, and temporal connectives \nprovide information about when events described in \nenglish sentences occur",
    "appliqu\u00e9e"
  ],
  [
    " \nin t roduct ion  \nenglish sentences contain many types of temporal \ninformation",
    "appliqu\u00e9e"
  ],
  [
    " \nthe following five rules describe the semantics of tense \nboth in english and in our representation",
    "appliqu\u00e9e"
  ],
  [
    " \"mary ate vhen jack had eaten \" \nconclusion \nthis paper describes a preliminary study of the temporal \nphenomena found in english sentences",
    "appliqu\u00e9e"
  ],
  [
    " five criteria were \nsuggested at the beginning of the paper for the \nrepresentation f temporal information found in an english \nsentence",
    "appliqu\u00e9e"
  ],
  [
    " meaning and the english verb",
    "appliqu\u00e9e"
  ],
  [
    " gundel, zero-np anaphora in \nrussian",
    "appliqu\u00e9e"
  ],
  [
    " \n\\[sidner1979\\] \ncandace lee sidner, towards a computa- \ntional theory of definite anaphora \ncomprehension i english discourse, mit- \nai tr-537, cambridge, m_a, 1979",
    "appliqu\u00e9e"
  ],
  [
    " an implementation of this work \nforms a critical portion of the knowledge acquisition \ncomponent of our transportable english-language \ninterface (tell),  which answers english questions \nabout tabular (first normal-form) data files and runs \non a symbolics lisp machine",
    "appliqu\u00e9e"
  ],
  [
    " we have sought to make tell  \n\"transportable\" in an extreme sense, where \ncustomizations may be performed (1) by end users, as \nopposed to the system designers, and (2) at any time \nduring the processing of english sentences, rather \nthan requiring a complete customization before \nenglish processing may occur",
    "appliqu\u00e9e"
  ],
  [
    "  which runs on a symbolics lisp machine, is \ndesigned to answer english questions about \ninformation stored in one or more tables, (i",
    "appliqu\u00e9e"
  ],
  [
    " \nenglish input:  \n",
    "appliqu\u00e9e"
  ],
  [
    " \nbut is less powerful, than the alternative english and \nenglish-like methods described in section 7",
    "appliqu\u00e9e"
  ],
  [
    " in most instances, the argument of a case \nslot can be an arbitrary ir structure, in keeping with \nthe recursive nature of the english inputs being \nrecognized",
    "appliqu\u00e9e"
  ],
  [
    " \nsince ir structures are built around the word \nand phrase types of the english being dealt with, and \nsince the meanings of words and phrases are stored \nglobally, ir structures should not be regarded as a \n\"knowledge representation\" in the sense of kl-one,  \nlogical form",
    "appliqu\u00e9e"
  ],
  [
    " \nfirst, the system will ask which columns contain \nvalues that either correspond to or are themselves \nenglish modifiers",
    "appliqu\u00e9e"
  ],
  [
    " on-line customization \nin general,  definitions are supplied to tel l  \nwhenever (a) an undefined modif ier is encountered \nduring the processing of an english input, or (b) the \nuser asks to supply or modify a definition",
    "appliqu\u00e9e"
  ],
  [
    "3 english and english-like specifications \nin addition, to the database and menu schemes \njust described, users may supply definitions in terms of \nenglish already known to the system",
    "appliqu\u00e9e"
  ],
  [
    " \nan alternative to english specification, which \nfunctions similarly from the user's standpoint, is to \nprovide for \"english-like\" specifications in which an \nexpression supplied by the user is translated by some \npattern-matching algorithm different from",
    "appliqu\u00e9e"
  ],
  [
    " the process involved \nin actual english parsing",
    "appliqu\u00e9e"
  ],
  [
    " the primary advantage of \nenglish-like specification, over english specification, \nis that translations into internal form can be more \nefficient, since definitions or parts of definitions will \nbe handled on a case by case basis",
    "appliqu\u00e9e"
  ],
  [
    " \nin teli ,  both english and english-like \nspecification are done in terms of sample domain \nvalues, which are treated as formal parameters",
    "appliqu\u00e9e"
  ],
  [
    " as of this writing, only english \nspecifications that involve no nested parameter \nreferences can be processed",
    "appliqu\u00e9e"
  ],
  [
    "4 specification by borrowing \nin addition to whatever mechanisms an nl \nsystem specifically provides for semantic acquisitions, \nit is reasonable to allow users to define one meaning \ndirectly in terms of another (in addition to indirect \ndependence, as in the case of english specification)",
    "appliqu\u00e9e"
  ],
  [
    " \neach system provides for a variety of customizations \nby non-natural language experts, though neither \nsystem has claimed success with actual users in either \ncustomization or english processing mode",
    "appliqu\u00e9e"
  ],
  [
    " \none important difference between teli  and \niracq is that irus distinguishes conceptual \ninformation, which resides within its kr framework, \nfrom the linguistic information that characterizes the \nenglish to be used",
    "appliqu\u00e9e"
  ],
  [
    " \nto begin with, ask provides quite general \ncustomization facilities, allowing english definitions at \nleast as sophisiticated as those outlined in section 7",
    "appliqu\u00e9e"
  ],
  [
    " \nthe constraint-propagation algorithm for generation \nhas been tested with previously constructed kimmo au- \ntomata for english, warlpiri, and turkish",
    "appliqu\u00e9e"
  ],
  [
    " \nall these aspects of runtime processing are apparent \nin traces of implemented kimmo recognition, for instance \nwhen the recognizer analyzes the english surface form \nsp ie l  (in 61 steps) according to karttunen and witten- \nburg's (1983) analysis (figure 1)",
    "appliqu\u00e9e"
  ],
  [
    " \nin english examples, misguided search subtrees are \nnecessarily shallow because the relevant spelling-change \nprocesses are local in character",
    "appliqu\u00e9e"
  ],
  [
    " \nlll+---+xxx+ \n-!-+xxx+ \nlll+---+---?xxx+ \ni ---?xlx+ \n- - -+---+xxx+ \ni \n- - -+-- -+lll+lll+**-? \ni ---+xxx+ \nkey to t ree nodes: \n- - -  normal t reversa l  \nlll new lexicon \naaa blocking by automata \nxxx no lexlcal-surface pai rs  \ncompatible with surface \nchar and dictionary \niii blocking by leftover input \n*'* analys is  found \n((\"spiel\" (n sg))) \nfigure \\]: these traces show the steps that the kimmorecognizer for english goes through while \nanalyzing the surface form sp ie l ",
    "appliqu\u00e9e"
  ],
  [
    " temporal and aspectual categories \nutterances of english sentences can, following vendler, be \nclassified into temporal/aspecmal types on the basis of the \ntenses, aspects and adverbials with which they can cooccur (cf",
    "appliqu\u00e9e"
  ],
  [
    "upped \npaul winked \nsue built a sandcastle \nthe ice melted completely \nmax worked in the garden \nalice played the piano \njohn knows french \nhe was in the kitchen \nhg~el  \nthe observation that each pr i~t ive ntity of a given type, such \nas the culmination-event of har~'s reaching the top, carries \nintimations of other associated events and states, such as the \nprocess by which the culmination was achieved, and the conse- \nquent state that followed",
    "appliqu\u00e9e"
  ],
  [
    " the adverbial/t took \nme two days then defines the temporal extent of this prepara- \ntory process needed to reach the point at which repeatedly \nplaying that piece of music so fast for such a considerable \nlength of time became a newly acquired skill \nthis basic framework thus allows for a unified semantics of a \nwide variety of aspectual dverbials, the progressive, the per- \nfect, and iterative xpressions in english",
    "appliqu\u00e9e"
  ],
  [
    " (1986) temporal anaphora in discourses of \nenglish",
    "appliqu\u00e9e"
  ],
  [
    "a compositional semantics of temporal expressions in \nenglish \nerhard w",
    "appliqu\u00e9e"
  ],
  [
    " tem- \nporal expressions of english are translated into this \nlanguage as quantifiers over times which bind tem- \nporal indices on predicates",
    "appliqu\u00e9e"
  ],
  [
    " reference time \nplays a crucial role in reichenbach's account of the \ndistinction betwen the simple past and the present \nperfect in english",
    "appliqu\u00e9e"
  ],
  [
    " the notions of focus (sidner 1983), of common \nground (stalnaker 1978) and of mutual knowledge \n(clark and marshall 1981) are certainly cases in point",
    "appliqu\u00e9e"
  ],
  [
    " \nsyntactically tenses in english appear as inflec- \ntional morphemes on verbs",
    "appliqu\u00e9e"
  ],
  [
    " the temporal logic is based on \nreichenbach's models for the semantics of english \ntense and uses multiple indices for semantic inter- \npretation",
    "appliqu\u00e9e"
  ],
  [
    " finally, i have demonstrated how the narrow \nscope of tense results in a fully compositional syntax \nand semantics of tensed sentences in english",
    "appliqu\u00e9e"
  ],
  [
    " shifters, verbal \ncategories and the russian verb",
    "appliqu\u00e9e"
  ],
  [
    " as a result of increased \ninternational communication, there exists today a \nmassive japanese effort in machine translation",
    "appliqu\u00e9e"
  ],
  [
    " \nan expectation-based approach to \"japanese-to- \nenglish machine translation is presented",
    "appliqu\u00e9e"
  ],
  [
    " \nciiaracteristics of tile japanese language \nthe difficulty of translation depends on the \nsimilarity between the languages involved",
    "appliqu\u00e9e"
  ],
  [
    " japanese \nand english are vastly different languages",
    "appliqu\u00e9e"
  ],
  [
    " translation \nfrom japanese to english involves restructuring of \nsentences, disambiguation of words, and additions and \n25 \ndeletions of certain lexical items",
    "appliqu\u00e9e"
  ],
  [
    " the following \ncharacteristics of the japanese language have \ninfluenced the design of the jetr system: \n1",
    "appliqu\u00e9e"
  ],
  [
    " japanese is a left-branching, post- \npositional, subject-object-verb language",
    "appliqu\u00e9e"
  ],
  [
    " particles and not word order are important \nin determining the roles of the noun \nphrases in a japanese sentence",
    "appliqu\u00e9e"
  ],
  [
    " information is usually more explicitly \nstated in english than in japanese",
    "appliqu\u00e9e"
  ],
  [
    " \nwhile analyzers of the english language rely \nheavily on verb-oriented processing, the existence of \nparticles in the japanese language and the subject- \nobject-verb word order have led to the pda's reliance \non forward expectations from words other than verbs",
    "appliqu\u00e9e"
  ],
  [
    " for example, the \ngenerator built by the electrotechnical laboratory of \njapan (ishizaki 1983), which produces japanese texts \nfrom the conceptual representation based on mops \n(schank 1982), generates a pronoun whenever the \nsame noun is seen the second time",
    "appliqu\u00e9e"
  ],
  [
    " the generator and not the pda calls the \ncontext analyzer to obtain missing information that \nare needed to translate grammatical japanese sentences \ninto grammatical english sentences",
    "appliqu\u00e9e"
  ],
  [
    " \nto achieve structural invariance, phrases are output \nas soon as possible without violating the english \nphrase order",
    "appliqu\u00e9e"
  ],
  [
    " in other words, the generator pretends \nthat incoming phrases are english phrases, and \nwhenever an ungrammatical phrase sequence is \ndetected, the new phrase is saved in one of three \nqueues: saved-prepositional, saved-refiner, \nand saved-object, as long as no violation of the \nenglish phrase order is detected or expected, the \nphrases are generated immediately",
    "appliqu\u00e9e"
  ],
  [
    " resolve pronoun references so that correct \nenglish pronouns can be generated and \nexpectations and object types can be \nassociated with pronouns",
    "appliqu\u00e9e"
  ],
  [
    " fill ellipses when necessary so that well- \nformed english sentences can be \ngenerated",
    "appliqu\u00e9e"
  ],
  [
    " instra \nwas designed with the goal of identifying the level of \nunderstanding required in translating instruction \nbooklets from japanese to english",
    "appliqu\u00e9e"
  ],
  [
    " generation of japanese sentences \nfrom conceptual representation",
    "appliqu\u00e9e"
  ],
  [
    " a heuristic approach to english-into- \njapanese machine translation",
    "appliqu\u00e9e"
  ],
  [
    " japanese \nlanguage semantic analyzer based on an \nextended case frame model",
    "appliqu\u00e9e"
  ],
  [
    " \nbetween valid english constructs and predicates of \nthe domain may be defined by entering sample \nphrases",
    "appliqu\u00e9e"
  ],
  [
    " irules define the mappings from english \nto these domain model predicates",
    "appliqu\u00e9e"
  ],
  [
    " \nfor example, knowing what relations are allowable \nbetween concepts in the domain, aids in determing \nwhat predicates can hold between concepts men- \ntioned in an english expression, and therefore, what \nare valid semantic mappings (irules, in our case)",
    "appliqu\u00e9e"
  ],
  [
    " work is also underway on an \nintelligent editing tool guaranteeing consistency with \nthe model when editing, and on an english \nparaphraser to express the content of a semantic rule",
    "appliqu\u00e9e"
  ],
  [
    "1 irules \nan irule defines, for a particular word or \n(semantic) class of words, the semantically accept- \nable english phrases that can occur having that word \nas head of the phrase, and in addition defines the \nsemantic interpretation of an accepted phrase",
    "appliqu\u00e9e"
  ],
  [
    " given an \nmrl expression for an input, the irus paraphraser \nfirst transforms it into a syntactic generation tree in \nwhich each mrl constituent is assigned a syntactic \nrole to play in an english paraphrase",
    "appliqu\u00e9e"
  ],
  [
    " \nin the second phase of the irus paraphraser, the \nsyntactic generation tree is transformed into an \nenglish sentence",
    "appliqu\u00e9e"
  ],
  [
    " this process uses an atn gram- \nmar and atn interpreter that describes how to com- \nbine the various syntactic slots in the generation tree \ninto an english sentence",
    "appliqu\u00e9e"
  ],
  [
    " \nfinally, the irus paraphraser expresses that mrl in \nenglish",
    "appliqu\u00e9e"
  ],
  [
    " \nproviding an english paraphrase from just the lin- \nguistic pattern of an irule would be simple and unin- \nteresting",
    "appliqu\u00e9e"
  ],
  [
    " the purpose of obtaining mrls for repre- \nsentative phrases and using the irus paraphraser to \ngo back to the english is to force the use of the right \nhand side of the irule which specifies the semantic \n37 \ninterpretation",
    "appliqu\u00e9e"
  ],
  [
    " a taxonomy for english nouns and \nverbs",
    "appliqu\u00e9e"
  ],
  [
    " the observed limited \nset of users' grammatical and ungrammatical forms \ndemonstrates the sufficiency of a very restricted grammar of \nenglish for a natural language interface to an advisory sys* \ntem",
    "appliqu\u00e9e"
  ],
  [
    " \nthis paper also presents an interpretation of the factors that \ncause users to naturally limit themselves to a very restricted \nsubset of english in typed communications between users and \ncomputerized advisers",
    "appliqu\u00e9e"
  ],
  [
    " hence, \nthe restricted subset of english should be general to any such \nsituations",
    "appliqu\u00e9e"
  ],
  [
    " the participants were instructed \nto ask help in english from what they believed was a com- \nputerized adviser by typing in the help window",
    "appliqu\u00e9e"
  ],
  [
    " and written textual dimensions \nin english",
    "appliqu\u00e9e"
  ],
  [
    " the attribute grammar is \ncurrently being used to write an english parser \nwhich embodies the principles of gb theory",
    "appliqu\u00e9e"
  ],
  [
    " the specification given here is for \nenglish",
    "appliqu\u00e9e"
  ],
  [
    " \nthe current version of the attribute grammar \nis presently being used to implement an english \nparser written in prolog",
    "appliqu\u00e9e"
  ],
  [
    " rizzi (1978) observed \nthat in italian the subjacency condition is systemat- \nically violated by double wh-extraction construc- \ntions, as in (4",
    "appliqu\u00e9e"
  ],
  [
    "a), if one assumes for italian the same \nset of bounding nodes as for english",
    "appliqu\u00e9e"
  ],
  [
    "b) is also possible in spanish",
    "appliqu\u00e9e"
  ],
  [
    " a \nsolution, considered by rizzi to explain the gram- \nmaticality of (4), is to assume that in italian and \nspanish, comp specifier position may be \"doubly \nfilled\" in the course of a transformational deriva- \ntion, while requiring that it be not doubly filled (by \nnon-empty phrases) at s-structure",
    "appliqu\u00e9e"
  ],
  [
    " \n(2) who~ did johny seem \\[ e, \\[ ej to love e,\\] \n(3) c(e,o) \nnp(m) comp1 (o,1) \nwho, comp s (~1) \ndid np(~=) infl i (2,1) \njohn2 infl vp (2'1) \ni \nv ~ (2,1) \nv c (2'1) \n{ \nseem np(~n comp~ (zn \ncomp s (zl) el \nl',i:, ('-,2) infl i \ni \ne2 \n(0,1) \ninfl vp (?'1) \ni i \nto v i (o,1) \nv np (6'1) \ni i \nlove el \n47 \na second solution, which is the one adopted \nby rizzi and constitutes the currently accepted \nexplanation of the (apparent) subiacency violation, \nis to assume that italian and spanish select c and \nnp as bounding nodes, a set different from that of \nenglish",
    "appliqu\u00e9e"
  ],
  [
    "b) to be also valid in italian",
    "appliqu\u00e9e"
  ],
  [
    " if we further assume that \nthe type of the attribute is universal, we may \nexplain the typological difference between italian \nand english, as it refers to the subjacency condi- \ntion, by assuming the presence of an a-chain \natack depth bound, which is parametrized by univer- \nsal grammar, and has the values 1 for english, and \n2 (or possibly more) for italian and spanish",
    "appliqu\u00e9e"
  ],
  [
    " \n48 \nparser  imp lementat ion  \na prototype of the english parser is currently being \ndeveloped using the prolog logic programming \nlanguage",
    "appliqu\u00e9e"
  ],
  [
    " syntactic analysis \nof english with respect to government- \nbinding grammar",
    "appliqu\u00e9e"
  ],
  [
    " \"violations of the wh-lsland \nconstraint in italian and the subjacency \ncondition",
    "appliqu\u00e9e"
  ],
  [
    " \"a government-binding parser \nfor french",
    "appliqu\u00e9e"
  ],
  [
    " \nnote that a morphological analyzer, wed-morph,  \nlinked to wednesday 2, plays a substantial role, \nspecially if the language is italian",
    "appliqu\u00e9e"
  ],
  [
    " in italian you may \nfind words like rifacendogliene, that  stands for while \nmaking some (of them) for him again",
    "appliqu\u00e9e"
  ],
  [
    " an example \nas an example let us consider the italian idiom prendere \n// toro per /e corn~ (literally: to take the bull by the \nhorns; idiomatically: to confront a difficult situation)",
    "appliqu\u00e9e"
  ],
  [
    " \nas mentioned, italian allows great flexibility",
    "appliqu\u00e9e"
  ],
  [
    " the \nperformance is very satisfying, in particular with \nregard to the flexibility present in italian",
    "appliqu\u00e9e"
  ],
  [
    " an english language question answering \nsystem for a large re la t iona l  database ",
    "appliqu\u00e9e"
  ],
  [
    " these additions pro- \nvide the phran-span system with the capability \nto translate digital system specifications input in \nenglish into correct representations for use by \nother programs",
    "appliqu\u00e9e"
  ],
  [
    " topics in the understanding of\nenglish sentences by computer",
    "appliqu\u00e9e"
  ],
  [
    " an integrated system of percep- \ntual strategies: syntactic and semantic interpreta- \ntion of english sentences",
    "appliqu\u00e9e"
  ],
  [
    " a lexical process model of nominal \ncompounding in english",
    "appliqu\u00e9e"
  ],
  [
    " a description of the warlpiri parsing system \nthe main reason for choosing warlpiri for our \ntest domain is that warlpiri provides a \nsufficient number of interesting morphological \nand phonological phenomena m such as \nvowel harmony and reduplication - -  without \nhaving an overabundance of phonological rules \n(unlike finnish which has roughly 20 rules in \nthe kimmo description)",
    "appliqu\u00e9e"
  ],
  [
    " we presume, \nhowever, that other phonetic facts may also \nhelp determine the prosody; see church (1983) \nfor a method for determining english prosodic \nconstituents from observable allophonic \nvariation",
    "appliqu\u00e9e"
  ],
  [
    " \nhowever, in our model, phonological rules are \ndefined for particular domains of application \nrather than continuously applying as in the \nk immo parser for finnish",
    "appliqu\u00e9e"
  ],
  [
    "adapting an english morphological analyzer for \nfrench \nroy j",
    "appliqu\u00e9e"
  ],
  [
    " watson research center \nyorktown lleights, new york 10598 \nabstract \na word-based morphological nalyzer and a dic- \ntionary for recognizing inflected forms of french \nwords have been built by adapting the udici\" \nsystem",
    "appliqu\u00e9e"
  ],
  [
    " we describe the adaptations, emphasiz- \ning mechanisms developed to handle french \nverbs",
    "appliqu\u00e9e"
  ],
  [
    " this work lays the groundwork for doing \nfrench derivational morphology and morphology \nfor other languages",
    "appliqu\u00e9e"
  ],
  [
    " its t'u-st \nversion was built for english and has been used \nin several systems needing a variety of informa- \ntion about english words (heidorn, et a1",
    "appliqu\u00e9e"
  ],
  [
    " \nthe english version of this analyzer has been de- \nscribed in byrd(1983) and byrd, et al (1986) and \nallows udict to recognize inflectionally and \nderivationally affixed words, compounds, and \ncollocations",
    "appliqu\u00e9e"
  ],
  [
    " the present paper describes an ef- \nfort to build a french version of udict",
    "appliqu\u00e9e"
  ],
  [
    " it \nbriefly discusses the creation of the dictionary \ndata itself and then focuses on issues ,raised in \nhandling french inflectional morphology",
    "appliqu\u00e9e"
  ],
  [
    " we have build a udict dictionary con- \ntaining such morphological information for \nfrench by starting with an existing spelling cor- \nrection and synonym aid dictionary ~and by add- \ning words and information from the \nfrench-english dictionary in collins(1978)",
    "appliqu\u00e9e"
  ],
  [
    " \nfrench udict contains a data base of over \n40,000 lemmata which are stored in a direct access \nfile managed by the dictionary access method \n(byrd, et al (1986))",
    "appliqu\u00e9e"
  ],
  [
    " the feature information relevant for \ninflectional analysis includes the following: \n(1) features : \npart -of-speech \ns ingu lar  \np lu ra l  \nmascullne \nfeminine \nwe are grateful to the advanced language development group of \nmaryland, for aocess to their french lexical materials",
    "appliqu\u00e9e"
  ],
  [
    " \nibm's application systems division in bethesda, \ninclude initial categorizations of french words into \ninvarlant \nfirst (second, third) person \ninfinitive \npartlclple \npast \npresent \nfuture \nimperfect \ns imple past \nsubjunctive \nindicative \ncondltlonal \nimperative \nsome of these features are explicitly stored in \nudict's data base",
    "appliqu\u00e9e"
  ],
  [
    " for french, no such information is \nstored now, but in other work (byrd, et al \n(1987)) we have demonstrated the feasibility of \ntransferring some additional exical information \n(for example, semantic features such as \n\\ [+human\\])  from english udict via bilingual \ndictionaries",
    "appliqu\u00e9e"
  ],
  [
    " \nwe estimate that the ratio of the number of \nfrench inflected forms to lemmata is around 5 (a \nlittle more for verbs, a little less for adjectives and \nnouns)",
    "appliqu\u00e9e"
  ],
  [
    " \nan example of an affix rule is the rule for forming \nfrench plural nouns shown in figure 1",
    "appliqu\u00e9e"
  ],
  [
    " (byrd(1983) describes further possible \ndistinctions which have so far not been exploited \nin the french system",
    "appliqu\u00e9e"
  ],
  [
    " \nwhile the assumption that affixes derive words \nfrom other words seems entirely appropriate for \nenglish, it at fast seemed less so for french",
    "appliqu\u00e9e"
  ],
  [
    " con- \nscqucntly, we have maintained the english model \nin which only words are stored in udict's dic- \ntionary",
    "appliqu\u00e9e"
  ],
  [
    " the following example shows two redun- \ndancy rules in the french word grammar: \n(3) : 0 (adj -masc -fem)(adj +masc) \n: e0 (adj +masc) (adj +fem) \nthe first rule has no boundary or affix name and \nits pattern does nothing to the input word",
    "appliqu\u00e9e"
  ],
  [
    " how-  \nevcr, rccursivc rule application plays a role in the \ndcrivation of feminine and plural forms of nouns, \nadjectives, and participles -- which will be dis- \ncussed under \"noun and adjective morphology\" \n- -  and in our method for handling stem \nmorphology of the french verbs belonging to the \nthird group, which will be discussed under \"verb \nmorphology\"",
    "appliqu\u00e9e"
  ],
  [
    " many french verbs be- \nlonging to the first group (i",
    "appliqu\u00e9e"
  ],
  [
    " \ntraditional french grammar books usually assign \neach verb anywhere from one to six stem forms",
    "appliqu\u00e9e"
  ],
  [
    " \n\"l~e french word grammar contains 165 verb \nstem rules and another 110 affix rules for third \ngroup verbs",
    "appliqu\u00e9e"
  ],
  [
    " summary and further work \na recoguizer for french inflected words has been \nbuilt using a modified version of udict, which \nis progranuned in pl/i and runs on ibm \nmainframe computers",
    "appliqu\u00e9e"
  ],
  [
    " approximately 400 affix \nand verb stem rules were required, of which over \nhalf are devoted to the analysis of french verbs \nbelonging to the third group",
    "appliqu\u00e9e"
  ],
  [
    " in \naddition to many minor changes not mentioned \nin this paper, the major effort in adapting the \nformerly english-only udict system to french \ninvolved handling stem morphology",
    "appliqu\u00e9e"
  ],
  [
    " french \nudict contains a dictionary of over 40,000 \nlemmata, providing fairly complete initial cover- \nage of most french texts, and forming a setting \nin which to add further, morphologically neutral, \nlexical information as required by various appli- \ncations",
    "appliqu\u00e9e"
  ],
  [
    " \nwe are testing french udict with a corpus of \ncanadian french containing well over 100,000 \nword types",
    "appliqu\u00e9e"
  ],
  [
    ") initial results how that the \nrecognizer successfully analyzes over 99% of the \nmost frequent 2,000 types in the corpus, after we \ndiscard those which are proper names or not \nfrench",
    "appliqu\u00e9e"
  ],
  [
    " in particular, \nwe believe that the spelling rule mechanism will \nhelp ha reeoguizing german umlauted forms and \nthat the stem mechanism will serve to handle \nhighly irregular paradigms in all of these lan- \nguages",
    "appliqu\u00e9e"
  ],
  [
    " \nwe also plan to expand our word ganunar to \nhandle the more productive parts of french deft",
    "appliqu\u00e9e"
  ],
  [
    " \ncolfins (1978) collins robert french dictionary: \nfrench-english",
    "appliqu\u00e9e"
  ],
  [
    " introduction \nin t \\ ]~  paper we discuss the syntactic, \nsemantic, and pragmatic analysis of fragmentary \nsentences in english",
    "appliqu\u00e9e"
  ],
  [
    " thus ?n appreciation of \nwhere such ellipses may occur is part of the \nl ingu, t/e knowledge of speakers of english and \nnot simply a function of the contextual salience \nof elided elements",
    "appliqu\u00e9e"
  ],
  [
    " one piece of supporting evidence for \nthis assumption is that  in many languages, such \nas japanese \\[gundel1980, l-nnds1983, \nkameyama1985\\] the functional equivalent of \nunstressed pronouns in english is a sere, or elided \nnoun phrase, s if seres in other languages can \ncorrespond to unstressed pronouns in english, \nthen we hypothesise that  seres in a sublunguage \nof english can correspond functionally to pro- \nnouns in standard english",
    "appliqu\u00e9e"
  ],
  [
    " thus the null verb \ninserted in the syntax is treated in the isr ill a \nfashion exactly parallel to the treatment of overt \nt stressed pronouns in eugiish corrupond to overt pro- \nnouns in lanzua,res like japanese",
    "appliqu\u00e9e"
  ],
  [
    " perhaps the fact that \nsublangusge mumn~j are characterised by rigid, contextualiy \nsupplied, topics contributes to the availability of the rye \nfragment type in english",
    "appliqu\u00e9e"
  ],
  [
    " such object elisioca occur more \nwidely in english in the context of instructions, as \nin handle _ udta sere",
    "appliqu\u00e9e"
  ],
  [
    " thus despite the greater \nfrequency of fragments we do not require either ?\ngr ?mm*r or ? preference structure different from \nthat of standard english in order to apply the \nstable system ~rammlr  to these telegraphic mes- \nsages",
    "appliqu\u00e9e"
  ],
  [
    " for example, fitspatrlck et al \n~itspatrick1986\\] propose that fragments are sub- \nject to ? constraint quite unlike any found in \nenglish generally",
    "appliqu\u00e9e"
  ],
  [
    " \nin snmm*ry, this supports the view that \nfragmentary constructions in english are regular, \ngramm~t|caliy constrained ellipses differing \nminimally from the standard language, rather \nthan ill-formed, unpredictable sublanguage exo- \ntlca",
    "appliqu\u00e9e"
  ],
  [
    " gundel, zero-np anaphora \nin russian",
    "appliqu\u00e9e"
  ],
  [
    " \n\\[hinds1983\\] \njohn hinds, topic continuity in \njapanese",
    "appliqu\u00e9e"
  ],
  [
    " most verbs of english have one or more ar- \ngument places that must be filled for the verb to be \nused in a syntactically/semantically felicitous way; this \nproperty of verbs is probably an important reason for \nthe persisting tendency to analyze them as n-place \npredicates rather than sets of situations",
    "appliqu\u00e9e"
  ],
  [
    " johnson acquired a rusty chevrolet\" \n/ \"frederick acquired a formidable speed\" \n\"a philosopher with a rusty chevrolet\" \n/ \",4 ship wi~ a formidable speed\" \nthe same set of terms is used in english for the \n26 \nownership relation, for the part-whole relation, and for \nthe relation between a function and its argument",
    "appliqu\u00e9e"
  ],
  [
    " \n\\[1\\] [10\\] in this approach, interpreting a natural lan- \nguage sentence is a multi-stage process, which starts \nout with a high-level meaning representation which \nreflects the semantic structure of the english sentence \nrather directly, and then applies translation rules \nwhich specify how the english-oriented semantic \nprimitives relate to the ones that are used at deeper \nlevels of analysis",
    "appliqu\u00e9e"
  ],
  [
    " \nenglish",
    "appliqu\u00e9e"
  ],
  [
    " \nthe most important case arises from the usa of \ndefinite descriptions in the english input sentence",
    "appliqu\u00e9e"
  ],
  [
    " \nthe proper treatment of quantification in or- \ndinary english",
    "appliqu\u00e9e"
  ],
  [
    " (i 1 3) a)) \n( )  p (+  3 (- 2 a))) \nwhen the measure noun appearing in an english \ninput differs from that by which the objects being \ntested are measured, as indicated by the second \nexample above, a scalar conversion is required",
    "appliqu\u00e9e"
  ],
  [
    "aft is the anglo- \nsaxon root (extant only on i:card ship) from which current \nenglish word derives",
    "appliqu\u00e9e"
  ],
  [
    "rathe\" is a middle english adverb meaning \"quickly'",
    "appliqu\u00e9e"
  ],
  [
    " syntax of the comparative clause construction i  \nenglish",
    "appliqu\u00e9e"
  ],
  [
    " computer interpretation f english text and picture \npatterns",
    "appliqu\u00e9e"
  ],
  [
    " natural language information processing: a \ncomputer grammar of english and its applications",
    "appliqu\u00e9e"
  ],
  [
    " the ideas \nhave all been imp lemented  \nwithin a large-scale grammar for \nswedish",
    "appliqu\u00e9e"
  ],
  [
    " \nalthough this move may in english \nseem syntactically quite unmotivated, \nthere are other languages where \nevidence can be found to support the \nclaim that these pronouns really exist",
    "appliqu\u00e9e"
  ],
  [
    " \nin russian,  where comparat ive \nconstructions very closely follow the \nenglish and swedish patterns, they can \noptionally appear in the surface \nstructure as the pronoun ~ 1\"0",
    "appliqu\u00e9e"
  ],
  [
    " in this connection we think \nthat the following data from swedish \nmay be of interest",
    "appliqu\u00e9e"
  ],
  [
    " \ncomparative constructions in swedish \nare v i r tua l ly  ident ical  to the \ncorresponding ones in english",
    "appliqu\u00e9e"
  ],
  [
    " \nm~n \nmen \nthere is, however, one exception to \nthe rule: \"vad\" may appear in the \"s- \n1 this is also possible in some dialects of english",
    "appliqu\u00e9e"
  ],
  [
    " the formation of \ncomparative clauses in french and english, \ngarland publishing inc",
    "appliqu\u00e9e"
  ],
  [
    " seafact allows the \nuser to specify cooking tasks \"using a small subset of \nenglish",
    "appliqu\u00e9e"
  ],
  [
    " the system analyzes english input and pro- \nduces a representation f the task which can drive \nmotion synthesis procedures",
    "appliqu\u00e9e"
  ],
  [
    " seafact allows the user to \nspecify tasks in this domain, using a small subset of \nenglish",
    "appliqu\u00e9e"
  ],
  [
    " the system then analyzes the english input \nand produces a representation of the task",
    "appliqu\u00e9e"
  ],
  [
    "the interpretat ion of tense and aspect in engl ish \nmary dalrymple \nartificial intelligence center \nsri international \n333 ravenswood avenue \nmenlo park, california 94025 usa \nabstract \nan analysis of english tense and aspect is pre- \nsented that specifies temporal precedence r lations \nwithin a sentence",
    "appliqu\u00e9e"
  ],
  [
    " \nwe provide an analysis of english tense and \naspect that involves specifying relations among \ntimes rather than events",
    "appliqu\u00e9e"
  ],
  [
    " t ime points  \nharper and charniak (1986) \\[henceforth h&c\\] \nprovide an interesting and revealing analysis of \nenglish tense and aspect involving relations be- \ntween events",
    "appliqu\u00e9e"
  ],
  [
    " finally, an analysis that utilizes under- \nspecified relations among times (not events) pro- \nvides a good prospect for analyzing tense and as- \npect in english",
    "appliqu\u00e9e"
  ],
  [
    " \n\"time and tense in english",
    "appliqu\u00e9e"
  ],
  [
    " \"a compositional \nsemantics of temporal expressions in english",
    "appliqu\u00e9e"
  ],
  [
    " \"choosing tense \nin english",
    "appliqu\u00e9e"
  ],
  [
    " incorporating both a graphical inter- \nface and a processor for english discourse, can- \ndide allows a user of the procedural reasoning \nsystem (pits) \\[10\\] to build and maintain proce- \ndural networks in a natural way",
    "appliqu\u00e9e"
  ],
  [
    " the proper treatment of quantifi- \ncation in ordinary english",
    "appliqu\u00e9e"
  ],
  [
    " from english \nto logic: context-free computation of 'conven- \ntional' logical translation",
    "appliqu\u00e9e"
  ],
  [
    " 2), and to describe the \nrelation between japanese and english structures ( ect",
    "appliqu\u00e9e"
  ],
  [
    " \nsemantic relations in the bilingual lexicon are \ncommon to english and japanese",
    "appliqu\u00e9e"
  ],
  [
    " \nin \nthis definition can be read: an agent-verb is-a \nverb which has-properties agent  for japanese and \nenglish",
    "appliqu\u00e9e"
  ],
  [
    "eive-a-favor polite interr \nfigure 2: example of a japanese sentence \nthe representation has already categorized to a \ncertain extent surface speech acts types",
    "appliqu\u00e9e"
  ],
  [
    " another possibility for a \nmono-directional system is to access the bilingual \nlexicon using the japanese ntry during parsing",
    "appliqu\u00e9e"
  ],
  [
    " here, the object te-1 (<~hand>>) is a part \nof the meaning of ~touch~ in this kind of construction, \nand the semantic relation that links the predicate and \nthe object being touched is a spatial destination in \njapanese (perceived as a goal or a target) and an object \nin english",
    "appliqu\u00e9e"
  ],
  [
    " \ntranslate \n\\[japanese: jasa \n\\[speech-act-type: #sat=re~t,  \nmanner: #mam~irect, \nspeaker: #j-m~j-speamm, \nh~&r :  # j -hz--q-heaber, \ns-act: #j-act~ \n\\[relation: ~3ate \nobject: \n\\[relaticn: ft~eru-i, \nobject: te-1, \nspatial-dest/naticn: hcn-1\\] \\] \\] \nstep 1 : rewrite translate which adds to the \ninput structure the english 2a~aarld new prop symbols \nin the translate",
    "appliqu\u00e9e"
  ],
  [
    " \n\\[ japanese: jasa \n\\[speech-act-type: #sat~equest, \nmanner: #man=direct, \nspeaker: # j-sp-j-speak~ \nhearer: # j -~-hearer~ \ns-act: # j-act~j-prfp \n\\[relation: negate \nabject: \n\\[relatiqn: ~ l - i ,  \nobject: te-1, \nspatial-dest/nation: hon-1\\] \\] \\] \nenglish :easa \n\\[speech-act-type: #sat, \nmanner: #man, \n~er :  ~ ,  \nhearer: #e-hearer, \ns-act: #e-act-eprop\\], \nt rans-act: p ~x)p \n\\[ japanese: #j-act, \nengl/sh: #e-act\\], ",
    "appliqu\u00e9e"
  ],
  [
    " it adds a new prop symbol \nwhich is in turn rewritten and this time the unification \nwith ~ succeeds: it adds the english object and a \nnew translate slot for 1~0i?",
    "appliqu\u00e9e"
  ],
  [
    " \n\\[japanese: jasa \n\\[speech-act-type: #sat~b~st,  \nmanner: #man-dibect, \nspeaker: # j -sp-j-speaker~ \nb~arer: # j-hr=j-hearer, \ns-act: #j-act-~7-prcp \n\\[ relation: # j-neg--j-neg \nobject: #-objl \n\\[relation: fure~j-1, \ncb~ct: #j-obj2--te-l, \nspatial-destination: #sd=hc~-i \\] \\] \nenglish :easa \n\\[speech-act-type: #sat~t,  \nmanner: #man=direct, \nspeaker: #j-sp=e-spea~l \nhearer: # j -hr--e-heaber, \ns-act: #e-act--ev \n\\[relation: #e-neg=e-neg, \nobject: #e-cbj= \n\\[relation: touch-i, \nobject: #e-obj2\\] \\], \ntrans-act :",
    "appliqu\u00e9e"
  ],
  [
    " the \nfinal structul'e produced by the interpreter is: \n\\[ japanese: jasa \n\\[ speech-act -type: #sat=reqjest, \nmanner: #marmoirect, \n~aker :  j -s~a~ \nhearer : j~  \ns-act: j-prop \n\\[relatic~: j-neg \nobject: \n\\[ relation: fureru-i, \nobject :te-1, \nspatial-destination:fen-l\\] \\], \nenglish :easa \n\\[ speech-act -type: #sat, \nn~nner: #man, \nspeaker:e-speaker, \nhearer :e-heare~ \ns-act: e-pbop \n\\[relation: e-neg, \nobject: \n\\[relation: tcxx~-i, \nobject :book-i\\] \\], \n",
    "appliqu\u00e9e"
  ],
  [
    " we hope this feature \nwill be useful in the future development of the \ngrammar, allowing for a precise constrastive analysis \nof japanese and english",
    "appliqu\u00e9e"
  ],
  [
    " \njapanese sentence analysis by means of phrase \nstructure grammar",
    "appliqu\u00e9e"
  ],
  [
    " \nin analyses of dutch cross-serial verb construc- \ntions (evers, 1975; huybrechts, 1984), subcate- \ngorization lists such as these may be appended by \nsyntactic rules (moortgat, 1984; steedman, 1985; \npollard, 1988), resulting in indefinitely long lists",
    "appliqu\u00e9e"
  ],
  [
    " \nconsider the dutch sentence \ndat \\[jan \\[marie \\[de oppasser \\[de olifanten \nthat john mary the keeper the elephants \n\\[zag helpen voeren\\]\\]\\]\\] \nsaw help feed \nthat john saw mary help the keeper feed the \nelephants \nthe string of verbs is analysed by appending their \nsubcategorization lists as follows: \nv \\[e,k,md\\] \nv \\[mj\\] v \\[e,k,m\\] \nzag \nsato \nv \\[k,m\\] v \\[e,k\\] \ni i \nhelpen voeren \nhelp feed \nsubcategorization lists under this analysis can \nhave any length, and it is impossible to predict \nfrom a semantic structure the size of its corre- \nsponding subcategorization list mereiy by exam- \nining the lexicon",
    "appliqu\u00e9e"
  ],
  [
    " the transformational cycle \nin german and dutch",
    "appliqu\u00e9e"
  ],
  [
    " dependency and coordi- \nnation in the grammar of dutch and english",
    "appliqu\u00e9e"
  ],
  [
    " \nkeywords :  logical form, natural anguage, semantics \nabstract \nthis paper describes a 'logical form' target \nlanguage for representing the literal mean- \ning of english sentences, and an interme- \ndiate level of representation ('quasi logical \nform') which engenders a natural separation \nbetween the compositional semantics and the \nprocesses of scoping and reference resolution",
    "appliqu\u00e9e"
  ],
  [
    " \nthe approach as been implemented in the \nsri core language engine which handles the \nenglish constructions discussed in the paper",
    "appliqu\u00e9e"
  ],
  [
    " \nintroduction \nthe sri core language engine (cle) is \na domain independent system for translat- \ning english sentences into formal represen- \ntations of their literal meanings which are \ncapable of supporting reasoning (alshawi et \nal",
    "appliqu\u00e9e"
  ],
  [
    " the representation \nlanguages we propose are powerful enough \nto give weu-motiwted translations of a wide \nrange of english sentences",
    "appliqu\u00e9e"
  ],
  [
    " in the current \nversion of the cle this is used to provide a \nsystematic and coherent coverage of all the \nmajor phrase types of english",
    "appliqu\u00e9e"
  ],
  [
    " \nwe will first motivate our extensions to \nfirst order logic and our distinction between \nlf and qlf, then describe the lf language, \nillustrating the logical form translations pro- \nduced by the cle for a number of english \nconstructions, and finally present he addi- \ntional constructs of the qlf language and \nillustrate their use",
    "appliqu\u00e9e"
  ],
  [
    " \nthe ways in which first order logic-- \npredicate logic in which the quantifiers 3 and \nv range over the domain of individuals--is ex- \ntended in our treatment can be grouped and \nmotivated as follows: \n? extensions motivated by lack of ex- \npressive power of ordinary first order \nlogic: for a general treatment of noun \nphrase constructions in english general- \nized quantifiers are needed ('most a are \nb' is not expressible in a first order lan- \nguage with just the two one-place pred- \nicates a and b)",
    "appliqu\u00e9e"
  ],
  [
    " \n? extensions motivated by the desire \n26 \nfor an elegant compositional semantic \nframework: \nuse of lambda abstraction for the \ntranslation of graded predicates in \nour treatment of comparatives and \nsuperlatives; \nuse of tense operators and inten- \nsional operators for dealing with \nthe english tense and au~liary sys- \ntem in a compositional way",
    "appliqu\u00e9e"
  ],
  [
    " some advan- \ntages of an operator treatment of the english \ntense system are discussed in (moore, 1981)",
    "appliqu\u00e9e"
  ],
  [
    " \nwe are aware of the fact that some as- \npects of our lf representation give what are \narguably overly neutral analyses of english \nconstructions",
    "appliqu\u00e9e"
  ],
  [
    " for example, the qlf gener- \nated for the definite description in every dog \nburied the bone that it found is: \nqterm(ref (def ,  the,  sing, ix\\]), sing, y, \nbone(y) a past (quant(ex ls ts ,  e, ev(e), \nfind(e, a_term(ref(pro,  it, sing, \\[y,z\\]), \nw, zmv rsonal(w)), y))))",
    "appliqu\u00e9e"
  ],
  [
    " the separation of the two seman- \ntic representation levels has been an impor- \ntant guiding principle in the implementation \nof a system covering a substantial fragment \nof english semantics in a well-motivated way",
    "appliqu\u00e9e"
  ],
  [
    " \"from \nenglish to logic: context-free compu- \ntation of 'conventional' logical trans- \nlations\"",
    "appliqu\u00e9e"
  ],
  [
    " box 517, paoli, pa 19301, usa \nabstract \ni examine how discourse anaphoric uses of the \ndefinite pronoun it contrast with similar uses of \nthe demonstrative pronoun thai",
    "appliqu\u00e9e"
  ],
  [
    " english has a relatively \nimpoverished set of definite pronouns in which \ngender is relevant only in the 3rd person singu- \nlar, and where number---a fairly universal nominal \ncategory--is not relevant in the 2nd person",
    "appliqu\u00e9e"
  ],
  [
    " yet \neven within the english pronominal system, there \nis a semantic ontrast hat provides language users \nwith alternative means for accessing the same pre- \nviously mentioned entities, therefore providing in- \nvestigators of language with an opportunity to ex- \nplore how distinct lexicogrammatical features cor- \nrelate with distinct attentional processes",
    "appliqu\u00e9e"
  ],
  [
    " \n4 d iscuss ion  \nthe outcome of this study is not a model of at- \ntentionai processes per #e, but rather, a set of fac- \ntors pertaining to attentional structure that elu- \ncidates the shifting functions of the demonstra- \ntive pronoun in english discourse",
    "appliqu\u00e9e"
  ],
  [
    " computing japanese discourse: \ngrammatical disambiguation with centering con- \nstralnts",
    "appliqu\u00e9e"
  ],
  [
    " towards a computational theory \nof definite anaphora comprehension i english \ndiscourse",
    "appliqu\u00e9e"
  ],
  [
    " up to now, \nlexicographers have been reliant either on citations \ncollected by human readers, which introduced an \nelement of selectivity and so inevitably distortion \n(rare words and uses were collected but common \nuses of common words were not), or on small \ncorpora of only a million words or so, which are \nreliably informative for only the most common uses \nof the few most frequent words of english",
    "appliqu\u00e9e"
  ],
  [
    " \nalthough this technology is a great improvement on \nusing human readers to collect boxes of citation \nindex cards (the method murray used in \nconstructing the oxford english dictionary a \ncentury ago), it works well if there are no more \nthan a few dozen concordance lines for a word, and \nonly two or three main sense divisions",
    "appliqu\u00e9e"
  ],
  [
    " intuitively, however, many of the \npatterns discovered seem to be good candidates for \nconventions of general english",
    "appliqu\u00e9e"
  ],
  [
    ") an entirely unconstrained combina- \ntory grammar would in fact allow any bracketing on \na sentence, although the grammars we actually write \nfor configurational l nguages like english are heavily \nconstrained by local conditions",
    "appliqu\u00e9e"
  ],
  [
    " \nthe claim of the present paper is simply that par- \nticular surface structures that are induced by the spe- \ncific combinatory grammar that are postulated to ex- \nplain coordination in english subsume the intona- \ntional structures that are postulated by pierrehumbert \net al to explain the possible intonation contours for \nsentences of english",
    "appliqu\u00e9e"
  ],
  [
    " more specifically, the claim is \nthat that in spoken utterance, intonation helps to de- \ntermine which of the many possible bracketings per- \nmitted by the combinatory syntax of english is in- \ntended, and that the interpretations of the constituents \nthat arise from these derivations, far from being \"spu- \nrious\", are related to distinctions of discourse focus \namong the concepts and open propositions that the \nspeaker has in mind",
    "appliqu\u00e9e"
  ],
  [
    " \nreferences \n\\[1\\] beckman, mary and janet pierrehumbert: 1986, \n'intonational structure in japanese and english', \nphonology yearbook, 3, 255-310",
    "appliqu\u00e9e"
  ],
  [
    " \n\\[10\\] pierrehumbert, janet: 1980, the phonology and \nphonetics of english intonation, ph",
    "appliqu\u00e9e"
  ],
  [
    ") \n\\[11\\] pierrehumbert, janet, and mary beckman: 1989, \njapanese tone structure, mit press, cambridge \nma",
    "appliqu\u00e9e"
  ],
  [
    " dependency and co- \nordination in the grammar of dutch and en- \nglish, language 61",
    "appliqu\u00e9e"
  ],
  [
    " in \na question-and-answer system, these messages would \nbe replaced by generated english answers",
    "appliqu\u00e9e"
  ],
  [
    " the proper treatment \nof quantification in ordinary english",
    "appliqu\u00e9e"
  ],
  [
    " a comprehensive gram- \nmar of the english language",
    "appliqu\u00e9e"
  ],
  [
    " \n25 \ntions from our data: 1) an extraction from a japanese \ndialogue in the conference registration domain, and \n2) an extraction from a spanish dialogue in the travel \nagency domain",
    "appliqu\u00e9e"
  ],
  [
    " although this shared stack mechanism ac- \ncounts for highly task-oriented and cooperative dia- \nlogues where one can assume that both speakers share \n3dialogue 1is extracted from a corpus of japanese atr \n(advanced telecommunication research) recorded simu- \nlated conference r gistration telephone conversations",
    "appliqu\u00e9e"
  ],
  [
    " dialogue 2 is extracted from a corpus of recorded \nspanish dialogues in the travel agency domain, collected by \nthe second author of this paper",
    "appliqu\u00e9e"
  ],
  [
    " \nwe are implementing this model using the span- \nish travel agency domain corpus and the japanese \natr conference r gistration corpus",
    "appliqu\u00e9e"
  ],
  [
    " john fought, linguistics \ndepartment, university of pennsylvania, for his help \nin collecting the spanish travel agency domain corpus, \nand mr",
    "appliqu\u00e9e"
  ],
  [
    " akira kurematsu for pro- \nviding us with their japanese atr conference r gistra- \ntion domain corpus",
    "appliqu\u00e9e"
  ],
  [
    " english \nhas a relatively impoverished inventory of pronouns \nin comparison to the bantu language chich~wa, \nwhich has two sets of definite pronouns, one of \nwhich is morphologically incorporated into the verb \nstem, and the other of which consists of indepen- \nnp antecedent it that \ngiven 78 17 \nnot given 31 71 \nprobability \" \\] , ",
    "appliqu\u00e9e"
  ],
  [
    " x7 this is reminiscent of the \npragmatic ontrast in english between it and that \nin focus-marking constructions, as illustrated in 2a- \nb) below",
    "appliqu\u00e9e"
  ],
  [
    " the ear- \nlier papers how that, provided type raising is limited \nto the two \"order preserving\" varieties exemplified in \nthese examples, the above reduction is the only one \npermitted by the lexicon of english",
    "appliqu\u00e9e"
  ],
  [
    "  < e  \nvl'\\(~/lw) \na dog a bone  \n~\\(~lw) \n,ip \nlip lip \n",
    "appliqu\u00e9e"
  ],
  [
    " this is a desir- \nable result: the example (16) and the earlier papers \nshow that the non-order-preserving stances (b, d) \nare required for the grammar of english and dutch",
    "appliqu\u00e9e"
  ],
  [
    " \nin configurational languages like english they must \nof course be carefully restricted as to the categories \nthat may unify with y",
    "appliqu\u00e9e"
  ],
  [
    " \nthe related proposal of zeevat et al \\[8\\],\\[9\\] also \nhas the property of allowing a single lexical raised \ncategory for the english np",
    "appliqu\u00e9e"
  ],
  [
    " zeevat's \ntype-raised categories are actually order-changing, \nand require the lexical category for the english pred- \nicate to be s/np  instead of s\\np ",
    "appliqu\u00e9e"
  ],
  [
    " (such categories immediately induce totally \nfree word-order, for example permitting (31) on the \nenglish lexicon)",
    "appliqu\u00e9e"
  ],
  [
    " while a few english \nlexical categories and an english sentence are given \nby way of illustration, the very general combinatory \nrules that are included will of course require further \nconstraints if they are not to overgenerate with larger \nfragments",
    "appliqu\u00e9e"
  ],
  [
    " (for example, >b and >bx must be dis- \nanguished as outlined above, and file latter must be \ngreatly constrained for english",
    "appliqu\u00e9e"
  ],
  [
    " \nuser :  \nsystem: \nuser: \nsystem: \nuser :  \nsystem: \nuser :  \nsystem: \nsearch for a lisp programmer who \nspeaks french \n#%holm, #%ebihara, #%jones, #%baker",
    "appliqu\u00e9e"
  ],
  [
    " \nfollowup one who speaks japanese \n#%ebihara \nfollowup her creator \n#%holm \ninspect it \n#%holm displayed in?~olnspector3 \nhere, output utterances are not true generated english \nbut rather canned text string templates whose blanks \nare filled in with pointers to kb units",
    "appliqu\u00e9e"
  ],
  [
    " a unified analysis of the \nenglish bare plural",
    "appliqu\u00e9e"
  ],
  [
    " \nluperfoy, susann (1989) the semantics of plural \nindefinite anaphors in english",
    "appliqu\u00e9e"
  ],
  [
    " \nthe first problem we encountered was the missing \nblank line between the second and third paragraphs in\nthe french (figure lb)",
    "appliqu\u00e9e"
  ],
  [
    ",\" and its french equivalent, \n\"prtittons - drprt de documents",
    "appliqu\u00e9e"
  ],
  [
    " \nfigure la: an example of ocred english \n4",
    "appliqu\u00e9e"
  ],
  [
    " \n2 \nfigure lb: an example of ocred french \n4",
    "appliqu\u00e9e"
  ],
  [
    " figure 2 plotsf(x) as a function of x, \nwhere x is a byte position in the english text andf(x) \nis the corresponding byte position in the french text, \nas determined by char_align",
    "appliqu\u00e9e"
  ],
  [
    " this is especially true for historically \nrelated language pairs such as english and french, \nwhich share quite a number of cognates, e",
    "appliqu\u00e9e"
  ],
  [
    " we have \nfound that it can even work on some texts in english \nand japanese such as the awk manual, because many \nof the technical terms (e",
    "appliqu\u00e9e"
  ],
  [
    ", english and russian versions of 5ess? \ntelephone switch manuals, formatted in troff)",
    "appliqu\u00e9e"
  ],
  [
    " figure 8 shows a dotplot of 3 \nyears of canadian hansards (37 million words) in \nenglish and french, tokenized by words",
    "appliqu\u00e9e"
  ],
  [
    " figure 9 \nshows a dotplot of a short article (25 kbytes) that \nappeared in a christian science magazine in both \nenglish and german, tokenized into 4-grams of \ncharacters",
    "appliqu\u00e9e"
  ],
  [
    ", for all e and fp we have an estimate for \np(fp\\]e), the probability that the english sentence \ne translates to the french passage fp",
    "appliqu\u00e9e"
  ],
  [
    " then, we \ncan assign a probability to the english corpus e \ntranslating to the french corpus :t with a partic- \nular alignment",
    "appliqu\u00e9e"
  ],
  [
    "42\\]?) = p(ele1)p(f~, f2, f3ie2) \nthis value should be fairly low, since the align- \nment does not map the english sentences to their \ntranslations",
    "appliqu\u00e9e"
  ],
  [
    " \nhowever, because the parameters are all of the \nform p(fple ) where e is a sentence, the above \nframework is not amenable to the situation where \na french sentence corresponds to no english sen- \ntences",
    "appliqu\u00e9e"
  ],
  [
    " \nunder this paradigm, instead of expressing the \ntranslation model as a conditional distribution \n10 \nenglish (?) \nel that is what the consumers \nare interested in and that \nis what the party is \ninterested in",
    "appliqu\u00e9e"
  ],
  [
    " \nfrench (~) \n/'i voil~ ce qui int6resse le \nconsommateur et rol l& ce \nque int6resse notre parti",
    "appliqu\u00e9e"
  ],
  [
    " in this section, \nwe only consider the generation of sentence beads \ncontaining a single english sentence e = el \" \"en  \nand single french sentence f = f l \" \" fm",
    "appliqu\u00e9e"
  ],
  [
    " we take \nn \np(\\[e; f\\]) = p(n)p(m) h p(ei) f i  p(fj) \ni=l j= l  \nwhere p(n) is the probability that an english sen- \ntence is n words long, p(m) is the probability that \na french sentence is m words long, p(ei) is the fre- \nquency of the word ei in english, and p(fj) is the \nfrequency of the word fj in french",
    "appliqu\u00e9e"
  ],
  [
    " \nto capture the dependence between individual \nenglish words and individual french words, we \ngenerate english and french words in pairs in \naddition to singly",
    "appliqu\u00e9e"
  ],
  [
    " a word bead is \neither a single english word, a single french word, \nor a single english word and a single french word",
    "appliqu\u00e9e"
  ],
  [
    " instead of generating a pair of sen- \ntences word by word, we generate sentences bead \nby bead, using the h l  word beads to capture the \ndependence between english and french words",
    "appliqu\u00e9e"
  ],
  [
    " ,  bl} is a multiset of word beads, \np(l) is the probabil ity that an english sentence \nand a french sentence contain l word beads, and \np(bi) denotes the frequency of the word bead bi",
    "appliqu\u00e9e"
  ],
  [
    " \nthis simple model captures lexical dependencies \nbetween english and french sentences",
    "appliqu\u00e9e"
  ],
  [
    " we take \nl p(t) \"b\" p(b) = -  i i  p\\[  i) n, z \nwhile a beading b describes an unordered mul- \ntiset of english and french words, sentences are \nin actuality ordered sequences of words",
    "appliqu\u00e9e"
  ],
  [
    " recall that n is the length of the english sen- \ntence and m is the length of the french sentence",
    "appliqu\u00e9e"
  ],
  [
    " for simplicity, \nwe only consider sentence beads consisting of one \nenglish sentence, one french sentence, one en- \nglish sentence and one french sentence, two en- \nglish sentences and one french sentence, and one \nenglish sentence and two french sentences",
    "appliqu\u00e9e"
  ],
  [
    " we have aligned a cor- \npus of 3,000,000 sentences (of both english and \nfrench) of the canadian hansards, a corpus of \n1,000,000 sentences of newer hansard proceedings, \nand a corpus of 2,000,000 sentences of proceed- \nings from the european economic community",
    "appliqu\u00e9e"
  ],
  [
    " \nthe rate of alignment ranged from 2,000 to \n5,000 sentences of both english and french per \nhour on an ibm rs/6000 530h workstation",
    "appliqu\u00e9e"
  ],
  [
    " \\scm{} \nlanguage = french \\ecm{} \nf2 \\scm{} paragraph \\ecm{} \nfigure 3: an alignment error \nmotion no",
    "appliqu\u00e9e"
  ],
  [
    " \n(dagan et al, 1991) ido dagan, alon itai, and u1- \nrike schwall",
    "appliqu\u00e9e"
  ],
  [
    "com \n94304 \nabst rac t  \nthe paper describes an algorithm that employs \nenglish and french text taggers to associate noun \nphrases in an aligned bilingual corpus",
    "appliqu\u00e9e"
  ],
  [
    " \nthe work described here makes use of the \naligned canadian hansards \\[gale and church, \n1991b\\] to obtain noun phrase correspondences be-\ntween the english and french text",
    "appliqu\u00e9e"
  ],
  [
    " consider an english sentence ei and a \nfrench sentence fi which are assumed to be ap- \nproximate translations of each other",
    "appliqu\u00e9e"
  ],
  [
    " english collocations are first \nextracted from the english side of the corpus",
    "appliqu\u00e9e"
  ],
  [
    " in- \nstances of the english collocation are found and \nthe mutual information is calculated between the \ninstances and various single word candidates in \naligned french sentences",
    "appliqu\u00e9e"
  ],
  [
    " the highest ranking \ncandidates are then extended by another word and \nthe procedure is repeated until a corresponding \nfrench collocation having the highest mutual in- \nformation is found",
    "appliqu\u00e9e"
  ],
  [
    " \nso far it has been assumed (for the sake of sim- \nplicity) that there is always a one-to-one mapping \nbetween english and french sentences",
    "appliqu\u00e9e"
  ],
  [
    " let there be l total alignments \nin the corpus; then ei is the english sentence for \nalignment i",
    "appliqu\u00e9e"
  ],
  [
    " considering the j ' th  \nnoun phrase in sentence ei, the function i~(ei, j) \nproduces an identifier for the phrase, which is the \nposition of the phrase in the english index",
    "appliqu\u00e9e"
  ],
  [
    " \nin turn, the french sentence fi will contain \n?(fi) noun phrases and given the p'th one, its po- \nsition in the french index will be given by/~(fi, p)",
    "appliqu\u00e9e"
  ],
  [
    " \nit will also be assumed that there are a total of \nve and vr phrases in the english and french in- \ndexes respectively",
    "appliqu\u00e9e"
  ],
  [
    " \nassuming these definitions, the algorithm is \ni english sentence e i \n1 \ni english tagger i \ni english np recognizer i\ni  n0",
    "appliqu\u00e9e"
  ],
  [
    "sh'o ex i \ni bilingual corpus i rth alignment \ni french ftntence i \nfrench tagger i \ni french i np recognizer \ni frenchlndex i \nfigure 1: component layout \nstated in figure 2",
    "appliqu\u00e9e"
  ],
  [
    " the equations assume a direc- \ntionality: finding french \"target\" correspondences \nfor english \"source\" phrases",
    "appliqu\u00e9e"
  ],
  [
    " the argument s refers to the english noun \nphrase nps(s) having position s in the english \nindex, and the argument  refers to the french \nnoun phrase npf(t) at position t in the french \nindex",
    "appliqu\u00e9e"
  ],
  [
    " equation (1) assumes that each english \nnoun phrase in ei is initially equally likely to cor- \nrespond to each french noun phrase in fi",
    "appliqu\u00e9e"
  ],
  [
    " 4,900 \ndistinct english noun phrases and 5,100 distinct \nfrench noun phrases were extracted from the sam- \nple",
    "appliqu\u00e9e"
  ],
  [
    " \n32 atlantic canada \nopportunities \nagency \n5 dree \n1 late spring \n1 whole issue \nof free trade \n23 agence de promotion \n6conomique du \ncanada atlantique \n4 meer \n1 fin du printemps \n1 question \ndu libre-~change \ntable 2: other correspondences \nthe table also illustrates an unembedded en- \nglish noun phrase having multiple prepositional \n19 \nphrases in its french correspondent",
    "appliqu\u00e9e"
  ],
  [
    "\" \nthe first problem is that the conjunctive modifiers \nin the english sentence cannot be accommodated \nby the noun phrase recognizer",
    "appliqu\u00e9e"
  ],
  [
    " if verb correspondences \nwere included, there is a mismatch between the \nthree that exist in the english sentence and the \nsingle one in the french",
    "appliqu\u00e9e"
  ],
  [
    " if the english were to \nreflect the french for the correspondence model \nto be appropriate, the noun phrases would per- \nhaps be \"part in the factory\" and \"part out of \nthe factory\"",
    "appliqu\u00e9e"
  ],
  [
    "\" \nin the case of the alliterative english phrase \"roar- \ning rabbit\", the (presumably) rhetorical aspect is \npreserved as a rhyme in \"souris qui rugit\"; the re- \nsult being that \"rabbit\" corresponds to \"souris\" \n(mouse)",
    "appliqu\u00e9e"
  ],
  [
    " the problem of prepositional \nphrase attachment is exemplified by the following \ncorresp on den ces: \n16 secretary 20 secrdtaire d' etat \nof state \n16 secretary 19 affaires extdrieures \nof state \n16 external affairs 19 affaires extdrieures \n16 external affairs 20 secrdtaire d' etat \ntable 5 \nthe correct english and french noun phrases \nare \"secretary of state for external affairs\" and \n\"secr~taire d' etat aux affaires ext~rieures\"",
    "appliqu\u00e9e"
  ],
  [
    " consider a sequence \nnp~ppe of an unembedded english noun phrase \nnpe followed by a prepositional phrase ppe, and \nlikewise a corresponding french sequence nplpp i",
    "appliqu\u00e9e"
  ],
  [
    " jp \nabst rac t  \nthis paper describes a method for finding struc- \nrural matching between parallel sentences of two \nlanguages, (such as japanese and english)",
    "appliqu\u00e9e"
  ],
  [
    " \nspecif icat ion of \nstructural matching \nproblem \nalthough the structural matching method shown \nin this paper is language independent, we deal with \nparallel texts of japanese a",
    "appliqu\u00e9e"
  ],
  [
    "nd english",
    "appliqu\u00e9e"
  ],
  [
    "panese and english sentences are parsed \nindependently into (disjuuctive)feature structures",
    "appliqu\u00e9e"
  ],
  [
    " \nwe are currently using lfg-like grammars for \nboth japanese and english, where the value of the \n'pred' label in an f-structure is the content word \nthat is the head of the corresponding c-structure",
    "appliqu\u00e9e"
  ],
  [
    " \ndef in i t ion  7 a semi-complete ds of a ds ? is a \nsubstruclure of a complete ds o f?  thai satisfies \nthe condition in definilion ~",
    "appliqu\u00e9e"
  ],
  [
    " \nparsing parallel english and japanese sentences \nresults in feature structures, from which depen- \ndency structures are derived by removing unrelated \nfeatures",
    "appliqu\u00e9e"
  ],
  [
    "'e and 'oj are dependency struc- \ntures of english and japanese sentences",
    "appliqu\u00e9e"
  ],
  [
    " then, f \nis a flmction over semi-complete dss derived fi'om \nenglish and japanese parallel sentences into a real \nnumber, and 9 is a function over feature label sets \n3in the case of similarity between dependency relations, \nthe original feature labels are taken into accotult",
    "appliqu\u00e9e"
  ],
  [
    " \n26 \nof english and japanese into a real number",
    "appliqu\u00e9e"
  ],
  [
    " \"vve assume some similarity measure be- \ntween japanese and english words",
    "appliqu\u00e9e"
  ],
  [
    " the reason is that we \nfound it difficult to have a clear view on the re- \nlationship between feature labels of english and \njapanese and on the meaning of feature labels be- \ntween semi-complete dependency structures",
    "appliqu\u00e9e"
  ],
  [
    "  \ns imi la r i ty  o f  word  pa i rs  \ngiven a pair of japanese and english sentences, \nwe take two methods to lneasure the similarity be- \ntween japanese and english content words appear- \ning in the sentences",
    "appliqu\u00e9e"
  ],
  [
    " \nfor each japanese content word wj apl)earing in \nthe japanese sentence, we can find a set of translat- \nable english words fl'om the japanese-ellglish die- \ntionary",
    "appliqu\u00e9e"
  ],
  [
    " when the japanese word is a",
    "appliqu\u00e9e"
  ],
  [
    " polysemous \nword, we select an english word fi'om each polyse- \nmous entry",
    "appliqu\u00e9e"
  ],
  [
    " let ce\\] be the set of such translat- \nable english words of wj",
    "appliqu\u00e9e"
  ],
  [
    " suppose ce is the set of \ncontents words in the english sentence",
    "appliqu\u00e9e"
  ],
  [
    "llocated at the \nleaves of the tree: for each japanese content word \n'wj appearing in tim japanese sentence, we can de- \nfine the set of translatable english words of wa, \ncej ",
    "appliqu\u00e9e"
  ],
  [
    "  from each english word in the set",
    "appliqu\u00e9e"
  ],
  [
    ", the mini- \nmum distance to each of the english content words \nappearing in the english sentence is measured",
    "appliqu\u00e9e"
  ],
  [
    " 5 \nthis minimum distance defines the similarity be- \ntween pairs of japanese and english words",
    "appliqu\u00e9e"
  ],
  [
    " \nwe decided to use this similarity only for esti- \nmating dissimilarity between japanese and english \nword pairs",
    "appliqu\u00e9e"
  ],
  [
    " \nnow, we define the similarity fimction f over \njapaaese and english semi-colnplete dss to give \nthe naa",
    "appliqu\u00e9e"
  ],
  [
    " \n28 \ntable 1: results of experiment, s \nparsing j al)anese and english sent",
    "appliqu\u00e9e"
  ],
  [
    "2% (6/59) \nthe match with tile best score includes \ncorrect matching 47 89% (47/53) \nno correct naatching 6 11% (6/53) \nsingle correct matching 34 64% (34/53) \nresu l ts  o f  the exper iments  \nwe used 82 pairs of japanese and english sen- \ntences appearing in a japanese-english dictionary",
    "appliqu\u00e9e"
  ],
  [
    " enhancement of english and japanese gram- \nmars for wider coverage and lower error rate",
    "appliqu\u00e9e"
  ],
  [
    " since english and japanese are grammatically \nquite different, some grammatical rela",
    "appliqu\u00e9e"
  ],
  [
    " \nsince the interpretations of the sample english sen- \ntences are in different mood, imperative and declar- \native, the mood of a",
    "appliqu\u00e9e"
  ],
  [
    " \nto extract useful information fl'om bilingual cor- \npora, structural matching is inevitable for language \npairs like english and japanese that have quite dif- \nferent linguistic structure",
    "appliqu\u00e9e"
  ],
  [
    " incidentally, we have \nfound that this dissimilarity plays an important \nrole in resolving syntactic ambiguities ince the \nsources of anlbiguities in english and japanese sen- \ntences are in many cases do not coincide (utsuro \n92)",
    "appliqu\u00e9e"
  ],
  [
    " we are currently working on extracting verbal \ncase frames of japanese fi'om the results of struc- \ntural matching of a aal)anese-l~nglish corpus (ut- \nsuro 93)",
    "appliqu\u00e9e"
  ],
  [
    "pplica- \nble to acquire verbal case fi'ames of english as well",
    "appliqu\u00e9e"
  ],
  [
    " \noverview of the appl icat ion \nthe boeing simplified english checker (a",
    "appliqu\u00e9e"
  ],
  [
    " that is, it re- \nports to users on where a text fails to comply with \nthe aerospace standard for maintenance documen- \ntation known as simplified english (aecma \n1989)",
    "appliqu\u00e9e"
  ],
  [
    " 2 the accu- \nracy of the error critiques over that 90 percent \nvaries, but our subjective xperience suggests that \nmost sentence reports contain critiques that are \nuseful in that they flag some bona fide failure to \ncomply with simplified english",
    "appliqu\u00e9e"
  ],
  [
    " as a con- \ntrolled sublanguage, simplified english requires \n2",
    "appliqu\u00e9e"
  ],
  [
    " the simplified english (se) standard allows \nsome exceptions tothe 'single part of speech' rule \nin its core vocabulary of about a thousand words",
    "appliqu\u00e9e"
  ],
  [
    " \n39 \noverview of simplified \nenglish \nthe se standard consists of a set of grammar, \nstyle, format, and vocabulary restrictions, not all \nof which lend themselves tocomputational analy- \nsis",
    "appliqu\u00e9e"
  ],
  [
    " \nthe overall function of such a program is to pres- \nent the writer with an independent check on a fair \nrange of simplified english requirements",
    "appliqu\u00e9e"
  ],
  [
    " for \nfurther details on simplified english and the \nbsec, see hoard et al (1992) and wojcik et al \n(1990)",
    "appliqu\u00e9e"
  ],
  [
    " \nalthough the bsec detects a wide variety of \nsimplified english and general writing violations, \nonly the error categories in table 1 are relevant to \nthis study: except for illegal comma usage, which \nis rather uncommon, the above errors are among \nthe most frequent types of errors detected by the \nbsec",
    "appliqu\u00e9e"
  ],
  [
    " \nto date, the boeing company is the only aero- \nspace manufacturer to produce aprogram that de- \ntects such a wide range of simplified english \nviolations",
    "appliqu\u00e9e"
  ],
  [
    " the bsec is the only \nsimplified english checker in existence that man- \nages to avoid this",
    "appliqu\u00e9e"
  ],
  [
    " oracle's recently released coauthor product, \nwhich is designed to be used with the interleaf \nword processor, has the potential to produce gram- \nmatical analyses of sentences, but it only works as \na simplified english word checker at present",
    "appliqu\u00e9e"
  ],
  [
    " so \nword-checking programs, while inexpensive and \neasy to produce, do not address the needs of sim- \nplified english writers",
    "appliqu\u00e9e"
  ],
  [
    " \nin the simplified english domain, it is more likely \nthat (2) will be an example of passive usage, thus \ncalling for an error report",
    "appliqu\u00e9e"
  ],
  [
    " not all of \nthe documents were intended to be in simplified \nenglish when they were originally written",
    "appliqu\u00e9e"
  ],
  [
    " the modified bracketed report contained \nonly 'actual' simplified english errors",
    "appliqu\u00e9e"
  ],
  [
    " from cogram to alco- \ngram: toward a controlled english gram- \nmar checker",
    "appliqu\u00e9e"
  ],
  [
    " aecma \nsimplified english",
    "appliqu\u00e9e"
  ],
  [
    " a procedure for quantitative- \nly comparing the syntactic coverage of \nenglish grammars",
    "appliqu\u00e9e"
  ],
  [
    " evaluating syntax performance of \nparser/grammars of english",
    "appliqu\u00e9e"
  ],
  [
    " an automated grammar and style \nchecker for writers of simplified english",
    "appliqu\u00e9e"
  ],
  [
    " peg: the plnlp english \ngrammar",
    "appliqu\u00e9e"
  ],
  [
    " \nthe boeing simplified english checker",
    "appliqu\u00e9e"
  ],
  [
    " the utterances were \nlabeled at bell laboratories for word boundaries and \nintonational prominences and phrasing following pier- \nrehumbert's description of english intonation (pierre- \nhumbert, 1980)",
    "appliqu\u00e9e"
  ],
  [
    " a computational \ngrammar of discourse-neutral prosodic phrasing in \nenglish",
    "appliqu\u00e9e"
  ],
  [
    " the phonology and \nphonetics of english intonation",
    "appliqu\u00e9e"
  ],
  [
    " although this paper describes \nthe lexicon, grammar, and semantics of english, \ngemini has also been used in a japanese spo- \nken language understanding system (kameyama, \n1992)",
    "appliqu\u00e9e"
  ],
  [
    " grammar  formal i sm \ngemini ncludes a midsized constituent gram- \nmar of english (described in section 2",
    "appliqu\u00e9e"
  ],
  [
    " \"the syntax and seman- \ntics of the japanese language engine\", forth- \ncoming",
    "appliqu\u00e9e"
  ],
  [
    " \njapanese syntactic processing, hillsdale, nj: \nlawrence erlbaum associates",
    "appliqu\u00e9e"
  ],
  [
    "a hybrid reasoning model for indirect answers \nnancy  green  \ndepartment  of computer  science \nuniversity of delaware \nnewark, de 19716, usa \ninternet: green@udel",
    "appliqu\u00e9e"
  ],
  [
    "edu \nsandra carberry \ndepartment of computer  science \nuniversity of delaware \nvisitor: inst",
    "appliqu\u00e9e"
  ],
  [
    " \naccording to one study of spoken english \n\\[stenstrhm, 1984\\], 13 percent of responses to yes- \nno questions were indirect answers",
    "appliqu\u00e9e"
  ],
  [
    " \nthis paper provides a computational model \nfor the interpretation and generation of indirect \nanswers to yes-no questions in english",
    "appliqu\u00e9e"
  ],
  [
    " \nthe model employs an agent's pragmatic \nknowledge of how language typically is used to \nanswer yes-no questions in english to constrain \nthe process of generating and interpreting indirect \nanswers",
    "appliqu\u00e9e"
  ],
  [
    " cohesion in english",
    "appliqu\u00e9e"
  ],
  [
    " in braj b",
    "appliqu\u00e9e"
  ],
  [
    " ques- \ntions and responses in english conversation",
    "appliqu\u00e9e"
  ],
  [
    " in \nclaes schaar and jan svartvik, editors, lund \nstudies in english 68",
    "appliqu\u00e9e"
  ],
  [
    "a stochastic finite-state word-segmentation algorithm \nfor chinese \nrichard sproat \nchilin shih \nwilliam gale \nat&t bell laboratories \n600 mountain avenue, \nroom {2d-451,2d-453,2c-278} \nmurray hill, nj, usa, 07974-0636 \n{rws, cls, gale}@research, att",
    "appliqu\u00e9e"
  ],
  [
    " com \nnancy chang \nharvard university \ndivision of applied sciences \nharvard university \ncambridge, ma 02138 \nnchang@das, harvard, edu \nabstract \nwe present astochastic finite-state model for segment- \ning chinese text into dictionary entries and produc- \ntively derived words, and providing pronunciations for \nthese words; the method incorporates a class-based \nmodel in its treatment of personal names",
    "appliqu\u00e9e"
  ],
  [
    " however, for chinese and \nother systems where whitespace is not used to delimit \nwords, such trivial schemes will not work",
    "appliqu\u00e9e"
  ],
  [
    " chinese \nwriting is morphosyllabic (defrancis, 1984), meaning \nthat each hanzi- 'chinese character' - (nearly always) \nrepresents a single syllable that is (usually) also a sin- \ngle morpheme",
    "appliqu\u00e9e"
  ],
  [
    " \nwhile for some applications it may be possible \nto bypass the word-segmentation problem and work \nstraight from hanzi, there are several reasons why this \napproach will not work in a text-to-speech (ti's) sys- \ntem for mandarin chinese - -  the primary intended \napplication of our segmenter",
    "appliqu\u00e9e"
  ],
  [
    " \nwe present astochastic finite-state model for seg- \nmenting chinese text into dictionary entries and words \nderived via the above-mentioned productive processes; \nas part of the treatment of personal names, we dis- \ncuss a class-based model which uses the good-turing \nmethod to estimate costs of previously unseen personal \nnames",
    "appliqu\u00e9e"
  ],
  [
    " we evaluate various specific aspects of the seg- \nmentation, and provide an evaluation of the overall \nsegmentation performance: this latter evaluation com- \npares the performance ofthe system with that of several \nhuman judges, since even people do not agree on a sin- \ngle correct way to segment a text, \nprevious work \nthere is a sizable literature on chinese word segmenta- \ntion: recent reviews include (wang et al, 1990; wu and \ntseng, 1993)",
    "appliqu\u00e9e"
  ],
  [
    " \ngiven this dictionary representation, recognizing a \nsingle chinese word involves representing the input as \na finite-state acceptor (fsa) where each arc is labeled \nwith a single hanzi of the input",
    "appliqu\u00e9e"
  ],
  [
    "0 \n(repubilc of chr, a) \nfigure 1: partial chinese lexicon (nc= noun; np = proper noun) \ni \nessay fish \ni~ :_nc ~ :wen2 \\]~- :zhangl i~ :_nc ,,~,",
    "appliqu\u00e9e"
  ],
  [
    "28 i e : nc : japanese octopus , - how say \ni \\[\\] :ri4 ~ :wen2 g :_nc -~-:zhangl ,~! ",
    "appliqu\u00e9e"
  ],
  [
    " \nchinese personal names \nfull chinese personal names are in one respect sim- \nple: they are always of the form family+given",
    "appliqu\u00e9e"
  ],
  [
    " \nevaluation of the segmentation as a whole: pre- \nvious reports on chinese segmentation have invariably \n4the current model is too simplistic in several respects",
    "appliqu\u00e9e"
  ],
  [
    " \nconclusions \nin this paper we have shown that good performance \ncan be achieved on chinese word segmentation byus- \ning probabilistic methods incorporated into a uniform \nstochastic finite-state model",
    "appliqu\u00e9e"
  ],
  [
    " we believe that the ap- \nproach reported here compares favorably with other \nreported approaches, though obviously it is impossible \nto make meaningful comparisons in the absence of uni- \nform test databases for chinese segmentation",
    "appliqu\u00e9e"
  ],
  [
    " as \nwe have observed there is often no single right answer \nto word segmentation in chinese",
    "appliqu\u00e9e"
  ],
  [
    " \nacknowledgements \nwe thank united informatics for providing us with \nour corpus of chinese text, and bdc for the 'behav- \n5we were recently pointed to (wang et al, 1992), which \nwe had unfortunately missed in our previous literature search",
    "appliqu\u00e9e"
  ],
  [
    " large-corpus- \nbased methods for chinese personal name recogni- \ntion",
    "appliqu\u00e9e"
  ],
  [
    " journal of chinese information processing, \n6(3):7-15",
    "appliqu\u00e9e"
  ],
  [
    " word \nidentification for mandarin chinese sentences",
    "appliqu\u00e9e"
  ],
  [
    " a \ncomparison of the enhanced good-turing and \ndeleted estimation methods for estimating prob- \nabilities of english bigrams",
    "appliqu\u00e9e"
  ],
  [
    " the chinese language",
    "appliqu\u00e9e"
  ],
  [
    " automatic word \nidentification i chinese sentences by the relax- \nation technique",
    "appliqu\u00e9e"
  ],
  [
    " computer processing of chinese \nand oriental languages, 4:33-56",
    "appliqu\u00e9e"
  ],
  [
    " \na preliminary study on unknown word problem \nin chinese word segmentation",
    "appliqu\u00e9e"
  ],
  [
    " the prosodic domain of tone \nsandhi in chinese",
    "appliqu\u00e9e"
  ],
  [
    " a statistical \nmethod for finding word boundaries in chinese \ntext",
    "appliqu\u00e9e"
  ],
  [
    " computer p ocessing of chinese and orien- \ntal languages, 4:336-35 i",
    "appliqu\u00e9e"
  ],
  [
    " a \nfinite-state morphological processor for spanish",
    "appliqu\u00e9e"
  ],
  [
    " au- \ntomatic processing of chinese words",
    "appliqu\u00e9e"
  ],
  [
    " journal of \nchinese information processing, 4(4): 1-11",
    "appliqu\u00e9e"
  ],
  [
    " chinese text \nsegmentation for text retrieval: achievements and \nproblems",
    "appliqu\u00e9e"
  ],
  [
    "t's in the limit, large dictionaries \nof actual english pronunciations did not give \nenough samples to correctly induce phonolog- \nical rules",
    "appliqu\u00e9e"
  ],
  [
    " an \nimplementation f the algorithm successfully \nlearns a number of english postlexical rules",
    "appliqu\u00e9e"
  ],
  [
    " \nthe subsequential transducer for the english flapping \nrule in 1 is shown in figure 1; an underlying t is realized \nas a flap after a stressed vowel and any number of r's, and \nbefore an unstressed vowel",
    "appliqu\u00e9e"
  ],
  [
    "  \n# : t  \nfigure 1: subsequential transducer for english flap- \nping: labels on arcs are of the form (input sym- \nbol):(output symbol)",
    "appliqu\u00e9e"
  ],
  [
    " consider again the \nenglish flapping rule, which applies in the context of a \npreceding stressed vowel",
    "appliqu\u00e9e"
  ],
  [
    " each pair consisted of \nan underlying and a surface pronunciation of an individ- \nual word of english",
    "appliqu\u00e9e"
  ],
  [
    " handling of various semitic er- \nror problems is illustrated, with reference \nto arabic and syriac examples",
    "appliqu\u00e9e"
  ],
  [
    " for example, syriac (md/nt~)'city' is \npronounced/mdit~/",
    "appliqu\u00e9e"
  ],
  [
    " \n3 e r ror  check ing  in  arab ic  \nwe demonstrate our model on the arabic verbal \nstems shown in (4) (mccarthy, 1981)",
    "appliqu\u00e9e"
  ],
  [
    " in proceedings \nof the second cambridge conference: bilingual \ncomputing in arabic and english",
    "appliqu\u00e9e"
  ],
  [
    " mil \nabst ract  \nin this paper we will present our ongoing \nwork on a plan-based iscourse processor \ndeveloped in the context of the enthusiast \nspanish to english translation system as \npart of the janus multi-lingual speech-to- \nspeech translation system",
    "appliqu\u00e9e"
  ],
  [
    " \n1 in t roduct ion  \nin this paper we will present our ongoing work on a \nplan-based iscourse processor developed in the con- \ntext of the enthusiast spanish to english translation \nsystem (suhm et al 1994) as part of the janus \nmulti-lingual speech-to-speech translation system",
    "appliqu\u00e9e"
  ],
  [
    " \na strength of our discourse processor is that \nbecause it was designed to take a language- \nindependent meaning representation (interlingua) as \nits input, it runs without modification on either en- \nglish or spanish input",
    "appliqu\u00e9e"
  ],
  [
    " development of our dis- \ncourse processor was based on a corpus of 20 spon- \ntaneous spanish scheduling dialogues containing a \ntotal of 630 sentences",
    "appliqu\u00e9e"
  ],
  [
    " although development and \ninitial testing of the discourse processor was done \nwith spanish dialogues, the theoretical work on the \nmodel as well as the evaluation presented in this pa- \nper was done with spontaneous english dialogues",
    "appliqu\u00e9e"
  ],
  [
    " \ndevelopment of our discourse processor was based \non a corpus of 20 spontaneous spanish scheduling di- \nalogues containing a total of 630 sentences",
    "appliqu\u00e9e"
  ],
  [
    " \n4 eva luat ion  \nthe evaluation was conducted on a corpus of 8 pre- \nviously unseen spontaneous english dialogues con- \ntaining a total of 223 sentences",
    "appliqu\u00e9e"
  ],
  [
    " 93-19, department of \ncomputer and information sciences, university of \ndelaware",
    "appliqu\u00e9e"
  ],
  [
    "2 resu l ts  \nwe have implemented this method on an english-to- \njapanese machine translation system called shalt2 \n(takeda et al, 1992), and conducted experiments \nto evaluate the effectiveness of this method",
    "appliqu\u00e9e"
  ],
  [
    " the translations were compared by check- \ning how well the output japanese sentence conveyed \nthe meaning of the input english sentence",
    "appliqu\u00e9e"
  ],
  [
    " peg: the plnlp english gram- \nmar",
    "appliqu\u00e9e"
  ],
  [
    " i also define the two swedish verbs skickade \n(sent) and skickades (was sent) to illustrate how this \nrule works",
    "appliqu\u00e9e"
  ],
  [
    " \nacknowledgments  \nthis work has been supported by the swedish re- \nsearch council for engineering sciences (tfr)",
    "appliqu\u00e9e"
  ],
  [
    " \nconsider the german examples in (5), cited by \npullum and zwicky (1986) and ingria (1990)",
    "appliqu\u00e9e"
  ],
  [
    ", \nin the english example above it was crucial that ma- \njor category labels were decomposed into the fea- \ntures noun and verb)",
    "appliqu\u00e9e"
  ],
  [
    " similarly, we decompose the \nfour nominal cases in german into the 'subcase' fea- \ntures obj (abbreviating 'objective') and dir (for 'di- \nrect') as follows",
    "appliqu\u00e9e"
  ],
  [
    " \nin fact, they seem to be necessary to obtain a \nlinguistically correct description of coordination i  \ngerman",
    "appliqu\u00e9e"
  ],
  [
    " \nfor example, bouma and van noord (1994) show \nthat assuming that heads ubcategorize for adjuncts \n(rather than the other way around, as is standard) \npermits a particularly elegant account of the double \ninfinitive construction i dutch",
    "appliqu\u00e9e"
  ],
  [
    ", a boolean expression of keywords) or, \nmore desirably, anatural anguage, such as english",
    "appliqu\u00e9e"
  ],
  [
    " the stress and \nstructure of modified noun phrases in english",
    "appliqu\u00e9e"
  ],
  [
    " since corpora with over 40 million \nwords are common and english has over 40 com- \nmon derivational affixes, one would expect o be able \nto increase this number by an order of magnitude",
    "appliqu\u00e9e"
  ],
  [
    " \nin addition, most english words are either derived \nthemselves or serve as bases of at least one deriva- \ntional affix",
    "appliqu\u00e9e"
  ],
  [
    " tagging english text with \na probabilistic model",
    "appliqu\u00e9e"
  ],
  [
    " computa- \ntional morphology: practical mechanisms for the \nenglish lexicon",
    "appliqu\u00e9e"
  ],
  [
    " the analy- \nsis is based on a set of lrs implemented \nand tested on the basis of spanish and \nenglish business- and finance-related cor- \npora",
    "appliqu\u00e9e"
  ],
  [
    " the \nfindings reported here have been implemented and \ntested on the basis of spanish and english business- \nand finance-related corpora",
    "appliqu\u00e9e"
  ],
  [
    " section 4 briefly \nreviews the cost factors associated with lrs; the \nargument in it is based on another case study, the \nadjective-related lrs, which is especialy instructive \nsince it may mislead one into thinking thai",
    "appliqu\u00e9e"
  ],
  [
    " such lrs \nautomatically produce word forms which are poly- \nsemous, such as the spanish generador 'generator,' \neither the artifact or someone who generates",
    "appliqu\u00e9e"
  ],
  [
    " the \nlrs have been tested in a real world application, in- \nvolving the semi-automatic a quisition of a spanish \ncomputational lexicon of about 35,000 word senses",
    "appliqu\u00e9e"
  ],
  [
    " this mecha- \nnism works because we rely on linguistic clues and \na see (viegas and nirenburg, 1995) for the details on \nthe acquisition process to build the core spanish lexicon, \nand (viegas and beale, 1996) for the details oil the con- \nceptual and technological tools used to check the quality \nof the lexicon",
    "appliqu\u00e9e"
  ],
  [
    "  ~ fo rme \ni ii i:ii i  ii i iiiiii!iiiiiiiiiiiiiiiiiijjii !i iii iiiii \naccepted  fo rms \nre jec ted  fo rms \n\"comprar-v1 \ncat: \ndfn: \nex:  \naamin: \nsyn: \nsere :  \nv \nacqu i re  the  possess ion  or  r ight  \nby  pay ing  or  p romis ing  to  pay  \nt roche  eompro  una  nueva  empress  \nj l ongwel  \"18 /1  15 :42 :44\"  \n\"root: \\[\\] \nrcat \n0 bj: ~ \\[sem: \n\"buy  \nagent: fi-i\\] human \ntheme: \\[~\\] object \nfigure 2: partial entry for the spanish lexieal item \ncomprar",
    "appliqu\u00e9e"
  ],
  [
    " for instance, the morpho-semantic rule lrpo- \nlarity_negative is at least attached to all verbs belong- \ning to the -aa class of spanish verbs, whose initial \nstem is of the form 'con', 'tra', or 'fir' with the corre- \nsponding allomorph ",
    "appliqu\u00e9e"
  ],
  [
    " \n35 \n\"compra-n1 \ncat: \ndfn: \nex: \nadmin: \nsyn: \nsere: \nlex-rul: \nv \nacquire  the  possess ion  or  r ight  \nby pay ing or p romis ing  to pay \nlr2event  \"11 /12  20:33:02\" \\[ oo, \nbuy\\] \ncomprar -v l  \"lr2event\"  \nfigure 3: partial entry for the spanish lexical item \ncompra generated automatically",
    "appliqu\u00e9e"
  ],
  [
    " in the process of spanish acquisi- \ntion, 20% of all entries were created from scratch by \nh-level lexicographers and 80% were generated by \nlrs and checked by research associates",
    "appliqu\u00e9e"
  ],
  [
    "' around \n300 english adjectives out of the 6,000 or so, which \noccur in the intersection of ldoce and the 1987-89 \nwall street journal corpora, end in -able",
    "appliqu\u00e9e"
  ],
  [
    " \nbeth levin 1992 towards a le~cical organization \nof english verbs chicago: university of chicago \npress",
    "appliqu\u00e9e"
  ],
  [
    " \n2 task  description \nthe input to a wsd program consists of unre- \nstricted, real-world english sentences",
    "appliqu\u00e9e"
  ],
  [
    " making such an assumption is reason- \nable since pos taggers that can achieve accuracy \nof 96% are readily available to assign pos to un- \nrestricted english sentences (brill, 1992; cutting et \nal",
    "appliqu\u00e9e"
  ],
  [
    " note that the sense definitions used in this \ndata set are those from longman dictionary of con- \ntemporary english (ldoce) (procter, 1978)",
    "appliqu\u00e9e"
  ],
  [
    " \nthese 192,800 word occurrences consist of 121 \nnouns and 70 verbs which are the most frequently oc- \ncurring and most ambiguous words of english",
    "appliqu\u00e9e"
  ],
  [
    " this set of 121 nouns accounts for about \n20% of all occurrences of nouns that one expects to \nencounter in any unrestricted english text",
    "appliqu\u00e9e"
  ],
  [
    " in proceedings of the 30th \nannual meeting of the association for computa- \ntional linguistics, newark, delaware",
    "appliqu\u00e9e"
  ],
  [
    "  com- \nputer recognition of english word senses",
    "appliqu\u00e9e"
  ],
  [
    " decision lists for lexical am- \nbiguity resolution: application to accent restora- \ntion in spanish and french",
    "appliqu\u00e9e"
  ],
  [
    " we present an \nevaluation of the system using time-to-completion \nand the quality of the final solution that suggests \nthat most native speakers of english can use the \nsystem successfully with virtually no training",
    "appliqu\u00e9e"
  ],
  [
    " the same system \nhas been effectively applied both to english and \nfrench, although this paper focuses on french (see \n(jacquemin, 1994) for the case of syntactic variants \nin english)",
    "appliqu\u00e9e"
  ],
  [
    "3 million words of the \nfrench newspaper \"le monde\"; \\[agr\\] is a set of \nabstracts of scientific papers in the agricultural do- \nmain from inist/cnrs (1",
    "appliqu\u00e9e"
  ],
  [
    " infle- \nctional morphology is implemented with finite-state \ntransducers on the model used for spanish (tzouker- \nmann and liberman, 1990)",
    "appliqu\u00e9e"
  ],
  [
    " \nthe system consists of precomputing stems, extrac- \nted from a large dictionary of french (boyer, 1993) \nenhanced with newspaper corpora, a total of over \n85,000 entries",
    "appliqu\u00e9e"
  ],
  [
    " \na d=5-word window is considered as sufficient for \ndetecting collocations in english (martin, a1, and \nvan sterkenburg, 1983)",
    "appliqu\u00e9e"
  ],
  [
    " we chose a window-size \ntwice as large because french is a romance language \nwith longer syntactic structures due to the absence \nof compounding, and because we want to be sure \nto observe structures panning over large textual se- \nquences",
    "appliqu\u00e9e"
  ],
  [
    " \nwe have devised a grammar of french to serve as a \nbasis for the creation of metarules for term variants",
    "appliqu\u00e9e"
  ],
  [
    " a finite-state morphological processor for \nspanish",
    "appliqu\u00e9e"
  ],
  [
    " combining linguistic \nknowledge and statistical learning in french part- \nof-speech tagging",
    "appliqu\u00e9e"
  ],
  [
    "combining unsupervised lexical knowledge methods for word \nsense disambiguation * \ngerman rigau, jordi atserias eneko agirre \ndept ",
    "appliqu\u00e9e"
  ],
  [
    " in fo rmat ikoak  sai la  \nun ivers i ta t  po l i t~cnica de cata lunya  euska l  herr iko  un iber ts i ta tea  \nbarce lona ,  cata lon ia  donost ia ,  basque  count ry  \n{g",
    "appliqu\u00e9e"
  ],
  [
    " the set of techniques have been \napplied in a combined way to disambiguate \nthe genus terms of two machine-readable \ndictionaries (mrd), enabling us to con- \nstruct complete taxonomies for spanish \nand french",
    "appliqu\u00e9e"
  ],
  [
    " \n1 introduction \nwhile in english the \"lexical bottleneck\" problem \n(briscoe, 1991) seems to be softened (e",
    "appliqu\u00e9e"
  ],
  [
    " \nalthough a large set of dictionaries have been ex- \nploited as lexicm resources, the most widely used \nmonolingual mrd for nlp is ldoce which was \ndesigned for learners of english",
    "appliqu\u00e9e"
  ],
  [
    " does it mean \nthat only highly structured ictionaries like ldoce \nare suitable to be exploited to provide lexical re- \nsources for nlp systems? \nwe explored this question probing two disparate \ndictionaries: diccionario general ilustrado de la \nlengua espa~ola (dgile, 1987) for spanish, and \nle plus petit larousse (lppl, 1980) for french",
    "appliqu\u00e9e"
  ],
  [
    " due to the morphological productivity \nof spanish and french, we have considered iffer- \nent variants of this heuristic",
    "appliqu\u00e9e"
  ],
  [
    " in order to apply conceptual distance, \nwordnet was chosen as the hierarchical knowledge \nbase, and bilingual dictionaries were used to link \nspanish and french words to the english concepts",
    "appliqu\u00e9e"
  ],
  [
    " in order to do this, the gap between our \nworking languages and english was filled with two \nbilingual dictionaries",
    "appliqu\u00e9e"
  ],
  [
    " for this purpose, we derived \na list of links for each word in spanish and french \nas follows",
    "appliqu\u00e9e"
  ],
  [
    " \nfirstly, each spanish or french word was looked \nup in the bilingual dictionary, and its english trans- \nlation was found",
    "appliqu\u00e9e"
  ],
  [
    " the pair made of the original word and \neach of the concepts linked to it, was included in a \nfile, thus producing a mtd with links between span- \nish or french words and wordnet concepts",
    "appliqu\u00e9e"
  ],
  [
    " \n7 acknowledgments  \nthis work would not be possible without the col- \nlaboration of our colleagues, pecially jose mari ar- \nriola, xabier artola, arantza diaz de ilarraza, kepa \nsarasola nd aitor soroa in the basque country and \nhoracio rodr~guez in catalonia",
    "appliqu\u00e9e"
  ],
  [
    " \nreferences \nalicia ageno, irene castellsn, maria antonia \nmarti, francesc ribas, german rigau, horacio \nrodriguez, mariona taul@ and felisa verdejo",
    "appliqu\u00e9e"
  ],
  [
    " \neneko agirre and german rigau",
    "appliqu\u00e9e"
  ],
  [
    " a taxonomy for english \nnouns and verbs",
    "appliqu\u00e9e"
  ],
  [
    " thesis, euskal herriko unibertsi- \ntatea, donostia, basque country",
    "appliqu\u00e9e"
  ],
  [
    " longman dictionary of contempo- \nrary english",
    "appliqu\u00e9e"
  ],
  [
    "a quasi-dependency model for structural analysis \nof chinese basenps* \nzhao jun huang changning \ndepartment ofcomputer science & technology, \nthe state key lab of intelligent technology & systems, \ntsinghua university, beijing, china, 100084 \nemail: zj@sl000e",
    "appliqu\u00e9e"
  ],
  [
    "cn \nabstract: the paper puts forward a quasi- \ndependency model for structural analysis of chinese \nbasenps and a mdl-based algorithm for quasi- \ndependency-strength acquisition",
    "appliqu\u00e9e"
  ],
  [
    " the experiments \nshow that the proposed model is more suitable for \nchinese basenp analysis and the proposed mdl- \nbased algorithm is superior to the traditional ml- \nbased algorithm",
    "appliqu\u00e9e"
  ],
  [
    " b~t the definition can not meet the \nneeds in chinese information retrieval",
    "appliqu\u00e9e"
  ],
  [
    " the \nusing the paper defines the chinese basenp \nrestrictive attributes",
    "appliqu\u00e9e"
  ],
  [
    " \n\\[ definition 1 \\] chinese basenp (hereafter \nabbreviated asbasenp)- \nbasenp -- basenp + basenp \nbasenp --- basenp + n i vn \nbasenp -- restrictive-attribute + basenp \nbasenp --- restrictive-attribute + n i vn \nrestrictive-attribute --- a i b i v in \\] s i x i \n(m+q) \nwhere, the terminal symbols a, b, v, n, vn, s, x, \nm, q stand for respectively adjective, distinctives, \nverbs, nouns, norminalized verbs, locatives, non- \nchinese string, numerals and quantifiers",
    "appliqu\u00e9e"
  ],
  [
    " \ntable- 1 : examples of basenp and -basenp \nexamples \nbasenp ~ q~/air z-i~/eorridor \nbasenp i~'~/politics/t~k$1j/system ~/ re form \nbasenp ,w, d/export ~ h/commodity ffl'~/price ~/ index  \nbasenp ~,/compl icated i~/de ~fi~q-'/feature \n- basenp ~i)~/research -~/and ~j~/development \n-basenp ~i~l~/teacher q/write t~/de i ,~/eomment \nboth basenp recognition and basenp structural \nanalysis are basic tasks in chinese information \nretrieval",
    "appliqu\u00e9e"
  ],
  [
    " \nthe paper mainly discusses the problems \nrelated to chinese basenp structural analysis",
    "appliqu\u00e9e"
  ],
  [
    " \nsection 2 puts forward a quasi-dependency model \nfor structure analysis of chinese basenps",
    "appliqu\u00e9e"
  ],
  [
    " the research of \nlauer shows that the dependency model is \nsuperior to the adjacency model for structural \nanalysis of english noun phrase\\[2\\]",
    "appliqu\u00e9e"
  ],
  [
    " however, \nthere is no model for structural nalysis of chinese \nbasenp till now",
    "appliqu\u00e9e"
  ],
  [
    " \n\\[assumption 1\\] in a chinese basenp, if two \nwords x and y can constituent dependency relation, \nthen the head is always the post-positon word y, \nthat is x' -y ",
    "appliqu\u00e9e"
  ],
  [
    " \non the basis of assumption-l, we put forward \nthe quasi-dependency model for structural analysis \nof chinese basenps",
    "appliqu\u00e9e"
  ],
  [
    " conclusions \nthe paper put forward a quasi-dependency model \nfor structural analysis of chinese basenps, and a \nmdl-based algorithm for the quasi-dependency- \nstrength acquisition",
    "appliqu\u00e9e"
  ],
  [
    " the experiments show that the \nproposed model is more suitable for chinese basenp \nanalysis and the proposed mdl-based algorithm is \nsuperior to the traditional ml-based algorithm",
    "appliqu\u00e9e"
  ],
  [
    ", for french noun phrases \nin switching with arabic and, most important, \n(iii) lexical borrowing",
    "appliqu\u00e9e"
  ],
  [
    " despite \ncriticism of this approach (rivas, 1981; wool- \nford, 1983; di sciullo et al, 1986; pandit, 1990; \nmyers-scotton, 1993; belazi et al, 1994; ma- \nhootian & santorini, 1994), it has been suc- \ncessfully used to account for code-switching in\nspanish-english (poplack, 1978,1980), finnish- \nenglish (poplack et al, 1987b), arabic-french \n(na'it m'barek & sankoff, 1988), tamil-english \n(sankoff et al, 1990), fongbe-french (meechan \n& poplack, 1995), wolof-french (poplack & \nmeechan, 1995), igbo-english (eze, 1997) and \nmany other bilingual communities",
    "appliqu\u00e9e"
  ],
  [
    " \nexamples (la,b) are two (fictitious) sentences \nin english and french which we may imagine to \nbe counterparts ofeach other according to some \n5proofs of all theorems are given in sankoff (1998) \ngrammatical analysis of the two languages, in \nthe sense of theorem 1: \ndespite differences in word order, the con- \nstituent structure is identical and the lexical \nitems are word-for-word translations (without \nquibbling about the questionable xical status \nof the reflexive clitic and the genitive particle \nand the somewhat different internal structure \nof determiner in the pp)",
    "appliqu\u00e9e"
  ],
  [
    " \nj s  \nn(f) d(e) \ni \nfr~res the avec some of grandma's sawn rem~nuable wash themselves \nto constrain the order, we are motivated to \ntry to exclude situations uch as a declarative \nsentence which begins with a well-formed verb \nphrase entirely in english followed by a subject \nnoun phrase in another language",
    "appliqu\u00e9e"
  ],
  [
    " thus in our hypothetical \nexample with a sentence-initial english verb \nphrase, requirements (ii) and (iii) conflict, so \nthe sentence is not well-formed",
    "appliqu\u00e9e"
  ],
  [
    " the rule np--+ adj+np in en- \nglish and np-~ np+adj in french results in \nthe lowest np being labeled e, by requirement \n(iii)",
    "appliqu\u00e9e"
  ],
  [
    " \nexample (9) is drawn from the finnish- \nenglish code-mixing corpus of poplack et al \n(1987b)",
    "appliqu\u00e9e"
  ],
  [
    " we assume, following these authors' \narguments, that this sentence consists of three \nfragments, with code-switches immediately be- \nfore and after the english preposition to",
    "appliqu\u00e9e"
  ],
  [
    " \n15 \nellative case-marked kidneyst~i and illative aor- \ntaan are formed of borrowings from english and \nbehave as native items (e",
    "appliqu\u00e9e"
  ],
  [
    " there is no en- \nglish determiner preceding them as would be \nexpected within english fragments; rather they \nmanifest null determiners and case-marking \ncharacteristic of finnish - -  see section 3)",
    "appliqu\u00e9e"
  ],
  [
    "' \nagain, the inessive marker -ssa has the same \nfunction as the english preposition at and only \none of them should have appeared, according to \nour model",
    "appliqu\u00e9e"
  ],
  [
    " examples (11) \nand (12) below are drawn from the tamil- \nenglish code-mixing corpus of sankoff et al \n(1990)",
    "appliqu\u00e9e"
  ],
  [
    " the noun in the finnish adpositional \n16 \nphrase, the object in svov constructions, the \nproposition complement ofboth the english and \ntamil verbs, all receive two labels this way",
    "appliqu\u00e9e"
  ],
  [
    "1, examples (14) and (15), as well as (13), il- \nlustrate the placement of an english proposition \npreceding the tamil propositional complemen- \ntizer, instead of in its obligatory english posi- \ntion following that",
    "appliqu\u00e9e"
  ],
  [
    " \nall other code-switches satisfy the equivalence \nconstraint; none of the numerous other word- \norder conflicts between tamil and english give \nrise to an insertional code-switching possibility",
    "appliqu\u00e9e"
  ],
  [
    " this involves the \ninsertion, by bilingual moroccans, of a full \nfrench noun phrase, including determiners and \nquantifiers, in all contexts where an arabic \nnoun phrase would be appropriate",
    "appliqu\u00e9e"
  ],
  [
    " this in- \ncludes, among other contexts, post-verbal sub- \njects as in (16), which are not possible in french",
    "appliqu\u00e9e"
  ],
  [
    " \ndeterminer-initial french noun phrases also ap- \npear after demonstratives a in (17) and (18), \nproducing demonstrative-determiner sequences, \nand after the indefinite wa",
    "appliqu\u00e9e"
  ],
  [
    "hd as in (18), produc- \ning determiner-determiner sequences, neither of \nwhich is a french pattern",
    "appliqu\u00e9e"
  ],
  [
    " for example, the english propositional \ncomplement preceding the tamil complemen- \ntizer nu would be labeled for tamil by crite- \nrion (iii) because of its non-english position, \nbut this would conflict with the english label \nit would receive from criterion (ii) since it is \na normal english sentence containing only en- \nglish lexical items",
    "appliqu\u00e9e"
  ],
  [
    " similarly, the post-verbal \nsubject consisting entirely of a normal french \nnoun phrase receives conflicting labels from its \nposition corresponding to arabic rules and from \nits own constituent elements",
    "appliqu\u00e9e"
  ],
  [
    " tamil-english or arabic-french), \nuse it very sparingly in the sense that typically \nonly one type of constituent (english proposi- \ntions or french noun phrases) may be inserted \nin contexts (before nu, postverbally) where it \nwould not be found in monolingual discourse",
    "appliqu\u00e9e"
  ],
  [
    " there is no dan- \nger that this will result in anomalous labeling \nhigher in the phrase structure, since a sister con- \nstituent (the tamil complementizer, the ara- \nbic verb) will already have the contrary label, \nand the constituent containing them is thus pre- \nvented from receiving a label by way of criterion \n(ii)",
    "appliqu\u00e9e"
  ],
  [
    "1 has been verified as a general ten- \ndency in several communities - puerto rican \nspanish and english in new york (poplack, \n1980), finnish and english (poplack et al, \n1987b), tamil and english (sankoff et al, \n1990), wolof and french, and fongbe and \nfrench (meechan & poplack, 1995; poplack & \nmeechan, 1995), igbo and english (eze, 1997), \nand others",
    "appliqu\u00e9e"
  ],
  [
    "2 case mark ing  of engl ish-or igin \nnouns in tamil  \nin the tamil corpus referred to in sections 2",
    "appliqu\u00e9e"
  ],
  [
    "2, many english-origin ouns occur in \npreverbal position, where the verb is an in- \nflected tamil form",
    "appliqu\u00e9e"
  ],
  [
    " tamil being a sov lan- \nguage, this is just where tamil direct (and indi- \nmarker marker \npresent absent n \naccusative \nenglish origin 29% 71% 108 \nnative tamil \n(no pronouns) 39% 61% 51 \ndative \nenglish origin 86% 14% 91 \nnative tamil 99% 1% 230 \ntable 1: variable accusative and dative marking \non english-origin and native tamil objects",
    "appliqu\u00e9e"
  ],
  [
    " examining these english- \norigin nouns, we first note that these occur most \nfrequently in isolation, and occasionally as com- \npounds, or as familiar adjective-noun combina- \ntions, but never preceded by english preposi- \ntions, articles, quantifiers or demonstratives a\nwould frequently be the case if these were parts \nof well-formed english fragments resulting from \ncode-switching",
    "appliqu\u00e9e"
  ],
  [
    " \nsecond, whereas the preponderance of prever- \nbal native tamil objects are actually pronouns, \nfrom 45-70% depending on the case, no english \npronouns whatsoever appear in this context, as \nwould be expected from borrowings, but not if \nthese were code-switches into english fragments \n- -  which would normally include at least the oc- \ncasional pronoun",
    "appliqu\u00e9e"
  ],
  [
    " they \neither have null morphology or tamil inflec- \ntions",
    "appliqu\u00e9e"
  ],
  [
    " since in tamil the numerically fre- \nquent accusatives and datives are prescribed to \ntake non-null case-marking, we examine mark- \ning rates quantitatively",
    "appliqu\u00e9e"
  ],
  [
    " in fact, as in table \n1, many (non-pronominal) tamil forms are un- \nmarked, especially accusatives",
    "appliqu\u00e9e"
  ],
  [
    " this morphological integration into \ntamil is exactly what would be expected of bor- \nrowings, and certainly not of well-formed en- \nglish fragments produced by code-switching",
    "appliqu\u00e9e"
  ],
  [
    " \nin summary, the criteria of syntactic integra- \ntion, isolation, lexical category, and morpholog- \nical integration all confirm the loanword status \nof the preverbal english-origin ouns, and jus- \ntify our considering them as tamil nouns for \nthe purposes of applying our model of code- \n19 \nswitching",
    "appliqu\u00e9e"
  ],
  [
    " bilingual \nspeech of turkish immigrants in the nether- \nlands",
    "appliqu\u00e9e"
  ],
  [
    " contraction, deletion and in- \nherent variability of the english copula",
    "appliqu\u00e9e"
  ],
  [
    " orphan \ncategories inbilingual discourse: adjectiviza- \ntion strategies in wolof-french and fongbe- \nfrench",
    "appliqu\u00e9e"
  ],
  [
    " sometimes i'll start a \nsentence in spanish y termino en \nespai~ol: toward a typology of code- \nswitching",
    "appliqu\u00e9e"
  ],
  [
    " of spanish and por- \ntuguese, university of massachusetts",
    "appliqu\u00e9e"
  ],
  [
    " the case of the nonce loan in tamil",
    "appliqu\u00e9e"
  ],
  [
    " of computer languages and systems \nuniversity of the basque country, 649 p",
    "appliqu\u00e9e"
  ],
  [
    ", \ne-20080 donostia, basque country \neneko@si",
    "appliqu\u00e9e"
  ],
  [
    " its \nuse as a part of speech tagger for english has been \nhighly successful",
    "appliqu\u00e9e"
  ],
  [
    " its application to english \n(engcg 3) resulted a very successful part of \nspeech tagger for english",
    "appliqu\u00e9e"
  ],
  [
    " \nthe corpus of genuine spelling errors, which we \nalso call the \"real\" corpus for short, was magazine \ntext from the bank of english corpus, which \nprobably was not previously spell-checked (it \ncontained many misspellings), so it was a good \nsource of errors",
    "appliqu\u00e9e"
  ],
  [
    " lastly, bf was \ntrained on the brown corpus on american english, \nwhile the \"real\" texts come from the bank of \nenglish",
    "appliqu\u00e9e"
  ],
  [
    " the \nalgorithm is evaluated in missing accent \nrestoration task for spanish and french text, \nagainst a predefined set of a few words giving an \naccuracy over 99%",
    "appliqu\u00e9e"
  ],
  [
    " secondly, we collected frequencies \nfrom an american english corpus to correct \nbritish english texts",
    "appliqu\u00e9e"
  ],
  [
    " \nacknowledgements \nthis research was supported by the basque \ngovernment, the university of the basque \ncountry and the cicyt (comisirn \ninterministerial de ciencia y tecnologfa)",
    "appliqu\u00e9e"
  ],
  [
    " (1967) computing analysis of \npresent-day american english",
    "appliqu\u00e9e"
  ],
  [
    " \nfor the language pairs that are of particular \ninterest to us, english vs",
    "appliqu\u00e9e"
  ],
  [
    " \nin english a large number of technical terms are \nmulti-word compounds, while the corresponding \nterms in other germanic languages are often \nsingle-word compounds",
    "appliqu\u00e9e"
  ],
  [
    " \nenglish \nfrle manager \nnetwork server \noperating system \nsetup directory \nswedish \nftlhanterare \nn~itverksserver \noperativsystem \ninstallationskatalog \nalso, many common adverbials and prepositions \nare multi-word units, which may or may not be \ntranslated as such",
    "appliqu\u00e9e"
  ],
  [
    " equivalent adverbials and prepositions \nenglish swedish \nafter all n~ir allt kommer,omkring \ntrots in spite of \nin general i allm~inhet \n1",
    "appliqu\u00e9e"
  ],
  [
    " \nalthough we primarily use the system for \n29 \nbitexts with an english and a scandinavian half, \nthe system should preferably be useful for many \ndifferent language pairs",
    "appliqu\u00e9e"
  ],
  [
    " \ncoefficient as their basis for aligning collocations \nbetween english and french",
    "appliqu\u00e9e"
  ],
  [
    " for instance, the do- \nsupport found in english usually has no \ncounterpart in other languages",
    "appliqu\u00e9e"
  ],
  [
    " this is definitely a \nheuristic, but it has been shown to be very useful \n31 \nfor technical texts involving english and \nscandinavian, where terms are often found in lists \nor table cells (tiedemann 1997)",
    "appliqu\u00e9e"
  ],
  [
    " for example, \\[0, s, ed, ing\\] is \na suffix list for regular english verbs",
    "appliqu\u00e9e"
  ],
  [
    "779 source words) \nwhich both were translated from english into \nswedish",
    "appliqu\u00e9e"
  ],
  [
    " \nacknowledgements \nthis work is part of the project \"parallell corpora \nin link6ping, uppsala and g6teborg\" (plug), \njointly funded by nutek and hsfr under the \nswedish national research programme in \nlanguage technology",
    "appliqu\u00e9e"
  ],
  [
    " alexa (1997) '~rowards automatically \naligning german compounds with english word groups",
    "appliqu\u00e9e"
  ],
  [
    "automatic acquisition of hierarchical transduction models \nfor machine translation \nhiyan  a lshawi  sr in ivas  bangalore shona douglas \nat&t labs research \n180 park avenue, p",
    "appliqu\u00e9e"
  ],
  [
    " the \nmethod has been applied to create an english- \nspanish translation model for a speech trans- \nlation application, with word accuracy of over \n75% as measured by a string-distance ompari- \nson to three reference translations",
    "appliqu\u00e9e"
  ],
  [
    " the resulting translation model \nhas been used as a component of an english- \nspanish speech translation system",
    "appliqu\u00e9e"
  ],
  [
    " \nin section 7, we show the effectiveness of ap- \npropriate head selection in terms of the trans- \nlation performance and size of the head trans- \nducer model in the context of an english- \nspanish translation system",
    "appliqu\u00e9e"
  ],
  [
    "1 \ntable 1: word accuracy (percent) against the \nsingle held-out human translation \n7 eng l i sh -span ish  exper iment  \nthe training and test data for the experiments \nreported here were taken from a set of tran- \nscribed utterances from the air travel infor- \nmation system (atis) corpus together with a \ntranslation of each utterance to spanish",
    "appliqu\u00e9e"
  ],
  [
    " \ntlle test set used in the evaluations reported \nhere consisted of 336 held-out english sentences",
    "appliqu\u00e9e"
  ],
  [
    " \nthe models evaluated are \nsys:  the automatically trained head trans- \nduction model; \nwfw: a baseline word-for-word model in \nwhich each english word is translated by the \nspanish word most highly correlated with it in \nthe corpus",
    "appliqu\u00e9e"
  ],
  [
    " we have started \nto experiment with learning models for more \nchallenging language pairs such as english to \njapanese that exhibit more variation in word \norder and complex lexical transformations",
    "appliqu\u00e9e"
  ],
  [
    " rossar i@lettres, unige, ch \nabst ract  \nstarting from descriptions of french connectives \n(in particular \"donc\"---therefore), on the one \nhand, and aspectual properties of french tenses \npass4 simple and imparfait on the other hand, \nwe study in this paper how the two interact \nwith respect o the expression of causality",
    "appliqu\u00e9e"
  ],
  [
    ", the translation into french of a simple past can be \neither ps or imp",
    "appliqu\u00e9e"
  ],
  [
    " we translate systematically imp into \npast progressive, ven when the glose does not have the \nsame aspectuo-temporal properties as the french origi- \nnal",
    "appliqu\u00e9e"
  ],
  [
    " the \nexamples we deal with in this paper suggest that \ntenses, at least in french and in particular the \nchoice between ps and imp must  also be taken \ninto account",
    "appliqu\u00e9e"
  ],
  [
    " \nwe adopt as a basis for the description of \nimp the proposal made in the drt frame- \nwork (kamp and rohrer, 1983; kamp and \nreyle, 1993), amended with proposals made in \nfrench literature, in particular concerning the \nanaphoric properties of this tense (tasmowski- \nde ryck, 1985; vet and molendijk, 1985; \nmolendijk, 1994)",
    "appliqu\u00e9e"
  ],
  [
    "1 data \neven if a causality (the second sentence intro- \nducing the cause of the first one) is pragmati- \ncally possible in all these examples, we observe \nthat a sequence ps-ps imposes in french a tem- \nporal sequence interpretation: in all the exam- \nples (3), the main eventuality of the second sen- \ntence is interpreted as temporally located after \nthe one of the first sentence, and this is strictly \nincompatible with a causality, where cause must \nprecede its effect",
    "appliqu\u00e9e"
  ],
  [
    " notice that here ps in french \nbehaves differently from simple past in english",
    "appliqu\u00e9e"
  ],
  [
    " jean was hitting her \n5the translation of the ambiguous example (2a) (las- \ncarides and asher, 1993) is not ambiguous in french \nwhere no causal interpretation is available (2b)",
    "appliqu\u00e9e"
  ],
  [
    "2 discuss ion \nwe think that these acceptabilities can be ex- \nplained if one takes into account two princi- \nples: one concerns causality itself in connection \nwith aspectuality, the other concerns the french \nimp's ability to act as an aspectual operator",
    "appliqu\u00e9e"
  ],
  [
    " in the absence of other dis- \ncourse clues, such a sequence is interpreted in \nfrench as a temporal sequence relation",
    "appliqu\u00e9e"
  ],
  [
    " on time, tense and aspect: \nan essay on english metaphysics",
    "appliqu\u00e9e"
  ],
  [
    " tense use and temporal \norientation: the 'pass@ simple' and 'imparfait' \nof french",
    "appliqu\u00e9e"
  ],
  [
    " the dis- \ncourse functions of past tenses of french",
    "appliqu\u00e9e"
  ],
  [
    "a memory-based approach to learning shallow natural \nlanguage patterns \nsh lomo argamon and ido dagan and yuva l  k rymolowsk i  \ndepar tment  of mathemat ics  and computer  science \nbar- i lan university \n52900 ramat  gan, israel \n{ argamon, dagan, yuvalk}@cs, b iu ",
    "appliqu\u00e9e"
  ],
  [
    " applying the method to three syntactic pat- \nterns in english yielded positive results, suggesting \nits applicability for recognizing local linguistic pat- \nterns",
    "appliqu\u00e9e"
  ],
  [
    " in future work we plan to investigate a data- \ndriven approach for optimal selection and weighting \nof statistical features of candidate scores, as well as \nto apply the method to syntactic patterns of hebrew \nand to domain-specific patterns for information ex- \ntraction",
    "appliqu\u00e9e"
  ],
  [
    " in eva ejerhed and ido dagan, edi- \ntors, proceedings of the fourth workshop on very \nlarge corpora, pages 14-27",
    "appliqu\u00e9e"
  ],
  [
    " such methods have \n11 \nbeen applied not only to english but also to \nfrench, german, italian, spanish, chinese and \njapanese",
    "appliqu\u00e9e"
  ],
  [
    "2 japanese broadcast news \ndictation system \nwe have been developing a large- \nvocabulary continuous-speech recognition \n(lvcsr) system for japanese broadcast-news \nspeech transcription \\[4\\]\\[5\\]",
    "appliqu\u00e9e"
  ],
  [
    " to calculate word n- \ngram language models, we segmented the \nbroadcast-news manuscripts into words by using \na morphological analyzer since japanese \nsentences are written without spaces between \nwords",
    "appliqu\u00e9e"
  ],
  [
    " \njapanese text is written by a mixture of three \nkinds of characters: chinese characters (kanji) \n12 \nand two kinds of japanese characters (hira-gana \nand kata-kana)",
    "appliqu\u00e9e"
  ],
  [
    " \ntable 1 - experimental results of japanese broadcast news \ndictation with various language models (word error ate \\[%\\]) \nevaluation sets language \nmodel m/c m/n f/c f/n \nlm1 17",
    "appliqu\u00e9e"
  ],
  [
    "4 information extraction from japanese \nbroadcast news \nsummarizing transcribed news speech is useful \nfor retrieving or indexing broadcast news",
    "appliqu\u00e9e"
  ],
  [
    " in the view4you \nsystem, german and servocroatian public \nnewscasts are recorded aily",
    "appliqu\u00e9e"
  ],
  [
    " in collaboration with the vecsys company \nand with the sncf (the french railways), \nlimsi has developed a prototype telephone \nservice providing timetables, imulated fares and \nreservations, and information on reductions and \nservices for the main french intercity \nconnections",
    "appliqu\u00e9e"
  ],
  [
    " this new formulation \nof speech recognit ion was \nappl ied  to the japanese \nbroadcast news dictation, and it was found that \nword error rates for the clean set were slightly \nreduced by this method",
    "appliqu\u00e9e"
  ],
  [
    " zhang: \"improvements in japanese broadcast \nnews transcription\", darpa broadcast news \nworkshop, virginia (1999) \n\\[5\\] k",
    "appliqu\u00e9e"
  ],
  [
    " \nfor concreteness and experimental evalua- \ntion, we focus in this paper on a particular type \nof cooccurrence, that of a main verb and the \nhead noun of its direct object in english text",
    "appliqu\u00e9e"
  ],
  [
    " \na comparison of the enhanced good-turing and \ndeleted estimation methods for estimating proba- \nbilities of english bigrams",
    "appliqu\u00e9e"
  ],
  [
    " \nido dagan, shaul marcus, and shaul markovitch",
    "appliqu\u00e9e"
  ],
  [
    " \nido dagan, lillian lee, and fernando pereira",
    "appliqu\u00e9e"
  ],
  [
    " distributional clustering of english \nwords",
    "appliqu\u00e9e"
  ],
  [
    " an applica- \ntion proposed concurrently with the definition \nof s-tag was that of machine translation, map- \nping between english and french (abeill~ et al \n1990); work continues in the area, for example \nusing s-tag for english-korean machine trans- \nlation in a practical system (palmer et al 1998)",
    "appliqu\u00e9e"
  ],
  [
    " \nin mapping between, say, english and french, \nthere is a lexicalised tag for each language (see \nxtag, 1995, for an overview of such a gram- \nmar)",
    "appliqu\u00e9e"
  ],
  [
    " the partial deriva- \ntion trees containing the clitic lui and its english \nparallel are as in figure 5",
    "appliqu\u00e9e"
  ],
  [
    " taking as a basic set of \ntrees the xtag standard grammar of english \n(xtag, 1995), the derivation tree pair for (4) \nwould be as in figure 7",
    "appliqu\u00e9e"
  ],
  [
    " it is likely to also be use- \nful in representations for machine translation \nbetween languages that are structurally more \ndissimilar than english and french, and hence \nmore in need of structural definition of object- \nlevel constructs; exploring this is future work",
    "appliqu\u00e9e"
  ],
  [
    " a lexicalized tree adjoining gram- \nmar for english",
    "appliqu\u00e9e"
  ],
  [
    "incorporating compositional evidence in memory-based\npartial parsing\n\nyuval krymolowski and ido dagan\ndepartment of mathematics and computer science\nbar-ilan university\n52900 ramat gan, israel\n{yuvalk ,dagan}@cs",
    "non-appliqu\u00e9e"
  ],
  [
    " ferro",
    "non-appliqu\u00e9e"
  ],
  [
    "\nversions of the limsi broadcast news transcrip-\ntion system have been developed in american en-\nglish, french, german, mandarin and portuguese",
    "non-appliqu\u00e9e"
  ],
  [
    "\nat limsi broadcast news transcription systems\nhave been developed for the american english,\nfrench, german, mandarin and portuguese lan-\nguages",
    "non-appliqu\u00e9e"
  ],
  [
    " our transcription systems for french\nand german have comparable error rates for news\nbroadcasts (adda-decker et al, 2000)",
    "non-appliqu\u00e9e"
  ],
  [
    " the score of a story is ob-\ntained by summing the query term weights which\nare simply the log probabilities of the terms given\nthe story model once interpolated with a general\nenglish model",
    "non-appliqu\u00e9e"
  ],
  [
    "\nbroadcast news transcription systems for french\nand german were developed",
    "non-appliqu\u00e9e"
  ],
  [
    " the french data\ncome from a variety of television news shows and\nradio stations",
    "non-appliqu\u00e9e"
  ],
  [
    " the german data consist of tv\nnews and documentaries from arte",
    "non-appliqu\u00e9e"
  ],
  [
    " the targeted languages are\nfrench, german and portuguese",
    "non-appliqu\u00e9e"
  ],
  [
    "\nacknowledgments\nthis work has been partially financed by the eu-\nropean commission and the french ministry of\ndefense",
    "non-appliqu\u00e9e"
  ],
  [
    "\nmartine adda-decker, gilles adda, lori lamel, ?in-\nvestigating text normalization and pronunciation\nvariants for german broadcast transcription,? proc",
    "non-appliqu\u00e9e"
  ],
  [
    "\ntraditional statistical language models calcu-\nlate the probability of a sentence \u0004 using the chain\nrule:\n\u0005\u0007\u0006\n\u0004\t\b\u000b\n\n\u0005\u0007\u0006\n\f\u000f\u000e\u0010\f\u0012\u0011\u0014\u0013\u0015\u0013\u0015\u0013\u0016\f\u0018\u0017\n\b\u000b\n\n\u0017\n\u0019\n\u001afiff\n\u000e\n\u0005\u0007\u0006\n\f\n\u001a\u0010fl ffi\u001f\u001a\n\b (1)\n \nthis work has been partially supported by the spanish\ncycit under contract (tic98/0423-c06)",
    "non-appliqu\u00e9e"
  ],
  [
    " viii spanish symposium on pattern\nrecognition and image analysis, pages 119?126",
    "non-appliqu\u00e9e"
  ],
  [
    "\nuniversity of delaware",
    "non-appliqu\u00e9e"
  ],
  [
    " the proper treatment of quantifi-\ncation in ordinary english",
    "non-appliqu\u00e9e"
  ],
  [
    " a lexicalized tree adjoin-\ning grammar for english",
    "non-appliqu\u00e9e"
  ],
  [
    "\n1 motivation\nthe logic of typed feature structures (carpenter,\n1992) has been widely used as a means of formaliz-\ning and developing natural language grammars that\nsupport computationally efficient parsing, genera-\ntion and sld resolution, notably grammars within\nthe head-driven phrase structure grammar (hpsg)\nframework, as evidenced by the recent successful\ndevelopment of the lingo reference grammar for\nenglish (lingo, 1999)",
    "non-appliqu\u00e9e"
  ],
  [
    " while this compro-\nmise solution must eventually be tested on larger and\nmore diverse grammars, it has been shown to reduce\nthe total parsing time of a large corpus on the ale\nhpsg benchmark grammar of english (penn, 1993)\nby a factor of about 4 (penn, 1999)",
    "non-appliqu\u00e9e"
  ],
  [
    " comparing demonstrative features\nin three written english genres",
    "non-appliqu\u00e9e"
  ],
  [
    " \ncitizen \np romanian \ngymnast \nc \nwho is lilian \nthuram? \nnews \npage \ni french \ndefender \np \nwho is the mayor \nof wash",
    "non-appliqu\u00e9e"
  ],
  [
    " english verb classes and alternations a\npreliminary investigation",
    "non-appliqu\u00e9e"
  ],
  [
    " consider, for example, \nthe question ?who is the leader of france?? the \nsentence ?henri hadjenberg, who is the leader of \nfrance?s jewish community, endorsed confronting \nthe specter of the vichy past? overlaps with all \nquestion terms, but it does not contain the correct \nanswer; while the sentence ?bush later met with \nfrench president jacques chirac? does not overlap \nwith any question term, but it does contain the \ncorrect answer",
    "non-appliqu\u00e9e"
  ],
  [
    "\nanother language (like swahili) uses morphologi-\ncal variations similar to latin for the same purpose\nand thus has ended up with a rich set of affixes",
    "non-appliqu\u00e9e"
  ],
  [
    "\nivan bulyko and mari ostendorf",
    "non-appliqu\u00e9e"
  ],
  [
    "\nuser: are there any thai restaurants?\nsystem: can you provide a neighborhood or city?\nuser: boston",
    "non-appliqu\u00e9e"
  ],
  [
    "\nsystem: there are no thai restaurants in dorch-\nester",
    "non-appliqu\u00e9e"
  ],
  [
    " thai village\nand house of siam",
    "non-appliqu\u00e9e"
  ],
  [
    ", query-\ning for ?chinese or japanese restaurants",
    "non-appliqu\u00e9e"
  ],
  [
    " ?some choices are italian\nframe example sentences\n\u0000\nc seek i?m interested in some low end restaurants in back bay please",
    "non-appliqu\u00e9e"
  ],
  [
    "\nand chinese",
    "non-appliqu\u00e9e"
  ],
  [
    "\nfor instance, if a vietnamese restaurant is not\navailable at all, the system relaxes the query to\nalternative asian cuisines",
    "non-appliqu\u00e9e"
  ],
  [
    " some of the\noptions are american, pizza, and italian",
    "non-appliqu\u00e9e"
  ],
  [
    " cheap thai restaurants in dorchester: there are no cheap thai restaurants in dorchester",
    "non-appliqu\u00e9e"
  ],
  [
    " however,\nthere are in total 14 cheap thai restaurants",
    "non-appliqu\u00e9e"
  ],
  [
    " the\nnearest one is thai village in the south end",
    "non-appliqu\u00e9e"
  ],
  [
    " sparky\nconsists of a randomized sentence plan gen-\nerator (spg) and a trainable sentence plan\nranker (spr); these are described in sections 3\nstrategy:recommend\nitems: chanpen thai\nrelations:justify(nuc:1;sat:2); justify(nuc:1;sat:3); jus-\ntify(nuc:1;sat:4)\ncontent: 1",
    "non-appliqu\u00e9e"
  ],
  [
    "\nalt realization h spr\n2 chanpen thai, which is a thai restau-\nrant, has decent decor",
    "non-appliqu\u00e9e"
  ],
  [
    "28\n5 since chanpen thai is a thai restau-\nrant, with good service, and it has de-\ncent decor, it has the best overall qual-\nity among the selected restaurants",
    "non-appliqu\u00e9e"
  ],
  [
    "14\n6 chanpen thai, which is a thai restau-\nrant, with decent decor and good ser-\nvice, has the best overall quality among\nthe selected restaurants",
    "non-appliqu\u00e9e"
  ],
  [
    " carmine?s, which is an italian\nrestaurant, with good service, has de-\ncent decor",
    "non-appliqu\u00e9e"
  ],
  [
    " on the other\nhand, carmine?s is an italian restau-\nrant",
    "non-appliqu\u00e9e"
  ],
  [
    "\ncarmine?s, which is an italian restau-\nrant, has decent decor and good service",
    "non-appliqu\u00e9e"
  ],
  [
    " carmine?s is\nan italian restaurant",
    "non-appliqu\u00e9e"
  ],
  [
    " for ex-\nample, relative-clause(chanpen thai is a\nthai restaurant, with decent decor and good ser-\nvice;chanpen thai has the best overall quality\namong the selected restaurants) yields chanpen\nthai, which is a thai restaurant, with decent\ndecor and good service, has the best overall qual-\nity among the selected restaurants",
    "non-appliqu\u00e9e"
  ],
  [
    " carmine?s\nis an italian restaurant",
    "non-appliqu\u00e9e"
  ],
  [
    " the\ncomposite labels on the interior nodes of the sp-\nperiod_elaboration\nperiod_contrast\nrelative_clause_inferperiod_infer\nperiod_infer <4>assert-com-service <7>assert-com-cuisine merge_infer\n<3>assert-come-decor <5>assert-com-service<2>assert-com-decor<6>assert-com-cuisine\n<1>assert-com-list_exceptional\nfigure 7: sentence plan tree (sp-tree) for alternative 13 in figure 4\noffer\nexceptional\namong\nrestaurant\nselected\nabove_and_carmine?s\ncarmine?s\nbe3\nrestaurantcarmine?s\nitalian\ndecor\ndecent and2\nservice\ngood\nhave1\nperiod\nnew_american\nbe3\nabove above decor\ngood\nhave1\nrestaurant\nabove\ngood\nhave1\nservice\nperiod\nperiod\nvalue\nperiod\nfigure 8: dependency tree (d-tree) for alternative 13 in figure 4\ntree indicate the clause-combining relation se-\nlected to communicate the specified rhetorical\nrelation",
    "non-appliqu\u00e9e"
  ],
  [
    " it?s a\nfrench, italian restaurant",
    "non-appliqu\u00e9e"
  ],
  [
    " it?s an italian restau-\nrant",
    "non-appliqu\u00e9e"
  ],
  [
    " john?s pizzeria is an italian , pizza\nrestaurant",
    "non-appliqu\u00e9e"
  ],
  [
    "\nuguale is a french, italian restaurant,\nwith very good service",
    "non-appliqu\u00e9e"
  ],
  [
    " lee (1999)) have criticised biber \nfor making assumptions about the validity and gener-\nalisability of his approach to english language as a \nwhole",
    "non-appliqu\u00e9e"
  ],
  [
    "3 182k ?\ntable 1: lecture corpus statistics\nsub-topics, even though it is a fairly rare term\nin general english and bears much semantic con-\ntent",
    "non-appliqu\u00e9e"
  ],
  [
    " cohesion in english",
    "non-appliqu\u00e9e"
  ],
  [
    "\nido dagan and alan itai",
    "non-appliqu\u00e9e"
  ],
  [
    "proceedings of the 45th annual meeting of the association of computational linguistics, pages 57?64,\nprague, czech republic, june 2007",
    "non-appliqu\u00e9e"
  ],
  [
    " the complete set of nouns extracted\nin this way is then used to drive a second phase of\nthe search, in which the query template ?as * as a\nnoun? is used to acquire similes that may have\nlain beyond the 200-snippet horizon of the original\nsearch, or that may hinge on adjectives not included\non the original list",
    "non-appliqu\u00e9e"
  ],
  [
    "\n1 introduction\nover the past few years, there has been consid-\nerable progress in the ability of manually created\nlarge-scale grammars, such as the english resource\ngrammar (erg, copestake and flickinger (2000))\nor the pargram grammars (butt et al, 2002), to\nparse wide-coverage text and assign it deep seman-\ntic representations",
    "non-appliqu\u00e9e"
  ],
  [
    " an open-\nsource grammar development environment and\nbroad-coverage english grammar using hpsg",
    "non-appliqu\u00e9e"
  ],
  [
    " an improper treatment of quantifi-\ncation in ordinary english",
    "non-appliqu\u00e9e"
  ],
  [
    " (2006) have augmented hidden markov models\nwith bayes networks trained to describe articula-\ntory constraints from a small amount of japanese\nvocal tract data, resulting in a small phoneme-\nerror reduction",
    "non-appliqu\u00e9e"
  ],
  [
    " how-\never, if the language under consideration is any-\nthing other than english, then a translation into\nenglish (or some other reference language) is for\nmost purposes a perfectly adequate meaning rep-\nresentation",
    "non-appliqu\u00e9e"
  ],
  [
    " it\ninvites efforts to enrich it by automatic means:\nfor example, there has been work on parsing the\nenglish translations and using the word-by-word\nglosses to transfer the parse tree to the object lan-\nguage, effectively creating a treebank automati-\ncally (xia and lewis, 2007)",
    "non-appliqu\u00e9e"
  ],
  [
    " two models are the\nvolunteers who scan documents and correct ocr\noutput in project gutenberg, or the undergraduate\nvolunteers who have constructed greek and latin\ntreebanks within project perseus (crane, 2010)",
    "non-appliqu\u00e9e"
  ],
  [
    " in proceedings of the 2007 joint\nconference on empirical methods in natural lan-\nguage processing and computational natural lan-\nguage learning (emnlp-conll), pages 42?50,\nprague, czech republic",
    "non-appliqu\u00e9e"
  ],
  [
    "\nphilip resnik, mari broman olsen, and mona diab",
    "non-appliqu\u00e9e"
  ],
  [
    "\njohannes schaback and fang li",
    "non-appliqu\u00e9e"
  ],
  [
    " 45th meeting of association for computational\nlinguistics (acl), prague, czech republic",
    "non-appliqu\u00e9e"
  ],
  [
    " of the\nannual meeting of the acl, pages 264?271, prague,\nczech republic, june",
    "non-appliqu\u00e9e"
  ],
  [
    " 45th meeting of association for computational\nlinguistics (acl), pages 632?639, prague, czech re-\npublic",
    "non-appliqu\u00e9e"
  ],
  [
    " of the conll shared\ntask, prague, czech republic",
    "non-appliqu\u00e9e"
  ],
  [
    "\n24\nfigure 1: curve fits using different curve families on a\ntest dataset\nfor all the six families on a test dataset for english-\ngerman language pair",
    "non-appliqu\u00e9e"
  ],
  [
    " in pro-\nceedings of the 45th annual meeting of the associ-\nation for computational linguistics companion vol-\nume proceedings of the demo and poster sessions,\npages 177?180, prague, czech republic, june",
    "non-appliqu\u00e9e"
  ],
  [
    "\n[no wonder he got an a for his english class,]e1 [he was\nstudying so hard",
    "non-appliqu\u00e9e"
  ],
  [
    " dynamic non-parametric mixture models and\nthe recurrent chinese restaurant process: with applica-\ntions to evolutionary clustering",
    "non-appliqu\u00e9e"
  ],
  [
    " in proceed-\nings of the fourth international workshop on semantic\nevaluations (semeval-2007), pages 129?132, prague,\nczech republic, june",
    "non-appliqu\u00e9e"
  ],
  [
    "\nin proceedings of the fourth international workshop on\nsemantic evaluations (semeval-2007), pages 245?248,\nprague, czech republic, june",
    "non-appliqu\u00e9e"
  ],
  [
    " ace (automatic content extraction)\nenglish annotation guidelines for events version 5",
    "non-appliqu\u00e9e"
  ],
  [
    " data: english broadcast news, 128m words training;\n692k words test; 143k word vocabulary",
    "non-appliqu\u00e9e"
  ],
  [
    "\n5 experimental results\nall results presented here are for english broad-\ncast news",
    "non-appliqu\u00e9e"
  ],
  [
    "\na procedure for quantitatively comparing the syn-\ntactic coverage of english grammars",
    "non-appliqu\u00e9e"
  ],
  [
    " a discourse structure analyzer for japanese\ntext",
    "non-appliqu\u00e9e"
  ],
  [
    "\nroy bar-haim, ido dagan, iddo greental, and eyal\nshnarch",
    "non-appliqu\u00e9e"
  ],
  [
    "\nido dagan, o",
    "non-appliqu\u00e9e"
  ],
  [
    "\n88\noren melamud, jonathan berant, ido dagan, jacob\ngoldberger, and idan szpektor",
    "non-appliqu\u00e9e"
  ],
  [
    "\nasher stern and ido dagan",
    "non-appliqu\u00e9e"
  ],
  [
    "\nasher stern, roni stern, ido dagan, and ariel felner",
    "non-appliqu\u00e9e"
  ],
  [
    "\nidan szpektor, hristo tanev, ido dagan, and bonaven-\ntura coppola",
    "non-appliqu\u00e9e"
  ],
  [
    "\nidan szpektor, eyal shnarch, and ido dagan",
    "non-appliqu\u00e9e"
  ],
  [
    "\nhila weisman, jonathan berant, idan szpektor, and ido\ndagan",
    "non-appliqu\u00e9e"
  ],
  [
    " the most recent developments have fo-\ncused on deep learning the relationships between\nvisual feature vectors and word-embeddings with\nlanguage generation models based on recurrent\nneural networks or long-short term memory net-\nworks (karpathy and fei-fei, 2015; vinyals et al,\n2015; mao et al, 2015; fang et al, 2015; don-\nahue et al, 2015; lebret et al, 2015)",
    "non-appliqu\u00e9e"
  ],
  [
    "\napplied morphological processing of english",
    "non-appliqu\u00e9e"
  ],
  [
    " wordnet: a lexical\ndatabase for english",
    "non-appliqu\u00e9e"
  ],
  [
    " english gigaword fourth edition",
    "non-appliqu\u00e9e"
  ],
  [
    "\nc?2015 association for computational linguistics\nsemantically smooth knowledge graph embedding\nshu guo\n?\n, quan wang\n??\n, bin wang\n?\n, lihong wang\n?\n, li guo\n?\n?\ninstitute of information engineering, chinese academy of sciences, beijing 100093, china\n{guoshu,wangquan,wangbin,guoli}@iie",
    "non-appliqu\u00e9e"
  ],
  [
    " 61402465), the s-\ntrategic priority research program of the chinese\nacademy of sciences (grant no",
    "non-appliqu\u00e9e"
  ],
  [
    " using syntax-\nbased machine translation to parse english into\nabstract meaning representation",
    "non-appliqu\u00e9e"
  ],
  [
    "\n\nwe would like to thank the anonymous reviewers for their valuable comments and thank kaiyu\nqian, gang niu for useful discussions",
    "non-appliqu\u00e9e"
  ],
  [
    "neural end-to-end learning for computational argumentation mining\nsteffen eger\u2020\u2021 , johannes daxenberger\u2020 , iryna gurevych\u2020\u2021\n\u2020\nubiquitous knowledge processing lab (ukp-tuda)\ndepartment of computer science, technische universitt darmstadt\n\u2021\nubiquitous knowledge processing lab (ukp-dipf)\ngerman institute for educational research and educational information\nhttp://www",
    "non-appliqu\u00e9e"
  ],
  [
    " the\nsecond author was supported by the german federal ministry of education and research (bmbf)\nunder the promotional reference 01ug1416b\n(cedifor)",
    "non-appliqu\u00e9e"
  ],
  [
    "\n\nraquel mochales palau and marie-francine moens",
    "non-appliqu\u00e9e"
  ],
  [
    " forbus, ni lao\nnorthwestern university, evanston, il\ntel-aviv university, tel aviv-yafo, israel\ngoogle inc",
    "non-appliqu\u00e9e"
  ],
  [
    " prague, czech republic, pages 678\u2013687",
    "non-appliqu\u00e9e"
  ],
  [
    "\nprior work used a customized hinge loss (abhishek et al",
    "non-appliqu\u00e9e"
  ],
  [
    " wordnet: a lexical database for\nenglish",
    "non-appliqu\u00e9e"
  ],
  [
    " english gigaword fifth edition (ldc2011t07)",
    "non-appliqu\u00e9e"
  ],
  [
    "\n\neyal shnarch, libby barak, and ido dagan",
    "non-appliqu\u00e9e"
  ],
  [
    " a\ncross-lingual dictionary for english wikipedia concepts",
    "non-appliqu\u00e9e"
  ],
  [
    "incremental transformer with deliberation decoder\nfor document grounded conversations\nzekang li\u2020\u2666 , cheng niu\u2021 , fandong meng\u2021\u2217, yang feng\u2666 , qian li\u2660 , jie zhou\u2021\n\u2020\ndian group, school of electronic information and communications\nhuazhong university of science and technology\n\u2021\npattern recognition center, wechat ai, tencent inc, china\n\u2666\nkey laboratory of intelligent information processing\ninstitute of computing technology, chinese academy of sciences\n\u2660\nschool of computer science and engineering, northeastern university, china\nzekangli97@gmail",
    "non-appliqu\u00e9e"
  ],
  [
    "\nyanran li, hui su, xiaoyu shen, wenjie li, ziqiang\ncao, and shuzi niu",
    "non-appliqu\u00e9e"
  ],
  [
    "\n\nalexis conneau, german kruszewski, guillaume\nlample, lo\u0131\u0308c barrault, and marco baroni",
    "non-appliqu\u00e9e"
  ],
  [
    "\nforbus, and ni lao",
    "non-appliqu\u00e9e"
  ],
  [
    " for\nillustration, consider the two derivations of the\nfollowing swiss german sentence from shieber\n(1985) in fig",
    "non-appliqu\u00e9e"
  ],
  [
    " 2c, ydpr (t)\nis the swiss german sentence in (1)",
    "non-appliqu\u00e9e"
  ],
  [
    " the proper treatment of\nquantification in ordinary english",
    "non-appliqu\u00e9e"
  ],
  [
    " aligning english strings with\nabstract meaning representation graphs",
    "non-appliqu\u00e9e"
  ],
  [
    " parsing english\ninto abstract meaning representation using syntaxbased machine translation",
    "non-appliqu\u00e9e"
  ],
  [
    "\n\nyanran li, hui su, xiaoyu shen, wenjie li, ziqiang\ncao, and shuzi niu",
    "non-appliqu\u00e9e"
  ],
  [
    "\n\nyinhan liu, myle ott, naman goyal, jingfei du, mandar joshi, danqi chen, omer levy, mike lewis,\nluke zettlemoyer, and veselin stoyanov",
    "non-appliqu\u00e9e"
  ],
  [
    "\n\nmandar joshi, danqi chen, yinhan liu, daniel s weld,\nluke zettlemoyer, and omer levy",
    "non-appliqu\u00e9e"
  ],
  [
    " for instance, the user utterance \u201ci am looking\nfor a korean restaurant in the centre\u201d mentions\ntwo slots, food and area, whose values are korean\nand centre respectively",
    "non-appliqu\u00e9e"
  ],
  [
    ")\n\nintroduction\n\n\u2217\n\nturns\nu0 : i am looking for a korean restaurant\nin the centre",
    "non-appliqu\u00e9e"
  ],
  [
    " such models are usually constructed based on a massive scale of general text\ncorpora, like english wikipedia or bookscorpus\n(zhu et al",
    "non-appliqu\u00e9e"
  ],
  [
    "\nunified\n\n93\n\n\fyanran li, hui su, xiaoyu shen, wenjie li, ziqiang\ncao, and shuzi niu",
    "non-appliqu\u00e9e"
  ],
  [
    " putting these two facts \ntogether ,  politics concludes that the russian goal can be \nfulf i l led if the mpla, which may become the new angeles \ngovernment,  is communist",
    "non-appliqu\u00e9e"
  ],
  [
    "  for example, \nshore ($h077\\] analyzes fifty-six freshman english papers \nwr i t ten  by black col lege students and reveals patterns \no f  nonstandard usage ranging from uninf lected p lu ra l s ,  \npossessives, and th i rd  person s ingulars to \nover in f lec t ion  (use of  inappropr iate endings",
    "non-appliqu\u00e9e"
  ],
  [
    ", \"design criteria for a \nknowledge-based english language system for \nmanagement: an experimental analysis,\" mac \ntr-i~6, m",
    "non-appliqu\u00e9e"
  ],
  [
    " \n? laws of the world behave like demons or triggers thai \nmonitor the models and block illegal extensions",
    "non-appliqu\u00e9e"
  ],
  [
    " the organization of discourse, \nin the english language in its social and historical \ncontext ed",
    "non-appliqu\u00e9e"
  ],
  [
    " the \nsound pattern of english",
    "non-appliqu\u00e9e"
  ],
  [
    " \nan interesting fact to note is that similar results with \nrespect  to syntax were obta ined  in the exper~nents w i th  \nusl, the \"sister system\" of rel developed by ibm heidel- \nberg \\[10\\] -- with german used as gll in two studies of \nhigh school students: predominance of wh-questions (317 \nin total of 451); not many relative clauses (66); com- \nmands (35); conjunctions (26); quantifiers (15); defini- \ntions (ii); comparisons (2); yes/no questions (i)",
    "non-appliqu\u00e9e"
  ],
  [
    " rel english for the user",
    "non-appliqu\u00e9e"
  ],
  [
    " introduction \nwe are engaged in a long-term project o construct a\nsystem that can partake in extended english dialogues \non some reasonably well specified range of topics",
    "non-appliqu\u00e9e"
  ],
  [
    "  \n(11) i'm reading the french lieutenant's \nwoman",
    "non-appliqu\u00e9e"
  ],
  [
    " ristad(1986) argues that the minimal set of admissible \nlocal trees in gkps' gpsg for english is considerably smaller, yet still \ncontains more than 10 z? local trees",
    "non-appliqu\u00e9e"
  ],
  [
    " so, for ex- \nample, no algor ithm can tell us whether the english gpsg of \ngkps really generates english or ~*",
    "non-appliqu\u00e9e"
  ],
  [
    " (1985) \"on two recent attempts to show that \nenglish is not a cfl,\" computational linguistics 10: 182- \n186",
    "non-appliqu\u00e9e"
  ],
  [
    " \nsome extensions of a montague fragment of \nenglish",
    "non-appliqu\u00e9e"
  ],
  [
    " the proper treat- \nment of quantification i ordinary english",
    "non-appliqu\u00e9e"
  ],
  [
    " determining the scope of \nenglish quantifiers",
    "non-appliqu\u00e9e"
  ],
  [
    " science \nuniversity of delaware \nnewark, de 19718 \napri l  20, 1989 \nabstract \nfeature structures are informational elements that have \nbeen used in several inguistic theories and in computa- \ntional systems for natural-language processing",
    "non-appliqu\u00e9e"
  ],
  [
    " since \na gap-filler is removed from the list once it has \nbeen \"consumed\" by a gap, this way of threading \nensures that fillers and gaps will be matched in \na last-in-first-out fashion, which seems to be the \ngeneral pattern for english sentences with multi- \nple filler-gap dependencies",
    "non-appliqu\u00e9e"
  ],
  [
    " english as a formal lan- \nguage",
    "non-appliqu\u00e9e"
  ],
  [
    " (1985) planning english refer- \nring expressions",
    "non-appliqu\u00e9e"
  ],
  [
    " \nmassam, diane and roberge, yves (1989) recipe \ncontext null objects in english",
    "non-appliqu\u00e9e"
  ],
  [
    " vijay-shanker \ndepartment of cis \nuniversity of delaware \ndelaware, de 19716 \ndavid j",
    "non-appliqu\u00e9e"
  ],
  [
    " the number of such derivations \nis given by the catalan series and is therefore xpo- \nnential in n",
    "non-appliqu\u00e9e"
  ],
  [
    " dependency and coordination \nin the grammar of dutch and english",
    "non-appliqu\u00e9e"
  ],
  [
    " \nappendix \ni 1 read o a 0 review 2 of 1 nasality 4 in 0 german",
    "non-appliqu\u00e9e"
  ],
  [
    " \ni 0 read 2 a 1 review 1 of 0 nasality 1 in 0 german",
    "non-appliqu\u00e9e"
  ],
  [
    " the rest were determined \nto be lp verbs through a consensus of 3 individu- \nals, and when possible, further substantiated to be \nlp verbs through the aid of two sources on verbs \nand their complements - a complete gram- \nmar of english by quirk, greenbaum, leech, \nand svartvik (1972) and valency of verbs \nby allerton (1982)",
    "non-appliqu\u00e9e"
  ],
  [
    " comprehensive gram- \nmar of the english language",
    "non-appliqu\u00e9e"
  ],
  [
    " \nsugimura et al (1988) propose the use of a con- \nstraint logic program for analyzing modifier-modifiee \nrelationships of japanese",
    "non-appliqu\u00e9e"
  ],
  [
    " \ncdg is actually being used for an interac- \ntive japanese parser of a japanese-to-english ma- \nchine translation system for a newspaper domain \n(maruyama et",
    "non-appliqu\u00e9e"
  ],
  [
    ", and ogino, s, \n1990, \"an interactive japanese parser for ma- \nchine translation,\" coling 'go, to appear",
    "non-appliqu\u00e9e"
  ],
  [
    " 1988, \n\"constraint analysis on japanese modification,\" \nin: dahl, v",
    "non-appliqu\u00e9e"
  ],
  [
    " motivation for this kind of projection algo- \nrithm is given by the processing of dutch (frazier 1987) and \nthe processing of certain english noun phrase constructions \n(gibson 1989)",
    "non-appliqu\u00e9e"
  ],
  [
    " consider (34): \n(34) # the russian women loved died",
    "non-appliqu\u00e9e"
  ],
  [
    " \nup until the last word, this sentence is ambiguous \nbetween two readings: one where loved is the matrix \nverb; and the other where loved heads a relative clause \nmodifier of the noun russian",
    "non-appliqu\u00e9e"
  ],
  [
    " \\[u, \\[we the russian women\\] \nb",
    "non-appliqu\u00e9e"
  ],
  [
    " \\[u, \\[we the in, \\[w, russian/\\] [cl, \\[we oi \\] \\[tp \\[we \nwomen \\] \\]\\] \\]\\] \\] \nstructure (35a) requires xrr plus since the np the \nrussian women needs but currently lacks a thematic \nrole",
    "non-appliqu\u00e9e"
  ],
  [
    " 1987 the english noun phrase in \nits sentential aspect",
    "non-appliqu\u00e9e"
  ],
  [
    "), readings \nin english transformational grammar, ginn, \nwaltham, ma: 184-221",
    "non-appliqu\u00e9e"
  ],
  [
    " \nfrazier, lyn 1987 syntactic processing evidence \nfrom dutch",
    "non-appliqu\u00e9e"
  ],
  [
    " toward a computa- \ntional theory of definite anaphora com- \nprehension i english",
    "non-appliqu\u00e9e"
  ],
  [
    " throughout the rest of this \npaper, we will follow the convention of denoting ar- \nbitrary activities using uppercase greek letters, while \nusing lowercase greek letters to denote act-types",
    "non-appliqu\u00e9e"
  ],
  [
    "a tr ipart ite  plan-based model of  d ialogue \nlynn lambert  \nsandra carberry  \ndepar tment  of computer  and information sciences \nuniversity of delaware \nnewark,  delaware 19716, usa \nabst ract  1 \nthis paper presents a tripartite model of dialogue in \nwhich three different kinds of actions are modeled: \ndomain actions, problem-solving actions, and dis- \ncourse or communicative actions",
    "non-appliqu\u00e9e"
  ],
  [
    " in his \nmodel, discourse plans can refer either to the explo- \nration level (corresponding to queries about possi- \nble ways of achieving a goal) or to the domain exe- \ni f  i decide to get a ba degree, then i'll take \nfrench to meet the foreign language requirement",
    "non-appliqu\u00e9e"
  ],
  [
    " \nin the above case, the speaker is still exploring a \nplan for getting a ba degree, but has committed \nto taking french to satisfy the foreign language re- \nquirement should the plan for the ba degree be \nadopted",
    "non-appliqu\u00e9e"
  ],
  [
    " \nitinrichs, erhard \\[1986\\] temporal anaphora in \ndiscourses of english",
    "non-appliqu\u00e9e"
  ],
  [
    " \"disambiguation \nof prepositional phrase attachments in english \nsentences using case grammar nalysis",
    "non-appliqu\u00e9e"
  ],
  [
    " a__ \ncomprehensive grammar ofthe english language",
    "non-appliqu\u00e9e"
  ],
  [
    " this seems \nto be sufficient to cover the range of examples \ntreated by dalrymple, shieber and pereira (1991), \nbut that is a specific linguistic claim about verb \nphrase ellipsis in english and not central to the \npresent paper",
    "non-appliqu\u00e9e"
  ],
  [
    " v i jay -shanker ,  & gi joo yang \ndepar tment  of computer  and in fo rmat ion  sciences \nunivers i ty  of delaware \nnewark,  delaware 19716, usa \nemail: mccoy@udel",
    "non-appliqu\u00e9e"
  ],
  [
    " phd thesis, university \nof delaware",
    "non-appliqu\u00e9e"
  ],
  [
    "conversational impl icatures in  indirect repl ies  \nnancy green \nsandra carberry \ndepar tment  of computer  and informat ion sciences \nuniversity of delaware \nnewark, delaware 19716, usa \nemail: green@cis",
    "non-appliqu\u00e9e"
  ],
  [
    " probabilis- \ntic grammar for phonetic to french tran- \nscription",
    "non-appliqu\u00e9e"
  ],
  [
    " japanese \nzero pronominal binding: where syntax and dis- \ncourse meet",
    "non-appliqu\u00e9e"
  ],
  [
    " poser, editor, pa- \npers from the second international workshop on \njapanese syntax, pages 47-74",
    "non-appliqu\u00e9e"
  ],
  [
    " zero anaphora: the case of \njapanese",
    "non-appliqu\u00e9e"
  ],
  [
    " tense and t ime reference in english",
    "non-appliqu\u00e9e"
  ],
  [
    " some structural  analogies between \ntenses and pronouns in english",
    "non-appliqu\u00e9e"
  ],
  [
    " cohesion in \nenglish",
    "non-appliqu\u00e9e"
  ],
  [
    "l waltz, \"an english language question answering \nsystem for a large relational database,\" \ncommunications of the acm 21(7):526-39, 1978",
    "non-appliqu\u00e9e"
  ],
  [
    " \nlascarides, alex, asher, nicholas and oberlander, \njon (1992) inferring discourse relations in context, in \nproceedings of the 30th annual meeting of the asso- \n40 \nciation of computational linguistics, ppl-8, delaware \nusa, june 1992",
    "non-appliqu\u00e9e"
  ],
  [
    " cohesion \nin english",
    "non-appliqu\u00e9e"
  ],
  [
    " english language \nseries, title no",
    "non-appliqu\u00e9e"
  ],
  [
    " a compar- \nison of the enhanced good-turing and deleted estimation \nmethods for estimating probabilities of english bigrams",
    "non-appliqu\u00e9e"
  ],
  [
    " the comlex english pronounc- \ning dictionary",
    "non-appliqu\u00e9e"
  ],
  [
    " the british english \nexample pronunciation dictionary, v0",
    "non-appliqu\u00e9e"
  ],
  [
    " applying speech verification to a large \ndata base of german to obtain a statistical sur- \nvey about rules of pronunciation",
    "non-appliqu\u00e9e"
  ],
  [
    " \nthe dependency model has also been proposed by \nkobayasi et al(1994) for analysing japanese noun \ncompounds, apparently independently",
    "non-appliqu\u00e9e"
  ],
  [
    " a freely available wide coverage mor- \nphological analyzer for english",
    "non-appliqu\u00e9e"
  ],
  [
    " \nanalysis of japanese compound nouns using \ncollocational information",
    "non-appliqu\u00e9e"
  ],
  [
    " the interpretation of \nenglish noun sequences on the computer",
    "non-appliqu\u00e9e"
  ],
  [
    " the stress and \nstructure of modified noun phrases in english",
    "non-appliqu\u00e9e"
  ],
  [
    " ordered chaos: the in- \nterpretation of english noun-noun compounds",
    "non-appliqu\u00e9e"
  ],
  [
    " english noun-phrase accent \nprediction for text-to-speech",
    "non-appliqu\u00e9e"
  ],
  [
    " net- \nwork morphology: a datr account of russian \nnominal inflection",
    "non-appliqu\u00e9e"
  ],
  [
    " an \nilex model for german compound stress in \ndatr",
    "non-appliqu\u00e9e"
  ],
  [
    " here, though, the main significance of \nthe definition is that it forms a component of a full- \nscale treatment of a gb theory of english s- and \nd-structure within l 2 this full definition estab- k,p\" \nlishes that the theory we capture licenses a strongly \ncontext-free language",
    "non-appliqu\u00e9e"
  ],
  [
    " this definition works for english be- \ncause it is possible, in english, to resolve chains into \nboundedly many types in such a way that no two \nchains of the same type ever overlap",
    "non-appliqu\u00e9e"
  ],
  [
    " \n6 conclus ion \n5 a compar ison and a contrast  \nhaving interpretations both of gpsg and of a \ngb account of english in l 2 provides a certain k,p \namount of insight into the distinctions between these \napproaches",
    "non-appliqu\u00e9e"
  ],
  [
    " of delaware",
    "non-appliqu\u00e9e"
  ],
  [
    " computa- \ntional analysis of present-day american english",
    "non-appliqu\u00e9e"
  ],
  [
    " decision lists for lexi- \ncal ambiguity resolution: application to accent \nrestoration in spanish and french",
    "non-appliqu\u00e9e"
  ],
  [
    " \nour implementation has been tested with several \nsmaller and one large (> 5000 lines) grammar, a \nlinearisation-based grammar of a sizeable fragment of \ngerman (hinrichs et al 1997)",
    "non-appliqu\u00e9e"
  ],
  [
    " \nwe also plan to investigate a specialised constraint \nlanguage for linearisation grammars, to be able to opti- \nraise the processing of freer word order languages such \nas german",
    "non-appliqu\u00e9e"
  ],
  [
    " english trans- \nlation of the russian article in dokl",
    "non-appliqu\u00e9e"
  ],
  [
    " peo- \nple who go into a bookstore or library are not usually \nlooking simply for information about a particular \ntopic, but rather have requirements of genre as well: \nthey are looking for scholarly articles about hypno- \ntism, novels about the french revolution, editorials \nabout the supercollider, and so forth",
    "non-appliqu\u00e9e"
  ],
  [
    " for his help with the english of \nthis text",
    "non-appliqu\u00e9e"
  ],
  [
    " distributional clustering of english words",
    "non-appliqu\u00e9e"
  ],
  [
    " \na comparison of the enhanced good-turing and \ndeleted estimation methods for estimating proba- \nbilites of english bigrams",
    "non-appliqu\u00e9e"
  ],
  [
    " distributional c ustering of english words",
    "non-appliqu\u00e9e"
  ],
  [
    "1 eva luat ion  cr i ter ia  \ngeneral-purpose l xical resources, such as word- \nnet, longman dictionary of contemporary english \n(ldoce), and roget's thesaurus, strive to achieve \ncompleteness",
    "non-appliqu\u00e9e"
  ],
  [
    " decision lists for lexical am- \nbiguity resolution: application to accent restora- \ntion in spanish and french",
    "non-appliqu\u00e9e"
  ],
  [
    " \nmarchand h, \"'on a question of contrary analysis \nwith derivational connected but morphologically \nuncharacterized words\", english studies",
    "non-appliqu\u00e9e"
  ],
  [
    " speech recognition for spontaneously \nspoken german dialogs",
    "non-appliqu\u00e9e"
  ],
  [
    " \nido dagan, ronen feldman, and haym hirsh",
    "non-appliqu\u00e9e"
  ],
  [
    " \nronen feldman and ido dagan",
    "non-appliqu\u00e9e"
  ],
  [
    " \nido dagan, shanl marcus, and shanl marko- \nvitch",
    "non-appliqu\u00e9e"
  ],
  [
    " \nido dagan, lillian lee, and fernando pereira",
    "non-appliqu\u00e9e"
  ],
  [
    " ma(r)king concessions in english and ger- \nman",
    "non-appliqu\u00e9e"
  ],
  [
    " \n58 \npattern a \nheadlight windshield ignition shifter dashboard ra- \ndiator brake tailpipe pipe airbag speedometer con- \nverter hood trunk visor vent wheel occupant en- \ngine tyre \npattern b \ntrunk wheel driver hood occupant seat bumper \nbackseat dashboard jalopy fender ear roof wind- \nshield back clunker window shipment reenactment \naxle \npattern c \npassenger gunmen leaflet hop houseplant airbag \ngun koran cocaine getaway motorist phone men \nindecency person ride woman detonator kid key \npattern d \nimport caravan make dozen carcass hipment hun- \ndred thousand sale export model truckload queue \nmillion boatload inventory hood registration trunk \nten \npattern e \nairbag packet switch gem amateur device handgun \npassenger fire smuggler phone tag driver weapon \nmeal compartment croatian defect refugee delay \ntable 2: grammatical pattern comparison \nour seeds are one word (such as \"car\") and its \nplural",
    "non-appliqu\u00e9e"
  ],
  [
    " nptool, a detector of \nenglish noun phrases",
    "non-appliqu\u00e9e"
  ],
  [
    " decision lists for lexi- \ncal ambiguity resolution: application to ac- \ncent restoration in spanish and french",
    "non-appliqu\u00e9e"
  ],
  [
    " in proceedings of the 30th annual \nmeeting of the a cl, pages 128-135, newark, \ndelaware",
    "non-appliqu\u00e9e"
  ]
]